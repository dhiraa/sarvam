{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from word_vec.utils.downloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ready\n"
     ]
    }
   ],
   "source": [
    "text_path = download(FILE_NAME, EXPECTED_BYTES, \"tmp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = read_data('tmp//text8.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17005207"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary, index_dictionary = build_vocab(words, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_vec.utils.common import vocab_to_tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:00<00:00, 66231.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 words into tmp/vocab.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_to_tsv(dictionary.keys(), \"tmp/vocab.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = generate_sample(list(dictionary.keys()), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<UNK>',\n",
       " 'the',\n",
       " 'of',\n",
       " 'and',\n",
       " 'one',\n",
       " 'in',\n",
       " 'a',\n",
       " 'to',\n",
       " 'zero',\n",
       " 'nine',\n",
       " 'two',\n",
       " 'is',\n",
       " 'as',\n",
       " 'eight',\n",
       " 'for',\n",
       " 's',\n",
       " 'five',\n",
       " 'three',\n",
       " 'was',\n",
       " 'by',\n",
       " 'that',\n",
       " 'four',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'with',\n",
       " 'on',\n",
       " 'are',\n",
       " 'it',\n",
       " 'from',\n",
       " 'or',\n",
       " 'his',\n",
       " 'an',\n",
       " 'be',\n",
       " 'this',\n",
       " 'which',\n",
       " 'at',\n",
       " 'he',\n",
       " 'also',\n",
       " 'not',\n",
       " 'have',\n",
       " 'were',\n",
       " 'has',\n",
       " 'but',\n",
       " 'other',\n",
       " 'their',\n",
       " 'its',\n",
       " 'first',\n",
       " 'they',\n",
       " 'some',\n",
       " 'had',\n",
       " 'all',\n",
       " 'more',\n",
       " 'most',\n",
       " 'can',\n",
       " 'been',\n",
       " 'such',\n",
       " 'many',\n",
       " 'who',\n",
       " 'new',\n",
       " 'used',\n",
       " 'there',\n",
       " 'after',\n",
       " 'when',\n",
       " 'into',\n",
       " 'american',\n",
       " 'time',\n",
       " 'these',\n",
       " 'only',\n",
       " 'see',\n",
       " 'may',\n",
       " 'than',\n",
       " 'world',\n",
       " 'i',\n",
       " 'b',\n",
       " 'would',\n",
       " 'd',\n",
       " 'no',\n",
       " 'however',\n",
       " 'between',\n",
       " 'about',\n",
       " 'over',\n",
       " 'years',\n",
       " 'states',\n",
       " 'people',\n",
       " 'war',\n",
       " 'during',\n",
       " 'united',\n",
       " 'known',\n",
       " 'if',\n",
       " 'called',\n",
       " 'use',\n",
       " 'th',\n",
       " 'system',\n",
       " 'often',\n",
       " 'state',\n",
       " 'so',\n",
       " 'history',\n",
       " 'will',\n",
       " 'up',\n",
       " 'while',\n",
       " 'where',\n",
       " 'city',\n",
       " 'being',\n",
       " 'english',\n",
       " 'then',\n",
       " 'any',\n",
       " 'both',\n",
       " 'under',\n",
       " 'out',\n",
       " 'made',\n",
       " 'well',\n",
       " 'her',\n",
       " 'e',\n",
       " 'number',\n",
       " 'government',\n",
       " 'them',\n",
       " 'm',\n",
       " 'later',\n",
       " 'since',\n",
       " 'him',\n",
       " 'part',\n",
       " 'name',\n",
       " 'c',\n",
       " 'century',\n",
       " 'through',\n",
       " 'because',\n",
       " 'x',\n",
       " 'university',\n",
       " 'early',\n",
       " 'life',\n",
       " 'british',\n",
       " 'year',\n",
       " 'like',\n",
       " 'same',\n",
       " 'including',\n",
       " 'became',\n",
       " 'example',\n",
       " 'day',\n",
       " 'each',\n",
       " 'even',\n",
       " 'work',\n",
       " 'language',\n",
       " 'although',\n",
       " 'several',\n",
       " 'form',\n",
       " 'john',\n",
       " 'u',\n",
       " 'national',\n",
       " 'very',\n",
       " 'much',\n",
       " 'g',\n",
       " 'french',\n",
       " 'before',\n",
       " 'general',\n",
       " 'what',\n",
       " 't',\n",
       " 'against',\n",
       " 'n',\n",
       " 'high',\n",
       " 'links',\n",
       " 'could',\n",
       " 'based',\n",
       " 'those',\n",
       " 'now',\n",
       " 'second',\n",
       " 'de',\n",
       " 'music',\n",
       " 'another',\n",
       " 'large',\n",
       " 'she',\n",
       " 'f',\n",
       " 'external',\n",
       " 'german',\n",
       " 'different',\n",
       " 'modern',\n",
       " 'great',\n",
       " 'do',\n",
       " 'common',\n",
       " 'set',\n",
       " 'list',\n",
       " 'south',\n",
       " 'series',\n",
       " 'major',\n",
       " 'game',\n",
       " 'power',\n",
       " 'long',\n",
       " 'country',\n",
       " 'king',\n",
       " 'law',\n",
       " 'group',\n",
       " 'film',\n",
       " 'still',\n",
       " 'until',\n",
       " 'north',\n",
       " 'international',\n",
       " 'term',\n",
       " 'we',\n",
       " 'end',\n",
       " 'book',\n",
       " 'found',\n",
       " 'own',\n",
       " 'political',\n",
       " 'party',\n",
       " 'order',\n",
       " 'usually',\n",
       " 'president',\n",
       " 'church',\n",
       " 'you',\n",
       " 'death',\n",
       " 'theory',\n",
       " 'area',\n",
       " 'around',\n",
       " 'include',\n",
       " 'god',\n",
       " 'ii',\n",
       " 'way',\n",
       " 'did',\n",
       " 'military',\n",
       " 'population',\n",
       " 'using',\n",
       " 'though',\n",
       " 'small',\n",
       " 'following',\n",
       " 'within',\n",
       " 'non',\n",
       " 'human',\n",
       " 'left',\n",
       " 'main',\n",
       " 'among',\n",
       " 'point',\n",
       " 'r',\n",
       " 'due',\n",
       " 'p',\n",
       " 'considered',\n",
       " 'public',\n",
       " 'popular',\n",
       " 'computer',\n",
       " 'west',\n",
       " 'family',\n",
       " 'east',\n",
       " 'information',\n",
       " 'important',\n",
       " 'european',\n",
       " 'man',\n",
       " 'sometimes',\n",
       " 'right',\n",
       " 'old',\n",
       " 'free',\n",
       " 'word',\n",
       " 'without',\n",
       " 'last',\n",
       " 'us',\n",
       " 'members',\n",
       " 'given',\n",
       " 'times',\n",
       " 'roman',\n",
       " 'make',\n",
       " 'h',\n",
       " 'age',\n",
       " 'place',\n",
       " 'l',\n",
       " 'thus',\n",
       " 'science',\n",
       " 'case',\n",
       " 'become',\n",
       " 'systems',\n",
       " 'union',\n",
       " 'born',\n",
       " 'york',\n",
       " 'line',\n",
       " 'countries',\n",
       " 'does',\n",
       " 'isbn',\n",
       " 'st',\n",
       " 'control',\n",
       " 'various',\n",
       " 'others',\n",
       " 'house',\n",
       " 'article',\n",
       " 'island',\n",
       " 'should',\n",
       " 'led',\n",
       " 'back',\n",
       " 'period',\n",
       " 'player',\n",
       " 'europe',\n",
       " 'languages',\n",
       " 'central',\n",
       " 'water',\n",
       " 'few',\n",
       " 'western',\n",
       " 'home',\n",
       " 'began',\n",
       " 'generally',\n",
       " 'less',\n",
       " 'k',\n",
       " 'similar',\n",
       " 'written',\n",
       " 'original',\n",
       " 'best',\n",
       " 'must',\n",
       " 'according',\n",
       " 'school',\n",
       " 'france',\n",
       " 'air',\n",
       " 'single',\n",
       " 'force',\n",
       " 'v',\n",
       " 'land',\n",
       " 'groups',\n",
       " 'down',\n",
       " 'how',\n",
       " 'works',\n",
       " 'development',\n",
       " 'official',\n",
       " 'support',\n",
       " 'england',\n",
       " 'j',\n",
       " 'rather',\n",
       " 'data',\n",
       " 'space',\n",
       " 'greek',\n",
       " 'km',\n",
       " 'named',\n",
       " 'germany',\n",
       " 'just',\n",
       " 'games',\n",
       " 'said',\n",
       " 'version',\n",
       " 'late',\n",
       " 'earth',\n",
       " 'company',\n",
       " 'every',\n",
       " 'economic',\n",
       " 'short',\n",
       " 'published',\n",
       " 'black',\n",
       " 'army',\n",
       " 'off',\n",
       " 'london',\n",
       " 'million',\n",
       " 'body',\n",
       " 'field',\n",
       " 'christian',\n",
       " 'either',\n",
       " 'social',\n",
       " 'empire',\n",
       " 'o',\n",
       " 'developed',\n",
       " 'standard',\n",
       " 'court',\n",
       " 'service',\n",
       " 'kingdom',\n",
       " 'along',\n",
       " 'college',\n",
       " 'republic',\n",
       " 'sea',\n",
       " 'america',\n",
       " 'today',\n",
       " 'result',\n",
       " 'held',\n",
       " 'team',\n",
       " 'light',\n",
       " 'means',\n",
       " 'never',\n",
       " 'especially',\n",
       " 'third',\n",
       " 'further',\n",
       " 'character',\n",
       " 'forces',\n",
       " 'take',\n",
       " 'men',\n",
       " 'society',\n",
       " 'show',\n",
       " 'open',\n",
       " 'possible',\n",
       " 'fact',\n",
       " 'battle',\n",
       " 'took',\n",
       " 'former',\n",
       " 'books',\n",
       " 'soviet',\n",
       " 'river',\n",
       " 'children',\n",
       " 'having',\n",
       " 'good',\n",
       " 'local',\n",
       " 'current',\n",
       " 'son',\n",
       " 'process',\n",
       " 'natural',\n",
       " 'present',\n",
       " 'himself',\n",
       " 'islands',\n",
       " 'total',\n",
       " 'near',\n",
       " 'white',\n",
       " 'days',\n",
       " 'person',\n",
       " 'itself',\n",
       " 'seen',\n",
       " 'culture',\n",
       " 'little',\n",
       " 'above',\n",
       " 'software',\n",
       " 'largest',\n",
       " 'words',\n",
       " 'upon',\n",
       " 'level',\n",
       " 'father',\n",
       " 'created',\n",
       " 'side',\n",
       " 'red',\n",
       " 'references',\n",
       " 'press',\n",
       " 'full',\n",
       " 'region',\n",
       " 'almost',\n",
       " 'image',\n",
       " 'al',\n",
       " 'famous',\n",
       " 'play',\n",
       " 'came',\n",
       " 'role',\n",
       " 'once',\n",
       " 'certain',\n",
       " 'league',\n",
       " 'jewish',\n",
       " 'james',\n",
       " 'january',\n",
       " 'site',\n",
       " 'again',\n",
       " 'numbers',\n",
       " 'art',\n",
       " 'member',\n",
       " 'areas',\n",
       " 'movement',\n",
       " 'religious',\n",
       " 'type',\n",
       " 'march',\n",
       " 'community',\n",
       " 'story',\n",
       " 'played',\n",
       " 'production',\n",
       " 'released',\n",
       " 'center',\n",
       " 'rights',\n",
       " 'real',\n",
       " 'related',\n",
       " 'foreign',\n",
       " 'low',\n",
       " 'ancient',\n",
       " 'terms',\n",
       " 'view',\n",
       " 'source',\n",
       " 'act',\n",
       " 'minister',\n",
       " 'change',\n",
       " 'energy',\n",
       " 'produced',\n",
       " 'research',\n",
       " 'actor',\n",
       " 'making',\n",
       " 'civil',\n",
       " 'december',\n",
       " 'women',\n",
       " 'special',\n",
       " 'style',\n",
       " 'william',\n",
       " 'design',\n",
       " 'japanese',\n",
       " 'available',\n",
       " 'chinese',\n",
       " 'forms',\n",
       " 'canada',\n",
       " 'northern',\n",
       " 'died',\n",
       " 'class',\n",
       " 'living',\n",
       " 'next',\n",
       " 'particular',\n",
       " 'program',\n",
       " 'council',\n",
       " 'television',\n",
       " 'head',\n",
       " 'david',\n",
       " 'china',\n",
       " 'middle',\n",
       " 'established',\n",
       " 'hand',\n",
       " 'bc',\n",
       " 'far',\n",
       " 'july',\n",
       " 'function',\n",
       " 'position',\n",
       " 'y',\n",
       " 'built',\n",
       " 'george',\n",
       " 'band',\n",
       " 'together',\n",
       " 'w',\n",
       " 'latin',\n",
       " 'thought',\n",
       " 'eastern',\n",
       " 'charles',\n",
       " 'parts',\n",
       " 'instead',\n",
       " 'study',\n",
       " 'might',\n",
       " 'india',\n",
       " 'code',\n",
       " 'included',\n",
       " 'meaning',\n",
       " 'trade',\n",
       " 'per',\n",
       " 'june',\n",
       " 'least',\n",
       " 'half',\n",
       " 'model',\n",
       " 'economy',\n",
       " 'prime',\n",
       " 'traditional',\n",
       " 'always',\n",
       " 'capital',\n",
       " 'range',\n",
       " 'november',\n",
       " 'emperor',\n",
       " 'young',\n",
       " 'anti',\n",
       " 'final',\n",
       " 'text',\n",
       " 'players',\n",
       " 'uk',\n",
       " 'april',\n",
       " 'run',\n",
       " 'september',\n",
       " 'addition',\n",
       " 'radio',\n",
       " 'live',\n",
       " 'august',\n",
       " 'taken',\n",
       " 'note',\n",
       " 'italian',\n",
       " 'lost',\n",
       " 'nature',\n",
       " 'project',\n",
       " 'technology',\n",
       " 'spanish',\n",
       " 'october',\n",
       " 'recent',\n",
       " 'rate',\n",
       " 'won',\n",
       " 'true',\n",
       " 'value',\n",
       " 'uses',\n",
       " 'russian',\n",
       " 'est',\n",
       " 'wrote',\n",
       " 'effect',\n",
       " 'album',\n",
       " 'southern',\n",
       " 'africa',\n",
       " 'whose',\n",
       " 'top',\n",
       " 'historical',\n",
       " 'australia',\n",
       " 'catholic',\n",
       " 'particularly',\n",
       " 'self',\n",
       " 'structure',\n",
       " 'record',\n",
       " 'evidence',\n",
       " 'rule',\n",
       " 'themselves',\n",
       " 'influence',\n",
       " 'cases',\n",
       " 'subject',\n",
       " 'referred',\n",
       " 'continued',\n",
       " 'nations',\n",
       " 'below',\n",
       " 'rock',\n",
       " 'japan',\n",
       " 'com',\n",
       " 'song',\n",
       " 'throughout',\n",
       " 'names',\n",
       " 'female',\n",
       " 'title',\n",
       " 'therefore',\n",
       " 'our',\n",
       " 'office',\n",
       " 'star',\n",
       " 'paul',\n",
       " 'too',\n",
       " 'cities',\n",
       " 'february',\n",
       " 'independent',\n",
       " 'author',\n",
       " 'problem',\n",
       " 'species',\n",
       " 'education',\n",
       " 'done',\n",
       " 'philosophy',\n",
       " 'come',\n",
       " 'higher',\n",
       " 'originally',\n",
       " 'market',\n",
       " 'town',\n",
       " 'my',\n",
       " 'season',\n",
       " 'love',\n",
       " 'strong',\n",
       " 'israel',\n",
       " 'irish',\n",
       " 'writer',\n",
       " 'films',\n",
       " 'elements',\n",
       " 'robert',\n",
       " 'whether',\n",
       " 'despite',\n",
       " 'eventually',\n",
       " 'here',\n",
       " 'football',\n",
       " 'action',\n",
       " 'internet',\n",
       " 'individual',\n",
       " 'sound',\n",
       " 'network',\n",
       " 'described',\n",
       " 'practice',\n",
       " 'characters',\n",
       " 're',\n",
       " 'royal',\n",
       " 'la',\n",
       " 'events',\n",
       " 'formed',\n",
       " 'commonly',\n",
       " 'base',\n",
       " 'received',\n",
       " 'african',\n",
       " 'problems',\n",
       " 'food',\n",
       " 'jews',\n",
       " 'able',\n",
       " 'male',\n",
       " 'typically',\n",
       " 'mass',\n",
       " 'complex',\n",
       " 'lower',\n",
       " 'includes',\n",
       " 'outside',\n",
       " 'legal',\n",
       " 'complete',\n",
       " 'significant',\n",
       " 'parliament',\n",
       " 'actually',\n",
       " 'business',\n",
       " 'fiction',\n",
       " 'physical',\n",
       " 'followed',\n",
       " 'deaths',\n",
       " 'key',\n",
       " 'leader',\n",
       " 'widely',\n",
       " 'page',\n",
       " 'basic',\n",
       " 'types',\n",
       " 'henry',\n",
       " 'elected',\n",
       " 'beginning',\n",
       " 'fire',\n",
       " 'building',\n",
       " 'independence',\n",
       " 'went',\n",
       " 'movie',\n",
       " 'aircraft',\n",
       " 'ever',\n",
       " 'canadian',\n",
       " 'material',\n",
       " 'births',\n",
       " 'video',\n",
       " 'news',\n",
       " 'future',\n",
       " 'scientific',\n",
       " 'simply',\n",
       " 'go',\n",
       " 'defined',\n",
       " 'laws',\n",
       " 'get',\n",
       " 'close',\n",
       " 'industry',\n",
       " 'specific',\n",
       " 'examples',\n",
       " 'believe',\n",
       " 'services',\n",
       " 'idea',\n",
       " 'method',\n",
       " 'introduced',\n",
       " 'points',\n",
       " 'return',\n",
       " 'cause',\n",
       " 'indian',\n",
       " 'britain',\n",
       " 'features',\n",
       " 'majority',\n",
       " 'size',\n",
       " 'post',\n",
       " 'lead',\n",
       " 'organization',\n",
       " 'cannot',\n",
       " 'designed',\n",
       " 'ireland',\n",
       " 'cross',\n",
       " 'classical',\n",
       " 'personal',\n",
       " 'writing',\n",
       " 'concept',\n",
       " 'associated',\n",
       " 'required',\n",
       " 'soon',\n",
       " 'changes',\n",
       " 'california',\n",
       " 'located',\n",
       " 'sense',\n",
       " 'believed',\n",
       " 'away',\n",
       " 'started',\n",
       " 'co',\n",
       " 'religion',\n",
       " 'mother',\n",
       " 'county',\n",
       " 'rules',\n",
       " 'studies',\n",
       " 'yet',\n",
       " 'find',\n",
       " 'knowledge',\n",
       " 'put',\n",
       " 'founded',\n",
       " 'policy',\n",
       " 'currently',\n",
       " 'provide',\n",
       " 'working',\n",
       " 'media',\n",
       " 'election',\n",
       " 'australian',\n",
       " 'me',\n",
       " 'thomas',\n",
       " 'allowed',\n",
       " 'russia',\n",
       " 'earlier',\n",
       " 'greater',\n",
       " 'limited',\n",
       " 'object',\n",
       " 'brought',\n",
       " 'online',\n",
       " 'association',\n",
       " 'lord',\n",
       " 'mostly',\n",
       " 'blue',\n",
       " 'constitution',\n",
       " 'across',\n",
       " 'added',\n",
       " 'interest',\n",
       " 'things',\n",
       " 'relations',\n",
       " 'speed',\n",
       " 'federal',\n",
       " 'singer',\n",
       " 'effects',\n",
       " 'growth',\n",
       " 'sources',\n",
       " 'your',\n",
       " 'remains',\n",
       " 'z',\n",
       " 'probably',\n",
       " 'gave',\n",
       " 'simple',\n",
       " 'attack',\n",
       " 'longer',\n",
       " 'reference',\n",
       " 'saint',\n",
       " 'success',\n",
       " 'killed',\n",
       " 'past',\n",
       " 'career',\n",
       " 'need',\n",
       " 'park',\n",
       " 'definition',\n",
       " 'say',\n",
       " 'etc',\n",
       " 'give',\n",
       " 'peace',\n",
       " 'chief',\n",
       " 'stories',\n",
       " 'security',\n",
       " 'wide',\n",
       " 'ball',\n",
       " 'saw',\n",
       " 'machine',\n",
       " 'better',\n",
       " 'cell',\n",
       " 'leading',\n",
       " 'becomes',\n",
       " 'spain',\n",
       " 'larger',\n",
       " 'products',\n",
       " 'parties',\n",
       " 'night',\n",
       " 'remained',\n",
       " 'prize',\n",
       " 'months',\n",
       " 'website',\n",
       " 'big',\n",
       " 'cultural',\n",
       " 'money',\n",
       " 'help',\n",
       " 'territory',\n",
       " 'private',\n",
       " 'moved',\n",
       " 'letter',\n",
       " 'wife',\n",
       " 'politics',\n",
       " 'lines',\n",
       " 'largely',\n",
       " 'contains',\n",
       " 'companies',\n",
       " 'lake',\n",
       " 'perhaps',\n",
       " 'green',\n",
       " 'already',\n",
       " 'dead',\n",
       " 'iii',\n",
       " 'library',\n",
       " 'separate',\n",
       " 'refer',\n",
       " 'makes',\n",
       " 'appeared',\n",
       " 'dutch',\n",
       " 'holy',\n",
       " 'era',\n",
       " 'novel',\n",
       " 'successful',\n",
       " 'italy',\n",
       " 'letters',\n",
       " 'results',\n",
       " 'matter',\n",
       " 'produce',\n",
       " 'origin',\n",
       " 'claim',\n",
       " 'whole',\n",
       " 'directly',\n",
       " 'attempt',\n",
       " 'actress',\n",
       " 'surface',\n",
       " 'revolution',\n",
       " 'highly',\n",
       " 'caused',\n",
       " 'status',\n",
       " 'musical',\n",
       " 'richard',\n",
       " 'commercial',\n",
       " 'division',\n",
       " 'color',\n",
       " 'health',\n",
       " 'coast',\n",
       " 'release',\n",
       " 'latter',\n",
       " 'authority',\n",
       " 'treaty',\n",
       " 'turn',\n",
       " 'michael',\n",
       " 'nation',\n",
       " 'direct',\n",
       " 'asia',\n",
       " 'edition',\n",
       " 'programming',\n",
       " 'playing',\n",
       " 'date',\n",
       " 'mary',\n",
       " 'native',\n",
       " 'whom',\n",
       " 'married',\n",
       " 'towards',\n",
       " 'issues',\n",
       " 'double',\n",
       " 'primary',\n",
       " 'basis',\n",
       " 'allow',\n",
       " 'enough',\n",
       " 'memory',\n",
       " 'reason',\n",
       " 'web',\n",
       " 'exist',\n",
       " 'provided',\n",
       " 'oil',\n",
       " 'course',\n",
       " 'functions',\n",
       " 'alexander',\n",
       " 'analysis',\n",
       " 'chemical',\n",
       " 'mid',\n",
       " 'replaced',\n",
       " 'queen',\n",
       " 'claims',\n",
       " 'tv',\n",
       " 'sun',\n",
       " 'literature',\n",
       " 'metal',\n",
       " 'amount',\n",
       " 'divided',\n",
       " 'blood',\n",
       " 'likely',\n",
       " 'access',\n",
       " 'average',\n",
       " 'length',\n",
       " 'smaller',\n",
       " 'medical',\n",
       " 'property',\n",
       " 'students',\n",
       " 'degree',\n",
       " 'elections',\n",
       " 'club',\n",
       " 'claimed',\n",
       " 'performance',\n",
       " 'director',\n",
       " 'digital',\n",
       " 'front',\n",
       " 'museum',\n",
       " 'difficult',\n",
       " 'tradition',\n",
       " 'nearly',\n",
       " 'schools',\n",
       " 'washington',\n",
       " 'gas',\n",
       " 'jesus',\n",
       " 'map',\n",
       " 'louis',\n",
       " 'rome',\n",
       " 'unit',\n",
       " 'baseball',\n",
       " 'mind',\n",
       " 'peter',\n",
       " 'mark',\n",
       " 'collection',\n",
       " 'product',\n",
       " 'congress',\n",
       " 'programs',\n",
       " 'changed',\n",
       " 'ideas',\n",
       " 'moon',\n",
       " 'entire',\n",
       " 'user',\n",
       " 'ground',\n",
       " 'records',\n",
       " 'frequently',\n",
       " 'increase',\n",
       " 'highest',\n",
       " 'sent',\n",
       " 'finally',\n",
       " 'board',\n",
       " 'don',\n",
       " 'notable',\n",
       " 'read',\n",
       " 'methods',\n",
       " 'recently',\n",
       " 'bit',\n",
       " 'involved',\n",
       " 'variety',\n",
       " 'call',\n",
       " 'democratic',\n",
       " 'ten',\n",
       " 'served',\n",
       " 'minor',\n",
       " 'hard',\n",
       " 'birth',\n",
       " 'objects',\n",
       " 'nuclear',\n",
       " 'increased',\n",
       " 'section',\n",
       " 'street',\n",
       " 'windows',\n",
       " 'relatively',\n",
       " 'car',\n",
       " 'move',\n",
       " 'create',\n",
       " 'returned',\n",
       " 'bank',\n",
       " 'conditions',\n",
       " 'operation',\n",
       " 'adopted',\n",
       " 'relationship',\n",
       " 'christ',\n",
       " 'hall',\n",
       " 'appear',\n",
       " 'rest',\n",
       " 'child',\n",
       " 'element',\n",
       " 'appears',\n",
       " 'takes',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<UNK>', 'the'),\n",
       " ('the', '<UNK>'),\n",
       " ('the', 'of'),\n",
       " ('the', 'and'),\n",
       " ('of', '<UNK>'),\n",
       " ('of', 'the'),\n",
       " ('of', 'and'),\n",
       " ('of', 'one'),\n",
       " ('and', 'the'),\n",
       " ('and', 'of'),\n",
       " ('and', 'one'),\n",
       " ('and', 'in'),\n",
       " ('one', 'of'),\n",
       " ('one', 'and'),\n",
       " ('one', 'in'),\n",
       " ('one', 'a'),\n",
       " ('in', 'and'),\n",
       " ('in', 'one'),\n",
       " ('in', 'a'),\n",
       " ('in', 'to'),\n",
       " ('a', 'one'),\n",
       " ('a', 'in'),\n",
       " ('a', 'to'),\n",
       " ('a', 'zero'),\n",
       " ('to', 'a'),\n",
       " ('to', 'zero'),\n",
       " ('zero', 'to'),\n",
       " ('zero', 'nine'),\n",
       " ('nine', 'zero'),\n",
       " ('nine', 'two'),\n",
       " ('two', 'nine'),\n",
       " ('two', 'is'),\n",
       " ('is', 'two'),\n",
       " ('is', 'as'),\n",
       " ('as', 'is'),\n",
       " ('as', 'eight'),\n",
       " ('eight', 'as'),\n",
       " ('eight', 'for'),\n",
       " ('for', 'as'),\n",
       " ('for', 'eight'),\n",
       " ('for', 's'),\n",
       " ('for', 'five'),\n",
       " ('s', 'for'),\n",
       " ('s', 'five'),\n",
       " ('five', 'for'),\n",
       " ('five', 's'),\n",
       " ('five', 'three'),\n",
       " ('five', 'was'),\n",
       " ('three', 'five'),\n",
       " ('three', 'was'),\n",
       " ('was', 'five'),\n",
       " ('was', 'three'),\n",
       " ('was', 'by'),\n",
       " ('was', 'that'),\n",
       " ('by', 'three'),\n",
       " ('by', 'was'),\n",
       " ('by', 'that'),\n",
       " ('by', 'four'),\n",
       " ('that', 'by'),\n",
       " ('that', 'four'),\n",
       " ('four', 'that'),\n",
       " ('four', 'six'),\n",
       " ('six', 'that'),\n",
       " ('six', 'four'),\n",
       " ('six', 'seven'),\n",
       " ('six', 'with'),\n",
       " ('seven', 'four'),\n",
       " ('seven', 'six'),\n",
       " ('seven', 'with'),\n",
       " ('seven', 'on'),\n",
       " ('with', 'six'),\n",
       " ('with', 'seven'),\n",
       " ('with', 'on'),\n",
       " ('with', 'are'),\n",
       " ('on', 'with'),\n",
       " ('on', 'are'),\n",
       " ('are', 'on'),\n",
       " ('are', 'it'),\n",
       " ('it', 'on'),\n",
       " ('it', 'are'),\n",
       " ('it', 'from'),\n",
       " ('it', 'or'),\n",
       " ('from', 'are'),\n",
       " ('from', 'it'),\n",
       " ('from', 'or'),\n",
       " ('from', 'his'),\n",
       " ('or', 'from'),\n",
       " ('or', 'his'),\n",
       " ('his', 'or'),\n",
       " ('his', 'an'),\n",
       " ('an', 'or'),\n",
       " ('an', 'his'),\n",
       " ('an', 'be'),\n",
       " ('an', 'this'),\n",
       " ('be', 'an'),\n",
       " ('be', 'this'),\n",
       " ('this', 'an'),\n",
       " ('this', 'be'),\n",
       " ('this', 'which'),\n",
       " ('this', 'at'),\n",
       " ('which', 'this'),\n",
       " ('which', 'at'),\n",
       " ('at', 'this'),\n",
       " ('at', 'which'),\n",
       " ('at', 'he'),\n",
       " ('at', 'also'),\n",
       " ('he', 'at'),\n",
       " ('he', 'also'),\n",
       " ('also', 'at'),\n",
       " ('also', 'he'),\n",
       " ('also', 'not'),\n",
       " ('also', 'have'),\n",
       " ('not', 'also'),\n",
       " ('not', 'have'),\n",
       " ('have', 'also'),\n",
       " ('have', 'not'),\n",
       " ('have', 'were'),\n",
       " ('have', 'has'),\n",
       " ('were', 'not'),\n",
       " ('were', 'have'),\n",
       " ('were', 'has'),\n",
       " ('were', 'but'),\n",
       " ('has', 'were'),\n",
       " ('has', 'but'),\n",
       " ('but', 'has'),\n",
       " ('but', 'other'),\n",
       " ('other', 'has'),\n",
       " ('other', 'but'),\n",
       " ('other', 'their'),\n",
       " ('other', 'its'),\n",
       " ('their', 'other'),\n",
       " ('their', 'its'),\n",
       " ('its', 'other'),\n",
       " ('its', 'their'),\n",
       " ('its', 'first'),\n",
       " ('its', 'they'),\n",
       " ('first', 'their'),\n",
       " ('first', 'its'),\n",
       " ('first', 'they'),\n",
       " ('first', 'some'),\n",
       " ('they', 'its'),\n",
       " ('they', 'first'),\n",
       " ('they', 'some'),\n",
       " ('they', 'had'),\n",
       " ('some', 'first'),\n",
       " ('some', 'they'),\n",
       " ('some', 'had'),\n",
       " ('some', 'all'),\n",
       " ('had', 'they'),\n",
       " ('had', 'some'),\n",
       " ('had', 'all'),\n",
       " ('had', 'more'),\n",
       " ('all', 'some'),\n",
       " ('all', 'had'),\n",
       " ('all', 'more'),\n",
       " ('all', 'most'),\n",
       " ('more', 'had'),\n",
       " ('more', 'all'),\n",
       " ('more', 'most'),\n",
       " ('more', 'can'),\n",
       " ('most', 'more'),\n",
       " ('most', 'can'),\n",
       " ('can', 'most'),\n",
       " ('can', 'been'),\n",
       " ('been', 'most'),\n",
       " ('been', 'can'),\n",
       " ('been', 'such'),\n",
       " ('been', 'many'),\n",
       " ('such', 'can'),\n",
       " ('such', 'been'),\n",
       " ('such', 'many'),\n",
       " ('such', 'who'),\n",
       " ('many', 'been'),\n",
       " ('many', 'such'),\n",
       " ('many', 'who'),\n",
       " ('many', 'new'),\n",
       " ('who', 'such'),\n",
       " ('who', 'many'),\n",
       " ('who', 'new'),\n",
       " ('who', 'used'),\n",
       " ('new', 'who'),\n",
       " ('new', 'used'),\n",
       " ('used', 'who'),\n",
       " ('used', 'new'),\n",
       " ('used', 'there'),\n",
       " ('used', 'after'),\n",
       " ('there', 'new'),\n",
       " ('there', 'used'),\n",
       " ('there', 'after'),\n",
       " ('there', 'when'),\n",
       " ('after', 'there'),\n",
       " ('after', 'when'),\n",
       " ('when', 'after'),\n",
       " ('when', 'into'),\n",
       " ('into', 'when'),\n",
       " ('into', 'american'),\n",
       " ('american', 'when'),\n",
       " ('american', 'into'),\n",
       " ('american', 'time'),\n",
       " ('american', 'these'),\n",
       " ('time', 'american'),\n",
       " ('time', 'these'),\n",
       " ('these', 'time'),\n",
       " ('these', 'only'),\n",
       " ('only', 'time'),\n",
       " ('only', 'these'),\n",
       " ('only', 'see'),\n",
       " ('only', 'may'),\n",
       " ('see', 'these'),\n",
       " ('see', 'only'),\n",
       " ('see', 'may'),\n",
       " ('see', 'than'),\n",
       " ('may', 'only'),\n",
       " ('may', 'see'),\n",
       " ('may', 'than'),\n",
       " ('may', 'world'),\n",
       " ('than', 'see'),\n",
       " ('than', 'may'),\n",
       " ('than', 'world'),\n",
       " ('than', 'i'),\n",
       " ('world', 'may'),\n",
       " ('world', 'than'),\n",
       " ('world', 'i'),\n",
       " ('world', 'b'),\n",
       " ('i', 'world'),\n",
       " ('i', 'b'),\n",
       " ('b', 'i'),\n",
       " ('b', 'would'),\n",
       " ('would', 'i'),\n",
       " ('would', 'b'),\n",
       " ('would', 'd'),\n",
       " ('would', 'no'),\n",
       " ('d', 'b'),\n",
       " ('d', 'would'),\n",
       " ('d', 'no'),\n",
       " ('d', 'however'),\n",
       " ('no', 'd'),\n",
       " ('no', 'however'),\n",
       " ('however', 'd'),\n",
       " ('however', 'no'),\n",
       " ('however', 'between'),\n",
       " ('however', 'about'),\n",
       " ('between', 'no'),\n",
       " ('between', 'however'),\n",
       " ('between', 'about'),\n",
       " ('between', 'over'),\n",
       " ('about', 'however'),\n",
       " ('about', 'between'),\n",
       " ('about', 'over'),\n",
       " ('about', 'years'),\n",
       " ('over', 'between'),\n",
       " ('over', 'about'),\n",
       " ('over', 'years'),\n",
       " ('over', 'states'),\n",
       " ('years', 'about'),\n",
       " ('years', 'over'),\n",
       " ('years', 'states'),\n",
       " ('years', 'people'),\n",
       " ('states', 'years'),\n",
       " ('states', 'people'),\n",
       " ('people', 'states'),\n",
       " ('people', 'war'),\n",
       " ('war', 'states'),\n",
       " ('war', 'people'),\n",
       " ('war', 'during'),\n",
       " ('war', 'united'),\n",
       " ('during', 'war'),\n",
       " ('during', 'united'),\n",
       " ('united', 'during'),\n",
       " ('united', 'known'),\n",
       " ('known', 'united'),\n",
       " ('known', 'if'),\n",
       " ('if', 'united'),\n",
       " ('if', 'known'),\n",
       " ('if', 'called'),\n",
       " ('if', 'use'),\n",
       " ('called', 'known'),\n",
       " ('called', 'if'),\n",
       " ('called', 'use'),\n",
       " ('called', 'th'),\n",
       " ('use', 'if'),\n",
       " ('use', 'called'),\n",
       " ('use', 'th'),\n",
       " ('use', 'system'),\n",
       " ('th', 'called'),\n",
       " ('th', 'use'),\n",
       " ('th', 'system'),\n",
       " ('th', 'often'),\n",
       " ('system', 'use'),\n",
       " ('system', 'th'),\n",
       " ('system', 'often'),\n",
       " ('system', 'state'),\n",
       " ('often', 'th'),\n",
       " ('often', 'system'),\n",
       " ('often', 'state'),\n",
       " ('often', 'so'),\n",
       " ('state', 'often'),\n",
       " ('state', 'so'),\n",
       " ('so', 'state'),\n",
       " ('so', 'history'),\n",
       " ('history', 'so'),\n",
       " ('history', 'will'),\n",
       " ('will', 'so'),\n",
       " ('will', 'history'),\n",
       " ('will', 'up'),\n",
       " ('will', 'while'),\n",
       " ('up', 'history'),\n",
       " ('up', 'will'),\n",
       " ('up', 'while'),\n",
       " ('up', 'where'),\n",
       " ('while', 'up'),\n",
       " ('while', 'where'),\n",
       " ('where', 'while'),\n",
       " ('where', 'city'),\n",
       " ('city', 'while'),\n",
       " ('city', 'where'),\n",
       " ('city', 'being'),\n",
       " ('city', 'english'),\n",
       " ('being', 'where'),\n",
       " ('being', 'city'),\n",
       " ('being', 'english'),\n",
       " ('being', 'then'),\n",
       " ('english', 'city'),\n",
       " ('english', 'being'),\n",
       " ('english', 'then'),\n",
       " ('english', 'any'),\n",
       " ('then', 'english'),\n",
       " ('then', 'any'),\n",
       " ('any', 'english'),\n",
       " ('any', 'then'),\n",
       " ('any', 'both'),\n",
       " ('any', 'under'),\n",
       " ('both', 'any'),\n",
       " ('both', 'under'),\n",
       " ('under', 'both'),\n",
       " ('under', 'out'),\n",
       " ('out', 'under'),\n",
       " ('out', 'made'),\n",
       " ('made', 'out'),\n",
       " ('made', 'well'),\n",
       " ('well', 'out'),\n",
       " ('well', 'made'),\n",
       " ('well', 'her'),\n",
       " ('well', 'e'),\n",
       " ('her', 'well'),\n",
       " ('her', 'e'),\n",
       " ('e', 'well'),\n",
       " ('e', 'her'),\n",
       " ('e', 'number'),\n",
       " ('e', 'government'),\n",
       " ('number', 'her'),\n",
       " ('number', 'e'),\n",
       " ('number', 'government'),\n",
       " ('number', 'them'),\n",
       " ('government', 'e'),\n",
       " ('government', 'number'),\n",
       " ('government', 'them'),\n",
       " ('government', 'm'),\n",
       " ('them', 'government'),\n",
       " ('them', 'm'),\n",
       " ('m', 'them'),\n",
       " ('m', 'later'),\n",
       " ('later', 'm'),\n",
       " ('later', 'since'),\n",
       " ('since', 'm'),\n",
       " ('since', 'later'),\n",
       " ('since', 'him'),\n",
       " ('since', 'part'),\n",
       " ('him', 'since'),\n",
       " ('him', 'part'),\n",
       " ('part', 'since'),\n",
       " ('part', 'him'),\n",
       " ('part', 'name'),\n",
       " ('part', 'c'),\n",
       " ('name', 'part'),\n",
       " ('name', 'c'),\n",
       " ('c', 'part'),\n",
       " ('c', 'name'),\n",
       " ('c', 'century'),\n",
       " ('c', 'through'),\n",
       " ('century', 'c'),\n",
       " ('century', 'through'),\n",
       " ('through', 'c'),\n",
       " ('through', 'century'),\n",
       " ('through', 'because'),\n",
       " ('through', 'x'),\n",
       " ('because', 'through'),\n",
       " ('because', 'x'),\n",
       " ('x', 'through'),\n",
       " ('x', 'because'),\n",
       " ('x', 'university'),\n",
       " ('x', 'early'),\n",
       " ('university', 'because'),\n",
       " ('university', 'x'),\n",
       " ('university', 'early'),\n",
       " ('university', 'life'),\n",
       " ('early', 'university'),\n",
       " ('early', 'life'),\n",
       " ('life', 'early'),\n",
       " ('life', 'british'),\n",
       " ('british', 'early'),\n",
       " ('british', 'life'),\n",
       " ('british', 'year'),\n",
       " ('british', 'like'),\n",
       " ('year', 'british'),\n",
       " ('year', 'like'),\n",
       " ('like', 'year'),\n",
       " ('like', 'same'),\n",
       " ('same', 'like'),\n",
       " ('same', 'including'),\n",
       " ('including', 'same'),\n",
       " ('including', 'became'),\n",
       " ('became', 'including'),\n",
       " ('became', 'example'),\n",
       " ('example', 'including'),\n",
       " ('example', 'became'),\n",
       " ('example', 'day'),\n",
       " ('example', 'each'),\n",
       " ('day', 'became'),\n",
       " ('day', 'example'),\n",
       " ('day', 'each'),\n",
       " ('day', 'even'),\n",
       " ('each', 'example'),\n",
       " ('each', 'day'),\n",
       " ('each', 'even'),\n",
       " ('each', 'work'),\n",
       " ('even', 'day'),\n",
       " ('even', 'each'),\n",
       " ('even', 'work'),\n",
       " ('even', 'language'),\n",
       " ('work', 'even'),\n",
       " ('work', 'language'),\n",
       " ('language', 'work'),\n",
       " ('language', 'although'),\n",
       " ('although', 'language'),\n",
       " ('although', 'several'),\n",
       " ('several', 'although'),\n",
       " ('several', 'form'),\n",
       " ('form', 'several'),\n",
       " ('form', 'john'),\n",
       " ('john', 'several'),\n",
       " ('john', 'form'),\n",
       " ('john', 'u'),\n",
       " ('john', 'national'),\n",
       " ('u', 'form'),\n",
       " ('u', 'john'),\n",
       " ('u', 'national'),\n",
       " ('u', 'very'),\n",
       " ('national', 'u'),\n",
       " ('national', 'very'),\n",
       " ('very', 'u'),\n",
       " ('very', 'national'),\n",
       " ('very', 'much'),\n",
       " ('very', 'g'),\n",
       " ('much', 'national'),\n",
       " ('much', 'very'),\n",
       " ('much', 'g'),\n",
       " ('much', 'french'),\n",
       " ('g', 'much'),\n",
       " ('g', 'french'),\n",
       " ('french', 'much'),\n",
       " ('french', 'g'),\n",
       " ('french', 'before'),\n",
       " ('french', 'general'),\n",
       " ('before', 'french'),\n",
       " ('before', 'general'),\n",
       " ('general', 'french'),\n",
       " ('general', 'before'),\n",
       " ('general', 'what'),\n",
       " ('general', 't'),\n",
       " ('what', 'before'),\n",
       " ('what', 'general'),\n",
       " ('what', 't'),\n",
       " ('what', 'against'),\n",
       " ('t', 'general'),\n",
       " ('t', 'what'),\n",
       " ('t', 'against'),\n",
       " ('t', 'n'),\n",
       " ('against', 't'),\n",
       " ('against', 'n'),\n",
       " ('n', 'against'),\n",
       " ('n', 'high'),\n",
       " ('high', 'against'),\n",
       " ('high', 'n'),\n",
       " ('high', 'links'),\n",
       " ('high', 'could'),\n",
       " ('links', 'n'),\n",
       " ('links', 'high'),\n",
       " ('links', 'could'),\n",
       " ('links', 'based'),\n",
       " ('could', 'links'),\n",
       " ('could', 'based'),\n",
       " ('based', 'links'),\n",
       " ('based', 'could'),\n",
       " ('based', 'those'),\n",
       " ('based', 'now'),\n",
       " ('those', 'could'),\n",
       " ('those', 'based'),\n",
       " ('those', 'now'),\n",
       " ('those', 'second'),\n",
       " ('now', 'based'),\n",
       " ('now', 'those'),\n",
       " ('now', 'second'),\n",
       " ('now', 'de'),\n",
       " ('second', 'now'),\n",
       " ('second', 'de'),\n",
       " ('de', 'now'),\n",
       " ('de', 'second'),\n",
       " ('de', 'music'),\n",
       " ('de', 'another'),\n",
       " ('music', 'second'),\n",
       " ('music', 'de'),\n",
       " ('music', 'another'),\n",
       " ('music', 'large'),\n",
       " ('another', 'music'),\n",
       " ('another', 'large'),\n",
       " ('large', 'another'),\n",
       " ('large', 'she'),\n",
       " ('she', 'another'),\n",
       " ('she', 'large'),\n",
       " ('she', 'f'),\n",
       " ('she', 'external'),\n",
       " ('f', 'she'),\n",
       " ('f', 'external'),\n",
       " ('external', 'f'),\n",
       " ('external', 'german'),\n",
       " ('german', 'f'),\n",
       " ('german', 'external'),\n",
       " ('german', 'different'),\n",
       " ('german', 'modern'),\n",
       " ('different', 'external'),\n",
       " ('different', 'german'),\n",
       " ('different', 'modern'),\n",
       " ('different', 'great'),\n",
       " ('modern', 'different'),\n",
       " ('modern', 'great'),\n",
       " ('great', 'different'),\n",
       " ('great', 'modern'),\n",
       " ('great', 'do'),\n",
       " ('great', 'common'),\n",
       " ('do', 'modern'),\n",
       " ('do', 'great'),\n",
       " ('do', 'common'),\n",
       " ('do', 'set'),\n",
       " ('common', 'do'),\n",
       " ('common', 'set'),\n",
       " ('set', 'do'),\n",
       " ('set', 'common'),\n",
       " ('set', 'list'),\n",
       " ('set', 'south'),\n",
       " ('list', 'set'),\n",
       " ('list', 'south'),\n",
       " ('south', 'set'),\n",
       " ('south', 'list'),\n",
       " ('south', 'series'),\n",
       " ('south', 'major'),\n",
       " ('series', 'list'),\n",
       " ('series', 'south'),\n",
       " ('series', 'major'),\n",
       " ('series', 'game'),\n",
       " ('major', 'series'),\n",
       " ('major', 'game'),\n",
       " ('game', 'major'),\n",
       " ('game', 'power'),\n",
       " ('power', 'major'),\n",
       " ('power', 'game'),\n",
       " ('power', 'long'),\n",
       " ('power', 'country'),\n",
       " ('long', 'game'),\n",
       " ('long', 'power'),\n",
       " ('long', 'country'),\n",
       " ('long', 'king'),\n",
       " ('country', 'long'),\n",
       " ('country', 'king'),\n",
       " ('king', 'long'),\n",
       " ('king', 'country'),\n",
       " ('king', 'law'),\n",
       " ('king', 'group'),\n",
       " ('law', 'country'),\n",
       " ('law', 'king'),\n",
       " ('law', 'group'),\n",
       " ('law', 'film'),\n",
       " ('group', 'king'),\n",
       " ('group', 'law'),\n",
       " ('group', 'film'),\n",
       " ('group', 'still'),\n",
       " ('film', 'law'),\n",
       " ('film', 'group'),\n",
       " ('film', 'still'),\n",
       " ('film', 'until'),\n",
       " ('still', 'group'),\n",
       " ('still', 'film'),\n",
       " ('still', 'until'),\n",
       " ('still', 'north'),\n",
       " ('until', 'still'),\n",
       " ('until', 'north'),\n",
       " ('north', 'still'),\n",
       " ('north', 'until'),\n",
       " ('north', 'international'),\n",
       " ('north', 'term'),\n",
       " ('international', 'north'),\n",
       " ('international', 'term'),\n",
       " ('term', 'north'),\n",
       " ('term', 'international'),\n",
       " ('term', 'we'),\n",
       " ('term', 'end'),\n",
       " ('we', 'international'),\n",
       " ('we', 'term'),\n",
       " ('we', 'end'),\n",
       " ('we', 'book'),\n",
       " ('end', 'term'),\n",
       " ('end', 'we'),\n",
       " ('end', 'book'),\n",
       " ('end', 'found'),\n",
       " ('book', 'we'),\n",
       " ('book', 'end'),\n",
       " ('book', 'found'),\n",
       " ('book', 'own'),\n",
       " ('found', 'end'),\n",
       " ('found', 'book'),\n",
       " ('found', 'own'),\n",
       " ('found', 'political'),\n",
       " ('own', 'book'),\n",
       " ('own', 'found'),\n",
       " ('own', 'political'),\n",
       " ('own', 'party'),\n",
       " ('political', 'found'),\n",
       " ('political', 'own'),\n",
       " ('political', 'party'),\n",
       " ('political', 'order'),\n",
       " ('party', 'political'),\n",
       " ('party', 'order'),\n",
       " ('order', 'party'),\n",
       " ('order', 'usually'),\n",
       " ('usually', 'party'),\n",
       " ('usually', 'order'),\n",
       " ('usually', 'president'),\n",
       " ('usually', 'church'),\n",
       " ('president', 'order'),\n",
       " ('president', 'usually'),\n",
       " ('president', 'church'),\n",
       " ('president', 'you'),\n",
       " ('church', 'president'),\n",
       " ('church', 'you'),\n",
       " ('you', 'president'),\n",
       " ('you', 'church'),\n",
       " ('you', 'death'),\n",
       " ('you', 'theory'),\n",
       " ('death', 'you'),\n",
       " ('death', 'theory'),\n",
       " ('theory', 'death'),\n",
       " ('theory', 'area'),\n",
       " ('area', 'theory'),\n",
       " ('area', 'around'),\n",
       " ('around', 'theory'),\n",
       " ('around', 'area'),\n",
       " ('around', 'include'),\n",
       " ('around', 'god'),\n",
       " ('include', 'area'),\n",
       " ('include', 'around'),\n",
       " ('include', 'god'),\n",
       " ('include', 'ii'),\n",
       " ('god', 'around'),\n",
       " ('god', 'include'),\n",
       " ('god', 'ii'),\n",
       " ('god', 'way'),\n",
       " ('ii', 'include'),\n",
       " ('ii', 'god'),\n",
       " ('ii', 'way'),\n",
       " ('ii', 'did'),\n",
       " ('way', 'ii'),\n",
       " ('way', 'did'),\n",
       " ('did', 'ii'),\n",
       " ('did', 'way'),\n",
       " ('did', 'military'),\n",
       " ('did', 'population'),\n",
       " ('military', 'did'),\n",
       " ('military', 'population'),\n",
       " ('population', 'did'),\n",
       " ('population', 'military'),\n",
       " ('population', 'using'),\n",
       " ('population', 'though'),\n",
       " ('using', 'military'),\n",
       " ('using', 'population'),\n",
       " ('using', 'though'),\n",
       " ('using', 'small'),\n",
       " ('though', 'population'),\n",
       " ('though', 'using'),\n",
       " ('though', 'small'),\n",
       " ('though', 'following'),\n",
       " ('small', 'using'),\n",
       " ('small', 'though'),\n",
       " ('small', 'following'),\n",
       " ('small', 'within'),\n",
       " ('following', 'though'),\n",
       " ('following', 'small'),\n",
       " ('following', 'within'),\n",
       " ('following', 'non'),\n",
       " ('within', 'following'),\n",
       " ('within', 'non'),\n",
       " ('non', 'following'),\n",
       " ('non', 'within'),\n",
       " ('non', 'human'),\n",
       " ('non', 'left'),\n",
       " ('human', 'within'),\n",
       " ('human', 'non'),\n",
       " ('human', 'left'),\n",
       " ('human', 'main'),\n",
       " ('left', 'human'),\n",
       " ('left', 'main'),\n",
       " ('main', 'left'),\n",
       " ('main', 'among'),\n",
       " ('among', 'left'),\n",
       " ('among', 'main'),\n",
       " ('among', 'point'),\n",
       " ('among', 'r'),\n",
       " ('point', 'main'),\n",
       " ('point', 'among'),\n",
       " ('point', 'r'),\n",
       " ('point', 'due'),\n",
       " ('r', 'point'),\n",
       " ('r', 'due'),\n",
       " ('due', 'r'),\n",
       " ('due', 'p'),\n",
       " ('p', 'due'),\n",
       " ('p', 'considered'),\n",
       " ('considered', 'p'),\n",
       " ('considered', 'public'),\n",
       " ('public', 'p'),\n",
       " ('public', 'considered'),\n",
       " ('public', 'popular'),\n",
       " ('public', 'computer'),\n",
       " ('popular', 'public'),\n",
       " ('popular', 'computer'),\n",
       " ('computer', 'public'),\n",
       " ('computer', 'popular'),\n",
       " ('computer', 'west'),\n",
       " ('computer', 'family'),\n",
       " ('west', 'popular'),\n",
       " ('west', 'computer'),\n",
       " ('west', 'family'),\n",
       " ('west', 'east'),\n",
       " ('family', 'west'),\n",
       " ('family', 'east'),\n",
       " ('east', 'west'),\n",
       " ('east', 'family'),\n",
       " ('east', 'information'),\n",
       " ('east', 'important'),\n",
       " ('information', 'family'),\n",
       " ('information', 'east'),\n",
       " ('information', 'important'),\n",
       " ('information', 'european'),\n",
       " ('important', 'east'),\n",
       " ('important', 'information'),\n",
       " ('important', 'european'),\n",
       " ('important', 'man'),\n",
       " ('european', 'information'),\n",
       " ('european', 'important'),\n",
       " ('european', 'man'),\n",
       " ('european', 'sometimes'),\n",
       " ('man', 'european'),\n",
       " ('man', 'sometimes'),\n",
       " ('sometimes', 'man'),\n",
       " ('sometimes', 'right'),\n",
       " ('right', 'sometimes'),\n",
       " ('right', 'old'),\n",
       " ('old', 'right'),\n",
       " ('old', 'free'),\n",
       " ('free', 'right'),\n",
       " ('free', 'old'),\n",
       " ('free', 'word'),\n",
       " ('free', 'without'),\n",
       " ('word', 'old'),\n",
       " ('word', 'free'),\n",
       " ('word', 'without'),\n",
       " ('word', 'last'),\n",
       " ('without', 'word'),\n",
       " ('without', 'last'),\n",
       " ('last', 'word'),\n",
       " ('last', 'without'),\n",
       " ('last', 'us'),\n",
       " ('last', 'members'),\n",
       " ('us', 'last'),\n",
       " ('us', 'members'),\n",
       " ('members', 'last'),\n",
       " ('members', 'us'),\n",
       " ('members', 'given'),\n",
       " ('members', 'times'),\n",
       " ('given', 'us'),\n",
       " ('given', 'members'),\n",
       " ('given', 'times'),\n",
       " ('given', 'roman'),\n",
       " ('times', 'members'),\n",
       " ('times', 'given'),\n",
       " ('times', 'roman'),\n",
       " ('times', 'make'),\n",
       " ('roman', 'times'),\n",
       " ('roman', 'make'),\n",
       " ('make', 'roman'),\n",
       " ('make', 'h'),\n",
       " ('h', 'roman'),\n",
       " ('h', 'make'),\n",
       " ('h', 'age'),\n",
       " ('h', 'place'),\n",
       " ('age', 'h'),\n",
       " ('age', 'place'),\n",
       " ('place', 'age'),\n",
       " ('place', 'l'),\n",
       " ('l', 'place'),\n",
       " ('l', 'thus'),\n",
       " ('thus', 'place'),\n",
       " ('thus', 'l'),\n",
       " ('thus', 'science'),\n",
       " ('thus', 'case'),\n",
       " ('science', 'thus'),\n",
       " ('science', 'case'),\n",
       " ('case', 'thus'),\n",
       " ('case', 'science'),\n",
       " ('case', 'become'),\n",
       " ('case', 'systems'),\n",
       " ('become', 'case'),\n",
       " ('become', 'systems'),\n",
       " ('systems', 'case'),\n",
       " ('systems', 'become'),\n",
       " ('systems', 'union'),\n",
       " ('systems', 'born'),\n",
       " ('union', 'become'),\n",
       " ('union', 'systems'),\n",
       " ('union', 'born'),\n",
       " ('union', 'york'),\n",
       " ('born', 'union'),\n",
       " ('born', 'york'),\n",
       " ('york', 'born'),\n",
       " ('york', 'line'),\n",
       " ('line', 'york'),\n",
       " ('line', 'countries'),\n",
       " ('countries', 'york'),\n",
       " ('countries', 'line'),\n",
       " ('countries', 'does'),\n",
       " ('countries', 'isbn'),\n",
       " ('does', 'line'),\n",
       " ('does', 'countries'),\n",
       " ('does', 'isbn'),\n",
       " ('does', 'st'),\n",
       " ('isbn', 'does'),\n",
       " ('isbn', 'st'),\n",
       " ('st', 'does'),\n",
       " ('st', 'isbn'),\n",
       " ('st', 'control'),\n",
       " ('st', 'various'),\n",
       " ('control', 'isbn'),\n",
       " ('control', 'st'),\n",
       " ('control', 'various'),\n",
       " ('control', 'others'),\n",
       " ('various', 'control'),\n",
       " ('various', 'others'),\n",
       " ('others', 'various'),\n",
       " ('others', 'house'),\n",
       " ('house', 'others'),\n",
       " ('house', 'article'),\n",
       " ('article', 'others'),\n",
       " ('article', 'house'),\n",
       " ('article', 'island'),\n",
       " ('article', 'should'),\n",
       " ('island', 'house'),\n",
       " ('island', 'article'),\n",
       " ('island', 'should'),\n",
       " ('island', 'led'),\n",
       " ('should', 'article'),\n",
       " ('should', 'island'),\n",
       " ('should', 'led'),\n",
       " ('should', 'back'),\n",
       " ('led', 'should'),\n",
       " ('led', 'back'),\n",
       " ('back', 'should'),\n",
       " ('back', 'led'),\n",
       " ('back', 'period'),\n",
       " ('back', 'player'),\n",
       " ('period', 'led'),\n",
       " ('period', 'back'),\n",
       " ('period', 'player'),\n",
       " ('period', 'europe'),\n",
       " ('player', 'period'),\n",
       " ('player', 'europe'),\n",
       " ('europe', 'period'),\n",
       " ('europe', 'player'),\n",
       " ('europe', 'languages'),\n",
       " ('europe', 'central'),\n",
       " ('languages', 'europe'),\n",
       " ('languages', 'central'),\n",
       " ('central', 'languages'),\n",
       " ('central', 'water'),\n",
       " ('water', 'languages'),\n",
       " ('water', 'central'),\n",
       " ('water', 'few'),\n",
       " ('water', 'western'),\n",
       " ('few', 'water'),\n",
       " ('few', 'western'),\n",
       " ('western', 'few'),\n",
       " ('western', 'home'),\n",
       " ('home', 'few'),\n",
       " ('home', 'western'),\n",
       " ('home', 'began'),\n",
       " ('home', 'generally'),\n",
       " ('began', 'home'),\n",
       " ('began', 'generally'),\n",
       " ('generally', 'home'),\n",
       " ('generally', 'began'),\n",
       " ('generally', 'less'),\n",
       " ('generally', 'k'),\n",
       " ('less', 'generally'),\n",
       " ('less', 'k'),\n",
       " ('k', 'less'),\n",
       " ('k', 'similar'),\n",
       " ('similar', 'k'),\n",
       " ('similar', 'written'),\n",
       " ('written', 'k'),\n",
       " ('written', 'similar'),\n",
       " ('written', 'original'),\n",
       " ('written', 'best'),\n",
       " ('original', 'written'),\n",
       " ('original', 'best'),\n",
       " ('best', 'original'),\n",
       " ('best', 'must'),\n",
       " ('must', 'best'),\n",
       " ('must', 'according'),\n",
       " ('according', 'must'),\n",
       " ('according', 'school'),\n",
       " ('school', 'must'),\n",
       " ('school', 'according'),\n",
       " ('school', 'france'),\n",
       " ('school', 'air'),\n",
       " ('france', 'school'),\n",
       " ('france', 'air'),\n",
       " ('air', 'school'),\n",
       " ('air', 'france'),\n",
       " ('air', 'single'),\n",
       " ('air', 'force'),\n",
       " ('single', 'france'),\n",
       " ('single', 'air'),\n",
       " ('single', 'force'),\n",
       " ('single', 'v'),\n",
       " ('force', 'single'),\n",
       " ('force', 'v'),\n",
       " ('v', 'single'),\n",
       " ('v', 'force'),\n",
       " ('v', 'land'),\n",
       " ('v', 'groups'),\n",
       " ('land', 'force'),\n",
       " ('land', 'v'),\n",
       " ('land', 'groups'),\n",
       " ('land', 'down'),\n",
       " ('groups', 'v'),\n",
       " ('groups', 'land'),\n",
       " ('groups', 'down'),\n",
       " ('groups', 'how'),\n",
       " ('down', 'groups'),\n",
       " ('down', 'how'),\n",
       " ('how', 'down'),\n",
       " ('how', 'works'),\n",
       " ('works', 'down'),\n",
       " ('works', 'how'),\n",
       " ('works', 'development'),\n",
       " ('works', 'official'),\n",
       " ('development', 'works'),\n",
       " ('development', 'official'),\n",
       " ('official', 'works'),\n",
       " ('official', 'development'),\n",
       " ('official', 'support'),\n",
       " ('official', 'england'),\n",
       " ('support', 'official'),\n",
       " ('support', 'england'),\n",
       " ('england', 'official'),\n",
       " ('england', 'support'),\n",
       " ('england', 'j'),\n",
       " ('england', 'rather'),\n",
       " ('j', 'support'),\n",
       " ('j', 'england'),\n",
       " ('j', 'rather'),\n",
       " ('j', 'data'),\n",
       " ('rather', 'england'),\n",
       " ('rather', 'j'),\n",
       " ('rather', 'data'),\n",
       " ('rather', 'space'),\n",
       " ('data', 'j'),\n",
       " ('data', 'rather'),\n",
       " ('data', 'space'),\n",
       " ('data', 'greek'),\n",
       " ('space', 'data'),\n",
       " ('space', 'greek'),\n",
       " ('greek', 'data'),\n",
       " ('greek', 'space'),\n",
       " ('greek', 'km'),\n",
       " ('greek', 'named'),\n",
       " ('km', 'space'),\n",
       " ('km', 'greek'),\n",
       " ('km', 'named'),\n",
       " ('km', 'germany'),\n",
       " ('named', 'km'),\n",
       " ('named', 'germany'),\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check how the data looks\n",
    "list(zip(features, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "features = np.asarray(features)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from word2vec import Word2Vec, Word2VecConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = Word2VecConfig(vocab_size=50000,\n",
    "                 words_vocab_file=\"tmp/vocab.tsv\",\n",
    "                 embedding_size=128,\n",
    "                 num_word_sample=64,\n",
    "                 learning_rate=0.001,\n",
    "                 word_emd_size=128,\n",
    "                 model_dir=\"tmp/model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'tmp/model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd288e33d68>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<bound method Word2Vec._model_fn of <word2vec.Word2Vec object at 0x7fd28a30b9e8>>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data.glove_data_iterator import setup_input_graph\n",
    "input_fn, intput_hook = setup_input_graph(features, labels, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58700"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "MAX_STEPS = (features.shape[0] // BATCH_SIZE) * NUM_EPOCHS\n",
    "\n",
    "MAX_STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_hook = model.get_store_hook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:table info: <tensorflow.python.ops.lookup_ops.HashTable object at 0x7efc9aacb710>\n",
      "INFO:tensorflow:center_word_ids -----> Tensor(\"center-words-2-ids/hash_table_Lookup:0\", shape=(?, ?), dtype=int64)\n",
      "INFO:tensorflow:table info: <tensorflow.python.ops.lookup_ops.HashTable object at 0x7efc993419e8>\n",
      "INFO:tensorflow:target_word_ids -----> Tensor(\"target-words-2-ids/Reshape:0\", shape=(?, 1), dtype=int64)\n",
      "INFO:tensorflow:embed_matrix -----> <tf.Variable 'embed/embed_matrix:0' shape=(50000, 128) dtype=float32_ref>\n",
      "INFO:tensorflow:embed -----> Tensor(\"loss/embed:0\", dtype=float32)\n",
      "INFO:tensorflow:nce_weight -----> <tf.Variable 'loss/nce_weight:0' shape=(50000, 128) dtype=float32_ref>\n",
      "INFO:tensorflow:nce_bias -----> <tf.Variable 'loss/nce_bias:0' shape=(50000,) dtype=float32_ref>\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tmp/model/model.ckpt-5870\n",
      "INFO:tensorflow:Saving checkpoints for 5871 into tmp/model/model.ckpt.\n",
      "INFO:tensorflow:loss = 252.566, step = 5871\n",
      "INFO:tensorflow:global_step/sec: 244.163\n",
      "INFO:tensorflow:loss = 248.048, step = 5971 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.455\n",
      "INFO:tensorflow:loss = 235.557, step = 6071 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.806\n",
      "INFO:tensorflow:loss = 261.505, step = 6171 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.076\n",
      "INFO:tensorflow:loss = 240.56, step = 6271 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.406\n",
      "INFO:tensorflow:loss = 288.75, step = 6371 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.211\n",
      "INFO:tensorflow:loss = 276.638, step = 6471 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.151\n",
      "INFO:tensorflow:loss = 263.534, step = 6571 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.265\n",
      "INFO:tensorflow:loss = 257.003, step = 6671 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.171\n",
      "INFO:tensorflow:loss = 288.778, step = 6771 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.152\n",
      "INFO:tensorflow:loss = 232.275, step = 6871 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.277\n",
      "INFO:tensorflow:loss = 286.076, step = 6971 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.002\n",
      "INFO:tensorflow:loss = 273.573, step = 7071 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.045\n",
      "INFO:tensorflow:loss = 282.404, step = 7171 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.825\n",
      "INFO:tensorflow:loss = 278.578, step = 7271 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.432\n",
      "INFO:tensorflow:loss = 265.905, step = 7371 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.342\n",
      "INFO:tensorflow:loss = 248.298, step = 7471 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.591\n",
      "INFO:tensorflow:loss = 280.842, step = 7571 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.602\n",
      "INFO:tensorflow:loss = 253.915, step = 7671 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.235\n",
      "INFO:tensorflow:loss = 268.024, step = 7771 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.271\n",
      "INFO:tensorflow:loss = 271.56, step = 7871 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.152\n",
      "INFO:tensorflow:loss = 287.238, step = 7971 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.074\n",
      "INFO:tensorflow:loss = 271.776, step = 8071 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.549\n",
      "INFO:tensorflow:loss = 277.016, step = 8171 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.758\n",
      "INFO:tensorflow:loss = 293.426, step = 8271 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.074\n",
      "INFO:tensorflow:loss = 280.526, step = 8371 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.43\n",
      "INFO:tensorflow:loss = 243.154, step = 8471 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.781\n",
      "INFO:tensorflow:loss = 243.957, step = 8571 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.991\n",
      "INFO:tensorflow:loss = 271.436, step = 8671 (0.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.236\n",
      "INFO:tensorflow:loss = 259.113, step = 8771 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.537\n",
      "INFO:tensorflow:loss = 250.312, step = 8871 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.259\n",
      "INFO:tensorflow:loss = 221.433, step = 8971 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.956\n",
      "INFO:tensorflow:loss = 272.116, step = 9071 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.685\n",
      "INFO:tensorflow:loss = 250.336, step = 9171 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.667\n",
      "INFO:tensorflow:loss = 284.934, step = 9271 (0.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.392\n",
      "INFO:tensorflow:loss = 268.648, step = 9371 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.997\n",
      "INFO:tensorflow:loss = 238.297, step = 9471 (0.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.356\n",
      "INFO:tensorflow:loss = 278.281, step = 9571 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.454\n",
      "INFO:tensorflow:loss = 302.006, step = 9671 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.935\n",
      "INFO:tensorflow:loss = 234.061, step = 9771 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.024\n",
      "INFO:tensorflow:loss = 277.478, step = 9871 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.21\n",
      "INFO:tensorflow:loss = 288.508, step = 9971 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.158\n",
      "INFO:tensorflow:loss = 281.266, step = 10071 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.016\n",
      "INFO:tensorflow:loss = 255.106, step = 10171 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.543\n",
      "INFO:tensorflow:loss = 252.312, step = 10271 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.728\n",
      "INFO:tensorflow:loss = 270.006, step = 10371 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.58\n",
      "INFO:tensorflow:loss = 241.08, step = 10471 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.052\n",
      "INFO:tensorflow:loss = 245.223, step = 10571 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.897\n",
      "INFO:tensorflow:loss = 276.943, step = 10671 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.316\n",
      "INFO:tensorflow:loss = 293.295, step = 10771 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.302\n",
      "INFO:tensorflow:loss = 240.893, step = 10871 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.994\n",
      "INFO:tensorflow:loss = 267.851, step = 10971 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.791\n",
      "INFO:tensorflow:loss = 245.067, step = 11071 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.231\n",
      "INFO:tensorflow:loss = 232.828, step = 11171 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.485\n",
      "INFO:tensorflow:loss = 241.667, step = 11271 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.022\n",
      "INFO:tensorflow:loss = 265.385, step = 11371 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.096\n",
      "INFO:tensorflow:loss = 242.044, step = 11471 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.084\n",
      "INFO:tensorflow:loss = 284.213, step = 11571 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.892\n",
      "INFO:tensorflow:loss = 241.393, step = 11671 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.155\n",
      "INFO:tensorflow:loss = 270.505, step = 11771 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.03\n",
      "INFO:tensorflow:loss = 248.319, step = 11871 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.97\n",
      "INFO:tensorflow:loss = 254.838, step = 11971 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.67\n",
      "INFO:tensorflow:loss = 261.361, step = 12071 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.433\n",
      "INFO:tensorflow:loss = 240.327, step = 12171 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.06\n",
      "INFO:tensorflow:loss = 243.715, step = 12271 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.696\n",
      "INFO:tensorflow:loss = 233.355, step = 12371 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.722\n",
      "INFO:tensorflow:loss = 275.109, step = 12471 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.972\n",
      "INFO:tensorflow:loss = 258.447, step = 12571 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.078\n",
      "INFO:tensorflow:loss = 262.354, step = 12671 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.463\n",
      "INFO:tensorflow:loss = 237.475, step = 12771 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.88\n",
      "INFO:tensorflow:loss = 256.907, step = 12871 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.661\n",
      "INFO:tensorflow:loss = 269.447, step = 12971 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.471\n",
      "INFO:tensorflow:loss = 307.778, step = 13071 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.5\n",
      "INFO:tensorflow:loss = 248.465, step = 13171 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.315\n",
      "INFO:tensorflow:loss = 263.986, step = 13271 (0.385 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 261.361\n",
      "INFO:tensorflow:loss = 254.329, step = 13371 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.151\n",
      "INFO:tensorflow:loss = 253.573, step = 13471 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.817\n",
      "INFO:tensorflow:loss = 223.682, step = 13571 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.721\n",
      "INFO:tensorflow:loss = 265.168, step = 13671 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.589\n",
      "INFO:tensorflow:loss = 258.455, step = 13771 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.555\n",
      "INFO:tensorflow:loss = 222.901, step = 13871 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.59\n",
      "INFO:tensorflow:loss = 237.902, step = 13971 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.165\n",
      "INFO:tensorflow:loss = 241.825, step = 14071 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.856\n",
      "INFO:tensorflow:loss = 237.771, step = 14171 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.141\n",
      "INFO:tensorflow:loss = 258.881, step = 14271 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.529\n",
      "INFO:tensorflow:loss = 269.842, step = 14371 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.242\n",
      "INFO:tensorflow:loss = 263.352, step = 14471 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.441\n",
      "INFO:tensorflow:loss = 270.484, step = 14571 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.684\n",
      "INFO:tensorflow:loss = 254.224, step = 14671 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.371\n",
      "INFO:tensorflow:loss = 226.691, step = 14771 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.183\n",
      "INFO:tensorflow:loss = 265.618, step = 14871 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.747\n",
      "INFO:tensorflow:loss = 309.732, step = 14971 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.945\n",
      "INFO:tensorflow:loss = 239.41, step = 15071 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.136\n",
      "INFO:tensorflow:loss = 241.349, step = 15171 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.336\n",
      "INFO:tensorflow:loss = 250.089, step = 15271 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.107\n",
      "INFO:tensorflow:loss = 218.239, step = 15371 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.795\n",
      "INFO:tensorflow:loss = 261.645, step = 15471 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.08\n",
      "INFO:tensorflow:loss = 254.109, step = 15571 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.717\n",
      "INFO:tensorflow:loss = 232.915, step = 15671 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.998\n",
      "INFO:tensorflow:loss = 265.872, step = 15771 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.947\n",
      "INFO:tensorflow:loss = 235.514, step = 15871 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.119\n",
      "INFO:tensorflow:loss = 232.492, step = 15971 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.285\n",
      "INFO:tensorflow:loss = 282.532, step = 16071 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.431\n",
      "INFO:tensorflow:loss = 302.241, step = 16171 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.847\n",
      "INFO:tensorflow:loss = 262.07, step = 16271 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.79\n",
      "INFO:tensorflow:loss = 242.588, step = 16371 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.382\n",
      "INFO:tensorflow:loss = 238.306, step = 16471 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.099\n",
      "INFO:tensorflow:loss = 237.747, step = 16571 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.663\n",
      "INFO:tensorflow:loss = 255.383, step = 16671 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.391\n",
      "INFO:tensorflow:loss = 267.949, step = 16771 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.299\n",
      "INFO:tensorflow:loss = 280.225, step = 16871 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.086\n",
      "INFO:tensorflow:loss = 245.89, step = 16971 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.995\n",
      "INFO:tensorflow:loss = 266.495, step = 17071 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.548\n",
      "INFO:tensorflow:loss = 261.205, step = 17171 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.715\n",
      "INFO:tensorflow:loss = 258.564, step = 17271 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.886\n",
      "INFO:tensorflow:loss = 277.287, step = 17371 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.011\n",
      "INFO:tensorflow:loss = 254.094, step = 17471 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.021\n",
      "INFO:tensorflow:loss = 266.675, step = 17571 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.994\n",
      "INFO:tensorflow:loss = 213.782, step = 17671 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.28\n",
      "INFO:tensorflow:loss = 241.96, step = 17771 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.139\n",
      "INFO:tensorflow:loss = 277.525, step = 17871 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.412\n",
      "INFO:tensorflow:loss = 271.405, step = 17971 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.096\n",
      "INFO:tensorflow:loss = 240.674, step = 18071 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.238\n",
      "INFO:tensorflow:loss = 262.284, step = 18171 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.868\n",
      "INFO:tensorflow:loss = 230.93, step = 18271 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.051\n",
      "INFO:tensorflow:loss = 264.09, step = 18371 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.957\n",
      "INFO:tensorflow:loss = 266.246, step = 18471 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.973\n",
      "INFO:tensorflow:loss = 227.11, step = 18571 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.244\n",
      "INFO:tensorflow:loss = 252.943, step = 18671 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.632\n",
      "INFO:tensorflow:loss = 223.065, step = 18771 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.464\n",
      "INFO:tensorflow:loss = 253.259, step = 18871 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.818\n",
      "INFO:tensorflow:loss = 291.286, step = 18971 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.724\n",
      "INFO:tensorflow:loss = 255.692, step = 19071 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.77\n",
      "INFO:tensorflow:loss = 265.868, step = 19171 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.962\n",
      "INFO:tensorflow:loss = 227.143, step = 19271 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.378\n",
      "INFO:tensorflow:loss = 237.962, step = 19371 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.135\n",
      "INFO:tensorflow:loss = 250.651, step = 19471 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.037\n",
      "INFO:tensorflow:loss = 243.261, step = 19571 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.703\n",
      "INFO:tensorflow:loss = 241.208, step = 19671 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.431\n",
      "INFO:tensorflow:loss = 242.897, step = 19771 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.044\n",
      "INFO:tensorflow:loss = 263.266, step = 19871 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.052\n",
      "INFO:tensorflow:loss = 241.508, step = 19971 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.464\n",
      "INFO:tensorflow:loss = 240.319, step = 20071 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.327\n",
      "INFO:tensorflow:loss = 261.845, step = 20171 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.106\n",
      "INFO:tensorflow:loss = 245.93, step = 20271 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.434\n",
      "INFO:tensorflow:loss = 265.635, step = 20371 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.459\n",
      "INFO:tensorflow:loss = 276.093, step = 20471 (0.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.118\n",
      "INFO:tensorflow:loss = 252.766, step = 20571 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.261\n",
      "INFO:tensorflow:loss = 241.2, step = 20671 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.011\n",
      "INFO:tensorflow:loss = 269.266, step = 20771 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.306\n",
      "INFO:tensorflow:loss = 238.363, step = 20871 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.349\n",
      "INFO:tensorflow:loss = 291.768, step = 20971 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.994\n",
      "INFO:tensorflow:loss = 247.606, step = 21071 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.909\n",
      "INFO:tensorflow:loss = 238.745, step = 21171 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.927\n",
      "INFO:tensorflow:loss = 233.35, step = 21271 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.186\n",
      "INFO:tensorflow:loss = 267.972, step = 21371 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.159\n",
      "INFO:tensorflow:loss = 263.783, step = 21471 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.07\n",
      "INFO:tensorflow:loss = 252.405, step = 21571 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.212\n",
      "INFO:tensorflow:loss = 253.303, step = 21671 (0.379 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 258.091\n",
      "INFO:tensorflow:loss = 291.844, step = 21771 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.709\n",
      "INFO:tensorflow:loss = 266.602, step = 21871 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.23\n",
      "INFO:tensorflow:loss = 202.356, step = 21971 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.836\n",
      "INFO:tensorflow:loss = 246.384, step = 22071 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.321\n",
      "INFO:tensorflow:loss = 243.255, step = 22171 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.862\n",
      "INFO:tensorflow:loss = 276.518, step = 22271 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.973\n",
      "INFO:tensorflow:loss = 245.046, step = 22371 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.036\n",
      "INFO:tensorflow:loss = 224.764, step = 22471 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.828\n",
      "INFO:tensorflow:loss = 233.782, step = 22571 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.72\n",
      "INFO:tensorflow:loss = 277.177, step = 22671 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.604\n",
      "INFO:tensorflow:loss = 250.71, step = 22771 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.409\n",
      "INFO:tensorflow:loss = 256.495, step = 22871 (0.388 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-5a3f2d2439ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mintput_hook\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_STEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    519\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    890\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    893\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(input_fn=input_fn, hooks=[intput_hook, store_hook], steps=MAX_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import word_vec.utils.common as common\n",
    "word_2_id, id_2_word = common.tsv_to_vocab(\"tmp/vocab.tsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "final_embeddings = np.load(\"tmp/embed_mat.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw visualization of distance between embeddings.\n",
    "def plot_with_labels(low_dim_embs, labels, filename):\n",
    "  assert low_dim_embs.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "  plt.figure(figsize=(18, 18))  # in inches\n",
    "  for i, label in enumerate(labels):\n",
    "    x, y = low_dim_embs[i, :]\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(label,\n",
    "                 xy=(x, y),\n",
    "                 xytext=(5, 2),\n",
    "                 textcoords='offset points',\n",
    "                 ha='right',\n",
    "                 va='bottom')\n",
    "\n",
    "  plt.savefig(filename)\n",
    "\n",
    "try:\n",
    "  # pylint: disable=g-import-not-at-top\n",
    "  from sklearn.manifold import TSNE\n",
    "  import matplotlib.pyplot as plt\n",
    "\n",
    "  tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000, method='exact')\n",
    "  plot_only = 500\n",
    "  low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only, :])\n",
    "  labels = [id_2_word[i] for i in range(plot_only)]\n",
    "  plot_with_labels(low_dim_embs, labels, os.path.join(\"tmp/\", 'tsne.png'))\n",
    "\n",
    "except ImportError as ex:\n",
    "  print('Please install sklearn, matplotlib, and scipy to show embeddings.')\n",
    "  print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](tmp/tsne.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
