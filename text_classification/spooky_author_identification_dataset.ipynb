{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [spooky-author-identification](https://www.kaggle.com/c/spooky-author-identification/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.data.kaggle.spooky_dataset import *\n",
    "from utils.pandas import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dhira Dataset Handler backed by Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed files...\n",
      "Fitting LabelEncoder and LabelBinarizer on processed utils...\n",
      "Done!\n",
      "Preparing vocab file...\n",
      "No <UNK> token found\n",
      "\u001b[93mtmp//words_vocab.tsv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "DATA_STORE_PATH=\"tmp/\"\n",
    "TEXT_COL = \"text\"\n",
    "CATEOGORY_COL = \"author\"\n",
    "\n",
    "TRAIN_FILE_PATH = \"../data/spooky_author_identification/input/train.csv\"\n",
    "TEST_FILE_PATH = \"../data/spooky_author_identification/input/test.csv\"\n",
    "\n",
    "#Prepare the dataset\n",
    "dataset: TextDataFrame = TextDataFrame(train_df_path=TRAIN_FILE_PATH,\n",
    "                                       test_df_path=TEST_FILE_PATH,\n",
    "                                       text_col=TEXT_COL,\n",
    "                                       category_col=CATEOGORY_COL,\n",
    "                                       model_name=DATA_STORE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train utils: 2.332MB\n",
      "Size of validation utils: 0.587MB\n",
      "Size of test utils: 1.240MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15663/15663 [00:01<00:00, 14502.12it/s]\n",
      "100%|██████████| 3916/3916 [00:00<00:00, 13477.50it/s]\n",
      "100%|██████████| 8392/8392 [00:00<00:00, 14263.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and their document counts based on author\n",
      "EAP    6320\n",
      "HPL    4508\n",
      "MWS    4835\n",
      "Name: author, dtype: int64\n",
      "Labels and their document counts based on author\n",
      "EAP    1580\n",
      "HPL    1127\n",
      "MWS    1209\n",
      "Name: author, dtype: int64\n",
      "Labels and their document counts based on author\n",
      "EAP    6320\n",
      "HPL    4508\n",
      "MWS    4835\n",
      "Name: author, dtype: int64\n",
      "Labels and their document counts based on author\n",
      "EAP    1580\n",
      "HPL    1127\n",
      "MWS    1209\n",
      "Name: author, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# To get the raw text features:\n",
    "train_text_data = dataset.get_train_text_data()\n",
    "val_text_data = dataset.get_val_text_data()\n",
    "test_tezt_data = dataset.get_test_text_data()\n",
    "\n",
    "#To get text word ids\n",
    "train_text_word_ids = dataset.get_train_text_word_ids()\n",
    "val_text_word_ids = dataset.get_val_text_word_ids()\n",
    "test_text_word_ids = dataset.get_test_text_word_ids()\n",
    "\n",
    "#To get text word char IDS\n",
    "train_text_word_char_ids = dataset.get_train_text_word_char_ids()\n",
    "val_text_word_char_ids = dataset.get_val_text_word_char_ids()\n",
    "test_text_word_char_ids = dataset.get_test_text_word_char_ids()\n",
    "\n",
    "# To get indexed category labels:\n",
    "train_label = dataset.get_train_label()\n",
    "val_label = dataset.get_val_label()\n",
    "# test_label = dataset.get_test_label()\n",
    "\n",
    "#To get on-hot encoded labels:\n",
    "train_one_hot_encoded_label = dataset.get_train_one_hot_label()\n",
    "val_one_hot_encoded_label= dataset.get_val_one_hot_label()\n",
    "# dataset.get_one_hot_test_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15663, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_word_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15663, 100, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_word_char_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.word2id[\"<UNK>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(id        19579\n",
       " text      19579\n",
       " author    19579\n",
       " dtype: int64,\n",
       "         id                                               text author\n",
       " 0  id26305  This process, however, afforded me no means of...    EAP\n",
       " 1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       " 2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       " 3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       " 4  id12958  Finding nothing else, not even gold, the Super...    HPL)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = dataset.get_train_df()\n",
    "train_df.count(), train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         8392\n",
       "id                 8392\n",
       "text               8392\n",
       "spacy_processed    8392\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = dataset.get_test_df()\n",
    "test_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[\"doc_length\"] = train_df[\"text\"].apply(lambda sentence: len(sentence.split(\" \")))\n",
    "train_df[\"max_word_length\"] = train_df[\"text\"].apply(lambda sentence: \n",
    "                                                 max([len(word) \\\n",
    "                                                      for word  in sentence.split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>doc_length</th>\n",
       "      <th>max_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>41</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "   doc_length  max_word_length  \n",
       "0          41               12  \n",
       "1          14                8  \n",
       "2          36               13  \n",
       "3          34                9  \n",
       "4          27               14  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count    19579.000000\n",
       " mean        26.730477\n",
       " std         19.048353\n",
       " min          2.000000\n",
       " 25%         15.000000\n",
       " 50%         23.000000\n",
       " 75%         34.000000\n",
       " max        861.000000\n",
       " Name: doc_length, dtype: float64, count    19579.000000\n",
       " mean        10.359262\n",
       " std          2.125577\n",
       " min          4.000000\n",
       " 25%          9.000000\n",
       " 50%         10.000000\n",
       " 75%         12.000000\n",
       " max         56.000000\n",
       " Name: max_word_length, dtype: float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"doc_length\"].describe(), train_df[\"max_word_length\"].describe(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents tha will be missed:  88\n",
      "Total number of documents:  19579\n"
     ]
    }
   ],
   "source": [
    "# Lets see how many documents are greater than MAX_DOC_LENGTH\n",
    "MAX_DOC_LENGTH = 100\n",
    "print(\"Number of documents tha will be missed: \", train_df[train_df[\"doc_length\"] > MAX_DOC_LENGTH].count()[0])\n",
    "print(\"Total number of documents: \", train_df.count()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words tha will be missed:  145\n"
     ]
    }
   ],
   "source": [
    "# Lets see how many documents are greater than MAX_DOC_LENGTH\n",
    "MAX_WORD_LENGTH = 15\n",
    "print(\"Number of words tha will be missed: \", train_df[train_df[\"max_word_length\"] > MAX_WORD_LENGTH].count()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scikit Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}