{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from utils.data.kaggle.spooky_dataset import *\n",
    "from capsules import capsules_text_classifier\n",
    "from utils.tf_hooks.early_stopping import EarlyStoppingLossHook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed files...\n",
      "Fitting LabelEncoder and LabelBinarizer on processed utils...\n",
      "Done!\n",
      "Preparing vocab file...\n",
      "No <UNK> token found\n",
      "\u001b[93mtmp//words_vocab.tsv\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15663/15663 [00:01<00:00, 14545.15it/s]\n",
      "100%|██████████| 3916/3916 [00:00<00:00, 13690.54it/s]\n",
      "100%|██████████| 8392/8392 [00:00<00:00, 15592.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and their document counts based on author\n",
      "EAP    6320\n",
      "HPL    4508\n",
      "MWS    4835\n",
      "Name: author, dtype: int64\n",
      "Labels and their document counts based on author\n",
      "EAP    1580\n",
      "HPL    1127\n",
      "MWS    1209\n",
      "Name: author, dtype: int64\n",
      "INFO:tensorflow:text_features.shape: (15663, 100)\n",
      "INFO:tensorflow:numeric_features.shape: (15663, 100, 15)\n",
      "INFO:tensorflow:labels.shape: (15663, 3)\n",
      "INFO:tensorflow:text_features.shape: (3916, 100)\n",
      "INFO:tensorflow:numeric_features.shape: (3916, 100, 15)\n",
      "INFO:tensorflow:labels.shape: (3916, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# add utils path\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "\n",
    "#Model Parameters\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "DATA_STORE_PATH=\"tmp/\"\n",
    "MODEL_STORE_PATH = \"tmp/bilstm_v0/\"\n",
    "TEXT_COL = \"text\"\n",
    "CATEOGORY_COL = \"author\"\n",
    "\n",
    "\n",
    "#Prepare the dataset\n",
    "dataset: TextDataFrame = TextDataFrame(train_df_path=TRAIN_FILE_PATH,\n",
    "                                       test_df_path=TEST_FILE_PATH,\n",
    "                                       text_col=TEXT_COL,\n",
    "                                       category_col=CATEOGORY_COL,\n",
    "                                       model_name=DATA_STORE_PATH)\n",
    "\n",
    "#To get text word ids\n",
    "train_text_word_ids = dataset.get_train_text_word_ids()\n",
    "val_text_word_ids = dataset.get_val_text_word_ids()\n",
    "test_text_word_ids = dataset.get_test_text_word_ids()\n",
    "\n",
    "#To get text word char IDS\n",
    "train_text_word_char_ids = dataset.get_train_text_word_char_ids()\n",
    "val_text_word_char_ids = dataset.get_val_text_word_char_ids()\n",
    "test_text_word_char_ids = dataset.get_test_text_word_char_ids()\n",
    "\n",
    "# To get on-hot encoded labels:\n",
    "train_one_hot_encoded_label = dataset.get_train_one_hot_label()\n",
    "val_one_hot_encoded_label = dataset.get_val_one_hot_label()\n",
    "# dataset.get_one_hot_test_label()\n",
    "\n",
    "#Prepare Tensorflow Dataset iterator for Estimator APIs\n",
    "train_input_fn, train_input_hook = setup_input_graph2(word_ids=train_text_word_ids,\n",
    "                                                      char_ids=train_text_word_char_ids,\n",
    "                                                      labels=train_one_hot_encoded_label,\n",
    "                                                      batch_size=BATCH_SIZE,\n",
    "                                                      is_eval = False,\n",
    "                                                      shuffle=True,\n",
    "                                                      scope='train-data')\n",
    "\n",
    "eval_input_fn, eval_input_hook = setup_input_graph2(word_ids=val_text_word_ids,\n",
    "                                                    char_ids=val_text_word_char_ids,\n",
    "                                                    labels=val_one_hot_encoded_label,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    is_eval = True,\n",
    "                                                    shuffle=True,\n",
    "                                                    scope='val-data')\n",
    "\n",
    "test_input_fn = test_inputs2(word_ids=test_text_word_ids,\n",
    "                             char_ids=test_text_word_char_ids,\n",
    "                             batch_size=1,\n",
    "                             scope='test-data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc06ec88e10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_save_checkpoints_steps': 100, '_keep_checkpoint_max': 100, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'tmp/CapsulesTextClassifierV0/'}\n",
      "WARNING:tensorflow:Estimator's model_fn (<bound method CapsulesTextClassifierV0._model_fn of <capsules.capsules_text_classifier.CapsulesTextClassifierV0 object at 0x7fc06ec88d30>>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "MAX_DOC_LENGTH = 100\n",
    "MAX_WORD_LENGTH = 15\n",
    "model = capsules_text_classifier.CapsulesTextClassifierV0(word_vocab_size=dataset.WORD_VOCAB_SIZE,\n",
    "                                                          char_vocab_size=dataset.CHAR_VOCAB_SIZE,\n",
    "                                                          max_doc_length=MAX_DOC_LENGTH,\n",
    "                                                          max_word_length=MAX_WORD_LENGTH,\n",
    "                                                          num_classes=3\n",
    "                                                          )\n",
    "NUM_STEPS = dataset.num_train_samples // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "INFO:tensorflow:token_ids: =======> Tensor(\"train-data/IteratorGetNext:1\", shape=(?, 100), dtype=int32, device=/device:CPU:0)\n",
      "INFO:tensorflow:char_ids: =======> Tensor(\"train-data/IteratorGetNext:0\", shape=(?, 100, 15), dtype=int32, device=/device:CPU:0)\n",
      "INFO:tensorflow:labels: =======> Tensor(\"Cast:0\", shape=(?, 3), dtype=float32)\n",
      "INFO:tensorflow:word_embeddings =====> Tensor(\"word-embed-layer/dropout/dropout/mul:0\", shape=(?, 100, 24), dtype=float32)\n",
      "INFO:tensorflow:seq_length =====> Tensor(\"word-embed-layer/Sum:0\", shape=(?,), dtype=int32)\n",
      "INFO:tensorflow:char_embeddings =====> Tensor(\"char_embed_layer/dropout/dropout/mul:0\", shape=(?, 100, 15, 48), dtype=float32)\n",
      "INFO:tensorflow:reshaped char_embeddings =====> Tensor(\"chars_level_bilstm_layer/reduce_dimension_1:0\", shape=(?, ?, 48), dtype=float32)\n",
      "INFO:tensorflow:word_lengths =====> Tensor(\"chars_level_bilstm_layer/Sum_1:0\", shape=(?,), dtype=int32)\n",
      "INFO:tensorflow:encoded_words =====> Tensor(\"chars_level_bilstm_layer/Reshape:0\", shape=(?, ?, 48), dtype=float32)\n",
      "INFO:tensorflow:encoded_sentence =====> Tensor(\"word_level_lstm_layer/concat:0\", shape=(?, 100, 96), dtype=float32)\n",
      "INFO:tensorflow:encoded_doc: =====> Tensor(\"char_word_embeddings-mergeing_layer/dropout/dropout/mul:0\", shape=(?, 100, 144), dtype=float32)\n",
      "INFO:tensorflow:encoded_doc: =====> Tensor(\"hidden_layer/Reshape:0\", shape=(?, 14400), dtype=float32)\n",
      "INFO:tensorflow:combined_logits: =====> Tensor(\"hidden_layer/Reshape_1:0\", shape=(16, 28, 28, 1), dtype=float32)\n",
      "INFO:tensorflow:conv1: =====> Tensor(\"Conv1_layer/Conv/Relu:0\", shape=(16, 20, 20, 256), dtype=float32)\n",
      "WARNING:tensorflow:From ../capsules/capsules_text_classifier.py:347: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "LEARNING_RATE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1f64146bed9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.train(input_fn=train_input_fn,\n\u001b[1;32m      2\u001b[0m                 \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_input_hook\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                 steps=0+1 * NUM_STEPS)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    709\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglobal_step_read_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 711\u001b[0;31m             features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m    712\u001b[0m       \u001b[0;31m# Check if the user created a loss summary, and add one if they didn't.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m       \u001b[0;31m# We assume here that the summary is called 'loss'. If it is not, we will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'config'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/dhiraa/sarvam/text_classification/capsules/capsules_text_classifier.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(self, features, labels, mode, params)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m             \u001b[0;31m#learning_rate = tf.train.exponential_decay(cfg.LEARNING_RATE, global_step,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m              \u001b[0;31m#                                          100, 0.99, staircase=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/platform/flags.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__flags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__flags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: LEARNING_RATE"
     ]
    }
   ],
   "source": [
    "model.train(input_fn=train_input_fn,\n",
    "                hooks=[train_input_hook],\n",
    "                steps=0+1 * NUM_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.random.rand()\n",
    "beta = 1-10**(- 0 - 1)\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
