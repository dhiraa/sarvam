{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "#add sarvam_utils path\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaurishk/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sarvam_utils.data.kaggle.spooky_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed files...\n",
      "Fitting LabelEncoder and LabelBinarizer on processed data...\n",
      "Done!\n",
      "Preparing vocab file...\n",
      "Size of train data: 2.332MB\n",
      "Size of validation data: 0.587MB\n",
      "Size of test data: 1.240MB\n",
      "Labels and their document counts based on author\n",
      "EAP    6320\n",
      "HPL    4508\n",
      "MWS    4835\n",
      "Name: author, dtype: int64\n",
      "Labels and their document counts based on author\n",
      "EAP    1580\n",
      "HPL    1127\n",
      "MWS    1209\n",
      "Name: author, dtype: int64\n",
      "Labels and their document counts based on author\n",
      "EAP    6320\n",
      "HPL    4508\n",
      "MWS    4835\n",
      "Name: author, dtype: int64\n",
      "Labels and their document counts based on author\n",
      "EAP    1580\n",
      "HPL    1127\n",
      "MWS    1209\n",
      "Name: author, dtype: int64\n",
      "Size of validation data: 0.587MB\n",
      "Size of test data: 1.240MB\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dataset = TextDataFrame(train_df_path=TRAIN_FILE_PATH,\n",
    "                        test_df_path=TEST_FILE_PATH,\n",
    "                        text_col=\"text\",\n",
    "                        category_col=\"author\",\n",
    "                        model_name=\"fast-text-v0\")\n",
    "\n",
    "# To get the features:\n",
    "train_data = dataset.get_train_data()\n",
    "val_data = dataset.get_val_data()\n",
    "test_data = dataset.get_test_data()\n",
    "\n",
    "# To get indexed category labels:\n",
    "train_label = dataset.get_train_label()\n",
    "val_label = dataset.get_val_label()\n",
    "# test_label = dataset.get_test_label()\n",
    "\n",
    "#To get on-hot encoded labels:\n",
    "train_one_hot_encoded_label = dataset.get_train_one_hot_label()\n",
    "val_one_hot_encoded_label= dataset.get_val_one_hot_label()\n",
    "# dataset.get_one_hot_test_label()\n",
    "\n",
    "train_input_fn, train_input_hook = setup_input_graph(train_data,\n",
    "                                                     train_one_hot_encoded_label,\n",
    "                                                      batch_size=BATCH_SIZE, \n",
    "                                                      scope='train-data')\n",
    "\n",
    "eval_input_fn, eval_input_hook =  setup_input_graph(dataset.get_val_data(),\n",
    "                                                     val_one_hot_encoded_label,\n",
    "                                                    batch_size=1, \n",
    "                                                    is_eval=True,\n",
    "                                                    scope='eval-data')\n",
    "                                                                                                          \n",
    "test_input_fn =  test_inputs(dataset.get_test_data(), \n",
    "                                        batch_size=1, \n",
    "                                        scope='test-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fast_text_v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = fast_text_v0.FastTextConfig(vocab_size=dataset.vocab_count, \n",
    "                                     model_dir=\"fast-text-v0/model/\", \n",
    "                                     words_vocab_file=dataset.words_vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'fast-text-v0/model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb1e6180978>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<bound method FastTextV0._model_fn of <fast_text_v0.FastTextV0 object at 0x7fb1e61807f0>>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "model = fast_text_v0.FastTextV0(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 6\n",
    "NUM_STEPS = dataset.num_train_samples // BATCH_SIZE\n",
    "NUM_STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "#     input_fn=eval_input_fn,\n",
    "#     early_stopping_rounds=3,\n",
    "#     early_stopping_metric=\"loss\",\n",
    "#     early_stopping_metric_minimize=True,\n",
    "#     every_n_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sarvam_utils.early_stopping import EarlyStoppingLossHook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create EarlyStoppingLossHook for reduced_mean:0\n"
     ]
    }
   ],
   "source": [
    "early_stopping_hook = EarlyStoppingLossHook(\"reduced_mean:0\", 0.0030)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:table info: <tensorflow.python.ops.lookup_ops.HashTable object at 0x7fb1e42b1780>\n",
      "INFO:tensorflow:words_embed=Tensor(\"embed-layer/EmbedSequence/embedding_lookup:0\", shape=(?, ?, 96), dtype=float32, device=/device:CPU:0)\n",
      "INFO:tensorflow:words_embed=Tensor(\"fast_text/Sum:0\", shape=(?, 96), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:wide_layer: ------> Tensor(\"hidden-mlp-layer/dropout_2/dropout/mul:0\", shape=(?, 48), dtype=float32)\n",
      "INFO:tensorflow:logits: ------> Tensor(\"logits-layer/dense/BiasAdd:0\", shape=(?, 3), dtype=float32)\n",
      "INFO:tensorflow:predicted_class: ------> Tensor(\"output-layer/class_output:0\", shape=(?,), dtype=int64)\n",
      "INFO:tensorflow:predicted_probabilities: ------> Tensor(\"output-layer/softmax_output:0\", shape=(?, 3), dtype=float32)\n",
      "INFO:tensorflow:Summary name fast_text/Sum:0 is illegal; using fast_text/Sum_0 instead.\n",
      "INFO:tensorflow:Summary name output-layer/softmax_output:0 is illegal; using output-layer/softmax_output_0 instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from fast-text-v0/model/model.ckpt-486\n",
      "INFO:tensorflow:Saving checkpoints for 487 into fast-text-v0/model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.452071, step = 487\n",
      "INFO:tensorflow:global_step/sec: 51.7634\n",
      "INFO:tensorflow:loss = 0.157216, step = 587 (1.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.4389\n",
      "INFO:tensorflow:loss = 0.16682, step = 687 (1.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.0453\n",
      "INFO:tensorflow:loss = 0.476855, step = 787 (1.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.9738\n",
      "INFO:tensorflow:loss = 0.501671, step = 887 (1.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.2161\n",
      "INFO:tensorflow:loss = 0.116519, step = 987 (1.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.8284\n",
      "INFO:tensorflow:loss = 0.180942, step = 1087 (1.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.3145\n",
      "INFO:tensorflow:loss = 0.461187, step = 1187 (1.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.5897\n",
      "INFO:tensorflow:loss = 0.449698, step = 1287 (1.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.7358\n",
      "INFO:tensorflow:loss = 0.681091, step = 1387 (1.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.4519\n",
      "INFO:tensorflow:loss = 0.306683, step = 1487 (1.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.1782\n",
      "INFO:tensorflow:loss = 0.870034, step = 1587 (1.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.6602\n",
      "INFO:tensorflow:loss = 0.161775, step = 1687 (1.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.6076\n",
      "INFO:tensorflow:loss = 0.317401, step = 1787 (1.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.5232\n",
      "INFO:tensorflow:loss = 0.137266, step = 1887 (1.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.1156\n",
      "INFO:tensorflow:loss = 0.0944596, step = 1987 (1.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.1796\n",
      "INFO:tensorflow:loss = 0.209185, step = 2087 (1.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.8593\n",
      "INFO:tensorflow:loss = 0.0851319, step = 2187 (1.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.2682\n",
      "INFO:tensorflow:loss = 0.287507, step = 2287 (1.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.3941\n",
      "INFO:tensorflow:loss = 0.0772674, step = 2387 (1.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.8699\n",
      "INFO:tensorflow:loss = 0.147144, step = 2487 (1.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.0936\n",
      "INFO:tensorflow:loss = 0.0872876, step = 2587 (1.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.0725\n",
      "INFO:tensorflow:loss = 0.0729889, step = 2687 (1.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.8193\n",
      "INFO:tensorflow:loss = 0.0679224, step = 2787 (1.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.7347\n",
      "INFO:tensorflow:loss = 0.066824, step = 2887 (1.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.6687\n",
      "INFO:tensorflow:loss = 0.178351, step = 2987 (1.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.0013\n",
      "INFO:tensorflow:loss = 0.255233, step = 3087 (1.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.4506\n",
      "INFO:tensorflow:loss = 0.126844, step = 3187 (1.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.4216\n",
      "INFO:tensorflow:loss = 0.162047, step = 3287 (1.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.5649\n",
      "INFO:tensorflow:loss = 0.641973, step = 3387 (1.867 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3420 into fast-text-v0/model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.490502.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fast_text_v0.FastTextV0 at 0x7fb1e61807f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=train_input_fn, hooks=[train_input_hook, early_stopping_hook], steps=NUM_EPOCHS*NUM_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:table info: <tensorflow.python.ops.lookup_ops.HashTable object at 0x7fb1dc342908>\n",
      "INFO:tensorflow:words_embed=Tensor(\"embed-layer/EmbedSequence/embedding_lookup:0\", shape=(?, ?, 96), dtype=float32, device=/device:CPU:0)\n",
      "INFO:tensorflow:words_embed=Tensor(\"fast_text/Sum:0\", shape=(?, 96), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:wide_layer: ------> Tensor(\"hidden-mlp-layer/dropout_2/Identity:0\", shape=(?, 48), dtype=float32)\n",
      "INFO:tensorflow:logits: ------> Tensor(\"logits-layer/dense/BiasAdd:0\", shape=(?, 3), dtype=float32)\n",
      "INFO:tensorflow:predicted_class: ------> Tensor(\"output-layer/class_output:0\", shape=(?,), dtype=int64)\n",
      "INFO:tensorflow:predicted_probabilities: ------> Tensor(\"output-layer/softmax_output:0\", shape=(?, 3), dtype=float32)\n",
      "INFO:tensorflow:Summary name fast_text/Sum:0 is illegal; using fast_text/Sum_0 instead.\n",
      "INFO:tensorflow:Summary name output-layer/softmax_output:0 is illegal; using output-layer/softmax_output_0 instead.\n",
      "INFO:tensorflow:Starting evaluation at 2017-11-23-10:42:56\n",
      "INFO:tensorflow:Restoring parameters from fast-text-v0/model/model.ckpt-3420\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-23-10:42:59\n",
      "INFO:tensorflow:Saving dict for global step 3420: Accuracy = 0.757661, Precision = 0.830897, Recall = 0.900257, global_step = 3420, loss = 0.590196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.75766087,\n",
       " 'Precision': 0.83089685,\n",
       " 'Recall': 0.90025687,\n",
       " 'global_step': 3420,\n",
       " 'loss': 0.59019595}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(input_fn=eval_input_fn, hooks=[eval_input_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}