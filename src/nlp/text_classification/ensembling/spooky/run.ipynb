{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../\")\n",
    "sys.path.append(\"../../../../\")\n",
    "from kaggle.dataset.spooky import SpookyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "from ensembling.spooky.tfidf import tfidf, count_vec\n",
    "from ensembling.spooky.lr import lr, lr_svd_gridsearch\n",
    "from ensembling.spooky.nb import mnb, mnb_gridsearch, generate_nb_features\n",
    "from ensembling.spooky.svm import svd, svm\n",
    "from ensembling.spooky.tree import xgbst, xgbst_on_vec\n",
    "from ensembling.spooky.keras_models import simple_net, bilstm_net\n",
    "\n",
    "from sarvam.nlp import word_vectors\n",
    "from sarvam.ensembler import Ensembler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed files...\n",
      "Fitting LabelEncoder and LabelBinarizer on processed audio_utils...\n",
      "Done!\n",
      "Preparing vocab file...\n",
      "No <UNK> token found\n",
      "\u001b[93mexperiments/data//spooky_dataset/words_vocab.tsv\u001b[0m\n",
      "Size of train data: 2.772MB\n",
      "Labels and their document counts based on author\n",
      "EAP    7505\n",
      "HPL    5353\n",
      "MWS    5741\n",
      "Name: author, dtype: int64\n",
      "Size of validation data: 0.147MB\n",
      "Labels and their document counts based on author\n",
      "EAP    395\n",
      "HPL    282\n",
      "MWS    303\n",
      "Name: author, dtype: int64\n",
      "Size of test data: 1.240MB\n"
     ]
    }
   ],
   "source": [
    "# Use the sarvam utils to load the data set and get train/val/test data\n",
    "dataset = SpookyDataset(train_file_path=\"../../../data/spooky_author_identification/input/train.csv\",\n",
    "                       test_file_path= \"../../../data/spooky_author_identification/input/test.csv\")\n",
    "\n",
    "TEXT_COL = \"text\"\n",
    "CATEGORY_COL = \"author\"\n",
    "\n",
    "\n",
    "\n",
    "dataset.prepare()\n",
    "dataframe = dataset.dataframe\n",
    "\n",
    "train_x = dataframe.get_train_text_data()\n",
    "train_y = dataframe.get_train_label()\n",
    "\n",
    "val_x = dataframe.get_val_text_data()\n",
    "val_y = dataframe.get_val_label()\n",
    "\n",
    "text_x = dataframe.get_test_text_data()\n",
    "\n",
    "train_df = dataframe.get_train_data()\n",
    "test_df = dataframe.get_test_df()\n",
    "\n",
    "## Prepare the data for modeling ###\n",
    "author_mapping_dict = {'EAP':0, 'HPL':1, 'MWS':2}\n",
    "# train_y = train_df['author'].map(author_mapping_dict)\n",
    "train_id = train_df['id'].values\n",
    "test_id = test_df['id'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to Numeric Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_word_tfidf, val_x_word_tfidf = tfidf(train_x, val_x, ngram=(1,3), analyzer=\"word\", lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_char_tfidf, val_x_char_tfidf = tfidf(train_x, val_x, ngram=(4,7), analyzer=\"char\", lowercase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_word_ctv, val_x_word_ctv = count_vec(train_x, val_x,  analyzer=\"word\", lowercase=True, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_char_ctv, val_x_char_ctv = count_vec(train_x, val_x,  analyzer=\"char\", lowercase=True, ngram=(4,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_word_tfidf_svd_scl, val_x_word_tfidf_svd_scl =  svd(train_x_word_tfidf, val_x_word_tfidf, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_char_tfidf_svd_scl, val_x_char_tfidf_svd_scl =  svd(train_x_char_tfidf, val_x_char_tfidf, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_word_ctv_svd_scl, val_x_word_ctv_svd_scl =  svd(train_x_word_ctv, val_x_word_ctv, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_char_ctv_svd_scl, val_x_char_ctv_svd_scl =  svd(train_x_char_ctv, val_x_char_ctv, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [03:51, 9470.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2195884 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = word_vectors.load_embeddings(\"/opt/datasets/glove/glove.840B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18599/18599 [00:07<00:00, 2560.90it/s]\n"
     ]
    }
   ],
   "source": [
    "train_x_glove = word_vectors.data_2_glove_vec(train_x, embeddings_index=embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 980/980 [00:00<00:00, 2616.56it/s]\n"
     ]
    }
   ],
   "source": [
    "val_x_glove = word_vectors.data_2_glove_vec(val_x, embeddings_index=embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and their document counts based on author\n",
      "EAP    7505\n",
      "HPL    5353\n",
      "MWS    5741\n",
      "Name: author, dtype: int64\n",
      "Labels and their document counts based on author\n",
      "EAP    395\n",
      "HPL    282\n",
      "MWS    303\n",
      "Name: author, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# scale the data before any neural net:\n",
    "scl = preprocessing.StandardScaler()\n",
    "train_x_glove_scl = scl.fit_transform(train_x_glove)\n",
    "val_x_glove_scl = scl.transform(val_x_glove)\n",
    "\n",
    "train_y_one_hot_encoded = dataframe.get_train_one_hot_label()\n",
    "val_y_one_hot_encoded = dataframe.get_val_one_hot_label()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.610 \n"
     ]
    }
   ],
   "source": [
    "lr(train_x_tfidf, train_y, val_x_tfidf, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.516 \n"
     ]
    }
   ],
   "source": [
    "lr(train_x_ctv, train_y, val_x_ctv, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
      "[CV] lr__C=0.1, lr__penalty=l1, svd__n_components=120 ................\n",
      "[CV] lr__C=0.1, lr__penalty=l1, svd__n_components=120 ................\n",
      "[CV] lr__C=0.1, lr__penalty=l1, svd__n_components=180 ................\n",
      "[CV] lr__C=0.1, lr__penalty=l1, svd__n_components=180 ................\n",
      "[CV]  lr__C=0.1, lr__penalty=l1, svd__n_components=120, score=-0.826303, total= 1.3min\n",
      "[CV] lr__C=0.1, lr__penalty=l2, svd__n_components=120 ................\n",
      "[CV]  lr__C=0.1, lr__penalty=l1, svd__n_components=120, score=-0.810406, total= 1.3min\n",
      "[CV] lr__C=0.1, lr__penalty=l2, svd__n_components=120 ................\n",
      "[CV]  lr__C=0.1, lr__penalty=l1, svd__n_components=180, score=-0.775996, total= 2.3min\n",
      "[CV] lr__C=0.1, lr__penalty=l2, svd__n_components=180 ................\n",
      "[CV]  lr__C=0.1, lr__penalty=l1, svd__n_components=180, score=-0.779073, total= 2.3min\n",
      "[CV] lr__C=0.1, lr__penalty=l2, svd__n_components=180 ................\n",
      "[CV]  lr__C=0.1, lr__penalty=l2, svd__n_components=120, score=-0.808601, total= 1.7min\n",
      "[CV] lr__C=1.0, lr__penalty=l1, svd__n_components=120 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  3.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__C=0.1, lr__penalty=l2, svd__n_components=120, score=-0.801700, total= 1.7min\n",
      "[CV] lr__C=1.0, lr__penalty=l1, svd__n_components=120 ................\n",
      "[CV]  lr__C=1.0, lr__penalty=l1, svd__n_components=120, score=-0.812132, total= 1.8min\n",
      "[CV] lr__C=1.0, lr__penalty=l1, svd__n_components=180 ................\n",
      "[CV]  lr__C=1.0, lr__penalty=l1, svd__n_components=120, score=-0.795271, total= 1.7min\n",
      "[CV] lr__C=1.0, lr__penalty=l1, svd__n_components=180 ................\n",
      "[CV]  lr__C=0.1, lr__penalty=l2, svd__n_components=180, score=-0.771930, total= 2.6min\n",
      "[CV] lr__C=1.0, lr__penalty=l2, svd__n_components=120 ................\n",
      "[CV]  lr__C=0.1, lr__penalty=l2, svd__n_components=180, score=-0.758431, total= 2.6min\n",
      "[CV] lr__C=1.0, lr__penalty=l2, svd__n_components=120 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  4.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__C=1.0, lr__penalty=l2, svd__n_components=120, score=-0.814725, total= 1.5min\n",
      "[CV] lr__C=1.0, lr__penalty=l2, svd__n_components=180 ................\n",
      "[CV]  lr__C=1.0, lr__penalty=l2, svd__n_components=120, score=-0.797284, total= 1.5min\n",
      "[CV] lr__C=1.0, lr__penalty=l2, svd__n_components=180 ................\n",
      "[CV] lr__C=10, lr__penalty=l1, svd__n_components=120 .................\n",
      "[CV]  lr__C=1.0, lr__penalty=l1, svd__n_components=180, score=-0.781171, total= 2.2min\n",
      "[CV] lr__C=10, lr__penalty=l1, svd__n_components=120 .................\n",
      "[CV]  lr__C=1.0, lr__penalty=l1, svd__n_components=180, score=-0.756178, total= 2.6min\n",
      "[CV] lr__C=10, lr__penalty=l1, svd__n_components=180 .................\n",
      "[CV] lr__C=10, lr__penalty=l1, svd__n_components=180 .................\n",
      "[CV] lr__C=10, lr__penalty=l2, svd__n_components=120 .................\n",
      "[CV] lr__C=10, lr__penalty=l2, svd__n_components=120 .................\n",
      "[CV]  lr__C=10, lr__penalty=l1, svd__n_components=120, score=-0.808256, total= 2.5min\n",
      "[CV] lr__C=10, lr__penalty=l2, svd__n_components=180 .................\n",
      "[CV]  lr__C=1.0, lr__penalty=l2, svd__n_components=180, score=-0.769389, total= 3.0min\n",
      "[CV] lr__C=10, lr__penalty=l2, svd__n_components=180 .................\n"
     ]
    },
    {
     "ename": "JoblibMemoryError",
     "evalue": "JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f351acadf60, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/mageswarand/anaconda3/envs/tensorflow1.0/l...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/magesw.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f351acadf60, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/mageswarand/anaconda3/envs/tensorflow1.0/l...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/magesw.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 24, 19, 46, 39, 337264), 'msg_id': '1669C9F0206B4967BF4A889EE8AAFCBD', 'msg_type': 'execute_request', 'session': '2986DFA3063045FB8F031660E5F24205', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1669C9F0206B4967BF4A889EE8AAFCBD', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'2986DFA3063045FB8F031660E5F24205']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 24, 19, 46, 39, 337264), 'msg_id': '1669C9F0206B4967BF4A889EE8AAFCBD', 'msg_type': 'execute_request', 'session': '2986DFA3063045FB8F031660E5F24205', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1669C9F0206B4967BF4A889EE8AAFCBD', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'2986DFA3063045FB8F031660E5F24205'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 24, 19, 46, 39, 337264), 'msg_id': '1669C9F0206B4967BF4A889EE8AAFCBD', 'msg_type': 'execute_request', 'session': '2986DFA3063045FB8F031660E5F24205', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1669C9F0206B4967BF4A889EE8AAFCBD', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-24-5b5d120b7869>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f348b7153c8, executi..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f351266d030, file \"<ipython-input-24-5b5d120b7869>\", line 1>\n        result = <ExecutionResult object at 7f348b7153c8, executi..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f351266d030, file \"<ipython-input-24-5b5d120b7869>\", line 1>, result=<ExecutionResult object at 7f348b7153c8, executi..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f351266d030, file \"<ipython-input-24-5b5d120b7869>\", line 1>\n        self.user_global_ns = {'In': ['', \"get_ipython().magic('load_ext autoreload')\\nget_i...)\\nfrom kaggle.dataset.spooky import SpookyDataset\", 'from ensembling.spooky.tfidf import tfidf, count...embling.spooky.xgboost import xgbst, xgbst_on_vec', 'import xgboost as xgb\\nfrom xgboost.sklearn import XGBClassifier', 'import xgboost as xgb\\nfrom xgb.sklearn import XGBClassifier', 'import xgboost as xgb\\nxgb.XGBClassifier', 'import xgboost as xgb\\nxgb.XGBClassifier', '# import xgboost as xgb\\n# xgb.XGBClassifier', 'import xgboost as xgb\\nxgb.XGBClassifier', 'from ensembling.spooky.tfidf import tfidf, count...ensembling.spooky.tree import xgbst, xgbst_on_vec', '# Use the sarvam utils to load the data set and ..._label()\\n\\ntext_x = dataframe.get_test_text_data()', 'train_x_tfidf, val_x_tfidf = tfidf(train_x, val_x)', 'lr(train_x_tfidf, train_y, val_x_tfidf, val_y)', 'train_x_ctv, val_x_ctv = count_vec(train_x, val_x)', 'lr(train_x_ctv, train_y, val_x_ctv, val_y)', 'xgbst_on_vec(train_x_tfidf, train_y, val_x_tfidf, val_y)', 'xgbst_on_vec(train_x_ctv, train_y, val_x_ctv, val_y)', 'xgbst(train_x_svd_scl, train_y, val_x_svd_scl, val_y)', 'train_x_svd_scl, val_x_svd_scl =  svd(train_x_tfidf, val_x_tfidf)', 'xgbst(train_x_svd_scl, train_y, val_x_svd_scl, val_y)', ...], 'Out': {}, 'SpookyDataset': <class 'kaggle.dataset.spooky.SpookyDataset'>, '_': '', '__': '', '___': '', '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '__doc__': 'Automatically created module for IPython interactive environment', '__loader__': None, ...}\n        self.user_ns = {'In': ['', \"get_ipython().magic('load_ext autoreload')\\nget_i...)\\nfrom kaggle.dataset.spooky import SpookyDataset\", 'from ensembling.spooky.tfidf import tfidf, count...embling.spooky.xgboost import xgbst, xgbst_on_vec', 'import xgboost as xgb\\nfrom xgboost.sklearn import XGBClassifier', 'import xgboost as xgb\\nfrom xgb.sklearn import XGBClassifier', 'import xgboost as xgb\\nxgb.XGBClassifier', 'import xgboost as xgb\\nxgb.XGBClassifier', '# import xgboost as xgb\\n# xgb.XGBClassifier', 'import xgboost as xgb\\nxgb.XGBClassifier', 'from ensembling.spooky.tfidf import tfidf, count...ensembling.spooky.tree import xgbst, xgbst_on_vec', '# Use the sarvam utils to load the data set and ..._label()\\n\\ntext_x = dataframe.get_test_text_data()', 'train_x_tfidf, val_x_tfidf = tfidf(train_x, val_x)', 'lr(train_x_tfidf, train_y, val_x_tfidf, val_y)', 'train_x_ctv, val_x_ctv = count_vec(train_x, val_x)', 'lr(train_x_ctv, train_y, val_x_ctv, val_y)', 'xgbst_on_vec(train_x_tfidf, train_y, val_x_tfidf, val_y)', 'xgbst_on_vec(train_x_ctv, train_y, val_x_ctv, val_y)', 'xgbst(train_x_svd_scl, train_y, val_x_svd_scl, val_y)', 'train_x_svd_scl, val_x_svd_scl =  svd(train_x_tfidf, val_x_tfidf)', 'xgbst(train_x_svd_scl, train_y, val_x_svd_scl, val_y)', ...], 'Out': {}, 'SpookyDataset': <class 'kaggle.dataset.spooky.SpookyDataset'>, '_': '', '__': '', '___': '', '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '__doc__': 'Automatically created module for IPython interactive environment', '__loader__': None, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/opt/dhiraa/sarvam/text_classification/ensembling/spooky/<ipython-input-24-5b5d120b7869> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/opt/dhiraa/sarvam/text_classification/ensembling/spooky/lr.py in lr_svd_gridsearch(train_x=<18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, train_y=array([2, 0, 0, ..., 2, 2, 2]), val_x=<980x400266 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, val_y=array([2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0, 2,...       1, 1, 1, 1, 0, 2, 1, 2, 2, 1, 2, 2, 2, 2]))\n     39     # Initialize Grid Search Model\n     40     model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n     41                          verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n     42 \n     43     # Fit Grid Search Model\n---> 44     model.fit(train_x, train_y)  # we can use the full data here but im only using xtrain\n        model.fit = <bound method GridSearchCV.fit of GridSearchCV(c...ter=False, needs_proba=True),\n       verbose=10)>\n        train_x = <18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>\n        train_y = array([2, 0, 0, ..., 2, 2, 2])\n     45     print(\"Best score: %0.3f\" % model.best_score_)\n     46     print(\"Best parameters set:\")\n     47     best_parameters = model.best_estimator_.get_params()\n     48     for param_name in sorted(param_grid.keys()):\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=2, error_score='raise',\n       e...tter=False, needs_proba=True),\n       verbose=10), X=<18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 2, 2, 2]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...ter=False, needs_proba=True),\n       verbose=10)>\n        X = <18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>\n        y = array([2, 0, 0, ..., 2, 2, 2])\n        groups = None\n        self.param_grid = {'lr__C': [0.1, 1.0, 10], 'lr__penalty': ['l1', 'l2'], 'svd__n_components': [120, 180]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=2, error_score='raise',\n       e...tter=False, needs_proba=True),\n       verbose=10), X=<18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 2, 2, 2]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Sun Dec 24 20:01:04 2017\nPID: 29934Python 3.6.1: /home/mageswarand/anaconda3/envs/tensorflow1.0/bin/python\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), <18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, array([2, 0, 0, ..., 2, 2, 2]), make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True), array([   0,    1,    2, ..., 9383, 9389, 9392]), array([ 9209,  9210,  9213, ..., 18596, 18597, 18598]), 10, {'lr__C': 1.0, 'lr__penalty': 'l2', 'svd__n_components': 180}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), <18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, array([2, 0, 0, ..., 2, 2, 2]), make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True), array([   0,    1,    2, ..., 9383, 9389, 9392]), array([ 9209,  9210,  9213, ..., 18596, 18597, 18598]), 10, {'lr__C': 1.0, 'lr__penalty': 'l2', 'svd__n_components': 180})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), X=<18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 2, 2, 2]), scorer=make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True), train=array([   0,    1,    2, ..., 9383, 9389, 9392]), test=array([ 9209,  9210,  9213, ..., 18596, 18597, 18598]), verbose=10, parameters={'lr__C': 1.0, 'lr__penalty': 'l2', 'svd__n_components': 180}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('....0001,\n          verbose=0, warm_start=False))])>\n        X_train = <9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        y_train = array([2, 0, 0, ..., 0, 0, 0])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), X=<9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 0, 0, 0]), **fit_params={})\n    263         Returns\n    264         -------\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n--> 268         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(steps=[(....0001,\n          verbose=0, warm_start=False))])>\n        X = <9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        y = array([2, 0, 0, ..., 0, 0, 0])\n    269         if self._final_estimator is not None:\n    270             self._final_estimator.fit(Xt, y, **fit_params)\n    271         return self\n    272 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), X=<9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 0, 0, 0]), **fit_params={})\n    229         Xt = X\n    230         for name, transform in self.steps[:-1]:\n    231             if transform is None:\n    232                 pass\n    233             elif hasattr(transform, \"fit_transform\"):\n--> 234                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt = <9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        transform.fit_transform = <bound method TruncatedSVD.fit_transform of Trun...80, n_iter=5,\n       random_state=None, tol=0.0)>\n        y = array([2, 0, 0, ..., 0, 0, 0])\n        fit_params_steps = {'lr': {}, 'scl': {}, 'svd': {}}\n        name = 'svd'\n    235             else:\n    236                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    237                               .transform(Xt)\n    238         if self._final_estimator is None:\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/decomposition/truncated_svd.py in fit_transform(self=TruncatedSVD(algorithm='randomized', n_components=180, n_iter=5,\n       random_state=None, tol=0.0), X=<9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 0, 0, 0]))\n    168             if k >= n_features:\n    169                 raise ValueError(\"n_components must be < n_features;\"\n    170                                  \" got %d >= %d\" % (k, n_features))\n    171             U, Sigma, VT = randomized_svd(X, self.n_components,\n    172                                           n_iter=self.n_iter,\n--> 173                                           random_state=random_state)\n        random_state = <mtrand.RandomState object>\n    174         else:\n    175             raise ValueError(\"unknown algorithm %r\" % self.algorithm)\n    176 \n    177         self.components_ = VT\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/utils/extmath.py in randomized_svd(M=<400266x9301 sparse matrix of type '<class 'nump...ored elements in Compressed Sparse Column format>, n_components=180, n_oversamples=10, n_iter=5, power_iteration_normalizer='auto', transpose=True, flip_sign=True, random_state=<mtrand.RandomState object>)\n    359     if transpose:\n    360         # this implementation is a bit faster with smaller shape[1]\n    361         M = M.T\n    362 \n    363     Q = randomized_range_finder(M, n_random, n_iter,\n--> 364                                 power_iteration_normalizer, random_state)\n        power_iteration_normalizer = 'auto'\n        random_state = <mtrand.RandomState object>\n    365 \n    366     # project M to the (k + p) dimensional space using the basis vectors\n    367     B = safe_sparse_dot(Q.T, M)\n    368 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/utils/extmath.py in randomized_range_finder(A=<400266x9301 sparse matrix of type '<class 'nump...ored elements in Compressed Sparse Column format>, size=190, n_iter=5, power_iteration_normalizer='LU', random_state=<mtrand.RandomState object>)\n    253     for i in range(n_iter):\n    254         if power_iteration_normalizer == 'none':\n    255             Q = safe_sparse_dot(A, Q)\n    256             Q = safe_sparse_dot(A.T, Q)\n    257         elif power_iteration_normalizer == 'LU':\n--> 258             Q, _ = linalg.lu(safe_sparse_dot(A, Q), permute_l=True)\n        Q = array([[-0.12371876, -0.6255367 , -0.45513213, .... -0.24736285,\n        -0.98142483,  0.59128062]])\n        _ = undefined\n        A = <400266x9301 sparse matrix of type '<class 'nump...ored elements in Compressed Sparse Column format>\n    259             Q, _ = linalg.lu(safe_sparse_dot(A.T, Q), permute_l=True)\n    260         elif power_iteration_normalizer == 'QR':\n    261             Q, _ = linalg.qr(safe_sparse_dot(A, Q), mode='economic')\n    262             Q, _ = linalg.qr(safe_sparse_dot(A.T, Q), mode='economic')\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/scipy/linalg/decomp_lu.py in lu(a=array([[ 0.        ,  0.        ,  0.        , ....  1.23625534,\n        -1.18298639,  0.12343751]]), permute_l=True, overwrite_a=False, check_finite=True)\n    180         a1 = asarray(a)\n    181     if len(a1.shape) != 2:\n    182         raise ValueError('expected matrix')\n    183     overwrite_a = overwrite_a or (_datacopied(a1, a))\n    184     flu, = get_flinalg_funcs(('lu',), (a1,))\n--> 185     p, l, u, info = flu(a1, permute_l=permute_l, overwrite_a=overwrite_a)\n        p = undefined\n        l = undefined\n        u = undefined\n        info = undefined\n        flu = <fortran object>\n        a1 = array([[ 0.        ,  0.        ,  0.        , ....  1.23625534,\n        -1.18298639,  0.12343751]])\n        permute_l = True\n        overwrite_a = False\n    186     if info < 0:\n    187         raise ValueError('illegal value in %d-th argument of '\n    188                                             'internal lu.getrf' % -info)\n    189     if permute_l:\n\nMemoryError: \n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 238, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/pipeline.py\", line 268, in fit\n    Xt, fit_params = self._fit(X, y, **fit_params)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/pipeline.py\", line 234, in _fit\n    Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/decomposition/truncated_svd.py\", line 173, in fit_transform\n    random_state=random_state)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/utils/extmath.py\", line 364, in randomized_svd\n    power_iteration_normalizer, random_state)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/utils/extmath.py\", line 258, in randomized_range_finder\n    Q, _ = linalg.lu(safe_sparse_dot(A, Q), permute_l=True)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/scipy/linalg/decomp_lu.py\", line 185, in lu\n    p, l, u, info = flu(a1, permute_l=permute_l, overwrite_a=overwrite_a)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nMemoryError                                        Sun Dec 24 20:01:04 2017\nPID: 29934Python 3.6.1: /home/mageswarand/anaconda3/envs/tensorflow1.0/bin/python\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), <18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, array([2, 0, 0, ..., 2, 2, 2]), make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True), array([   0,    1,    2, ..., 9383, 9389, 9392]), array([ 9209,  9210,  9213, ..., 18596, 18597, 18598]), 10, {'lr__C': 1.0, 'lr__penalty': 'l2', 'svd__n_components': 180}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), <18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, array([2, 0, 0, ..., 2, 2, 2]), make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True), array([   0,    1,    2, ..., 9383, 9389, 9392]), array([ 9209,  9210,  9213, ..., 18596, 18597, 18598]), 10, {'lr__C': 1.0, 'lr__penalty': 'l2', 'svd__n_components': 180})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), X=<18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 2, 2, 2]), scorer=make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True), train=array([   0,    1,    2, ..., 9383, 9389, 9392]), test=array([ 9209,  9210,  9213, ..., 18596, 18597, 18598]), verbose=10, parameters={'lr__C': 1.0, 'lr__penalty': 'l2', 'svd__n_components': 180}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('....0001,\n          verbose=0, warm_start=False))])>\n        X_train = <9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        y_train = array([2, 0, 0, ..., 0, 0, 0])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), X=<9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 0, 0, 0]), **fit_params={})\n    263         Returns\n    264         -------\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n--> 268         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(steps=[(....0001,\n          verbose=0, warm_start=False))])>\n        X = <9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        y = array([2, 0, 0, ..., 0, 0, 0])\n    269         if self._final_estimator is not None:\n    270             self._final_estimator.fit(Xt, y, **fit_params)\n    271         return self\n    272 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), X=<9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 0, 0, 0]), **fit_params={})\n    229         Xt = X\n    230         for name, transform in self.steps[:-1]:\n    231             if transform is None:\n    232                 pass\n    233             elif hasattr(transform, \"fit_transform\"):\n--> 234                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt = <9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        transform.fit_transform = <bound method TruncatedSVD.fit_transform of Trun...80, n_iter=5,\n       random_state=None, tol=0.0)>\n        y = array([2, 0, 0, ..., 0, 0, 0])\n        fit_params_steps = {'lr': {}, 'scl': {}, 'svd': {}}\n        name = 'svd'\n    235             else:\n    236                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    237                               .transform(Xt)\n    238         if self._final_estimator is None:\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/decomposition/truncated_svd.py in fit_transform(self=TruncatedSVD(algorithm='randomized', n_components=180, n_iter=5,\n       random_state=None, tol=0.0), X=<9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 0, 0, 0]))\n    168             if k >= n_features:\n    169                 raise ValueError(\"n_components must be < n_features;\"\n    170                                  \" got %d >= %d\" % (k, n_features))\n    171             U, Sigma, VT = randomized_svd(X, self.n_components,\n    172                                           n_iter=self.n_iter,\n--> 173                                           random_state=random_state)\n        random_state = <mtrand.RandomState object>\n    174         else:\n    175             raise ValueError(\"unknown algorithm %r\" % self.algorithm)\n    176 \n    177         self.components_ = VT\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/utils/extmath.py in randomized_svd(M=<400266x9301 sparse matrix of type '<class 'nump...ored elements in Compressed Sparse Column format>, n_components=180, n_oversamples=10, n_iter=5, power_iteration_normalizer='auto', transpose=True, flip_sign=True, random_state=<mtrand.RandomState object>)\n    359     if transpose:\n    360         # this implementation is a bit faster with smaller shape[1]\n    361         M = M.T\n    362 \n    363     Q = randomized_range_finder(M, n_random, n_iter,\n--> 364                                 power_iteration_normalizer, random_state)\n        power_iteration_normalizer = 'auto'\n        random_state = <mtrand.RandomState object>\n    365 \n    366     # project M to the (k + p) dimensional space using the basis vectors\n    367     B = safe_sparse_dot(Q.T, M)\n    368 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/utils/extmath.py in randomized_range_finder(A=<400266x9301 sparse matrix of type '<class 'nump...ored elements in Compressed Sparse Column format>, size=190, n_iter=5, power_iteration_normalizer='LU', random_state=<mtrand.RandomState object>)\n    253     for i in range(n_iter):\n    254         if power_iteration_normalizer == 'none':\n    255             Q = safe_sparse_dot(A, Q)\n    256             Q = safe_sparse_dot(A.T, Q)\n    257         elif power_iteration_normalizer == 'LU':\n--> 258             Q, _ = linalg.lu(safe_sparse_dot(A, Q), permute_l=True)\n        Q = array([[-0.12371876, -0.6255367 , -0.45513213, .... -0.24736285,\n        -0.98142483,  0.59128062]])\n        _ = undefined\n        A = <400266x9301 sparse matrix of type '<class 'nump...ored elements in Compressed Sparse Column format>\n    259             Q, _ = linalg.lu(safe_sparse_dot(A.T, Q), permute_l=True)\n    260         elif power_iteration_normalizer == 'QR':\n    261             Q, _ = linalg.qr(safe_sparse_dot(A, Q), mode='economic')\n    262             Q, _ = linalg.qr(safe_sparse_dot(A.T, Q), mode='economic')\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/scipy/linalg/decomp_lu.py in lu(a=array([[ 0.        ,  0.        ,  0.        , ....  1.23625534,\n        -1.18298639,  0.12343751]]), permute_l=True, overwrite_a=False, check_finite=True)\n    180         a1 = asarray(a)\n    181     if len(a1.shape) != 2:\n    182         raise ValueError('expected matrix')\n    183     overwrite_a = overwrite_a or (_datacopied(a1, a))\n    184     flu, = get_flinalg_funcs(('lu',), (a1,))\n--> 185     p, l, u, info = flu(a1, permute_l=permute_l, overwrite_a=overwrite_a)\n        p = undefined\n        l = undefined\n        u = undefined\n        info = undefined\n        flu = <fortran object>\n        a1 = array([[ 0.        ,  0.        ,  0.        , ....  1.23625534,\n        -1.18298639,  0.12343751]])\n        permute_l = True\n        overwrite_a = False\n    186     if info < 0:\n    187         raise ValueError('illegal value in %d-th argument of '\n    188                                             'internal lu.getrf' % -info)\n    189     if permute_l:\n\nMemoryError: \n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nMemoryError                                        Sun Dec 24 20:01:04 2017\nPID: 29934Python 3.6.1: /home/mageswarand/anaconda3/envs/tensorflow1.0/bin/python\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), <18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, array([2, 0, 0, ..., 2, 2, 2]), make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True), array([   0,    1,    2, ..., 9383, 9389, 9392]), array([ 9209,  9210,  9213, ..., 18596, 18597, 18598]), 10, {'lr__C': 1.0, 'lr__penalty': 'l2', 'svd__n_components': 180}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), <18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, array([2, 0, 0, ..., 2, 2, 2]), make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True), array([   0,    1,    2, ..., 9383, 9389, 9392]), array([ 9209,  9210,  9213, ..., 18596, 18597, 18598]), 10, {'lr__C': 1.0, 'lr__penalty': 'l2', 'svd__n_components': 180})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), X=<18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 2, 2, 2]), scorer=make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True), train=array([   0,    1,    2, ..., 9383, 9389, 9392]), test=array([ 9209,  9210,  9213, ..., 18596, 18597, 18598]), verbose=10, parameters={'lr__C': 1.0, 'lr__penalty': 'l2', 'svd__n_components': 180}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('....0001,\n          verbose=0, warm_start=False))])>\n        X_train = <9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        y_train = array([2, 0, 0, ..., 0, 0, 0])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), X=<9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 0, 0, 0]), **fit_params={})\n    263         Returns\n    264         -------\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n--> 268         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(steps=[(....0001,\n          verbose=0, warm_start=False))])>\n        X = <9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        y = array([2, 0, 0, ..., 0, 0, 0])\n    269         if self._final_estimator is not None:\n    270             self._final_estimator.fit(Xt, y, **fit_params)\n    271         return self\n    272 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), X=<9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 0, 0, 0]), **fit_params={})\n    229         Xt = X\n    230         for name, transform in self.steps[:-1]:\n    231             if transform is None:\n    232                 pass\n    233             elif hasattr(transform, \"fit_transform\"):\n--> 234                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt = <9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        transform.fit_transform = <bound method TruncatedSVD.fit_transform of Trun...80, n_iter=5,\n       random_state=None, tol=0.0)>\n        y = array([2, 0, 0, ..., 0, 0, 0])\n        fit_params_steps = {'lr': {}, 'scl': {}, 'svd': {}}\n        name = 'svd'\n    235             else:\n    236                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    237                               .transform(Xt)\n    238         if self._final_estimator is None:\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/decomposition/truncated_svd.py in fit_transform(self=TruncatedSVD(algorithm='randomized', n_components=180, n_iter=5,\n       random_state=None, tol=0.0), X=<9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 0, 0, 0]))\n    168             if k >= n_features:\n    169                 raise ValueError(\"n_components must be < n_features;\"\n    170                                  \" got %d >= %d\" % (k, n_features))\n    171             U, Sigma, VT = randomized_svd(X, self.n_components,\n    172                                           n_iter=self.n_iter,\n--> 173                                           random_state=random_state)\n        random_state = <mtrand.RandomState object>\n    174         else:\n    175             raise ValueError(\"unknown algorithm %r\" % self.algorithm)\n    176 \n    177         self.components_ = VT\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/utils/extmath.py in randomized_svd(M=<400266x9301 sparse matrix of type '<class 'nump...ored elements in Compressed Sparse Column format>, n_components=180, n_oversamples=10, n_iter=5, power_iteration_normalizer='auto', transpose=True, flip_sign=True, random_state=<mtrand.RandomState object>)\n    359     if transpose:\n    360         # this implementation is a bit faster with smaller shape[1]\n    361         M = M.T\n    362 \n    363     Q = randomized_range_finder(M, n_random, n_iter,\n--> 364                                 power_iteration_normalizer, random_state)\n        power_iteration_normalizer = 'auto'\n        random_state = <mtrand.RandomState object>\n    365 \n    366     # project M to the (k + p) dimensional space using the basis vectors\n    367     B = safe_sparse_dot(Q.T, M)\n    368 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/utils/extmath.py in randomized_range_finder(A=<400266x9301 sparse matrix of type '<class 'nump...ored elements in Compressed Sparse Column format>, size=190, n_iter=5, power_iteration_normalizer='LU', random_state=<mtrand.RandomState object>)\n    253     for i in range(n_iter):\n    254         if power_iteration_normalizer == 'none':\n    255             Q = safe_sparse_dot(A, Q)\n    256             Q = safe_sparse_dot(A.T, Q)\n    257         elif power_iteration_normalizer == 'LU':\n--> 258             Q, _ = linalg.lu(safe_sparse_dot(A, Q), permute_l=True)\n        Q = array([[-0.12371876, -0.6255367 , -0.45513213, .... -0.24736285,\n        -0.98142483,  0.59128062]])\n        _ = undefined\n        A = <400266x9301 sparse matrix of type '<class 'nump...ored elements in Compressed Sparse Column format>\n    259             Q, _ = linalg.lu(safe_sparse_dot(A.T, Q), permute_l=True)\n    260         elif power_iteration_normalizer == 'QR':\n    261             Q, _ = linalg.qr(safe_sparse_dot(A, Q), mode='economic')\n    262             Q, _ = linalg.qr(safe_sparse_dot(A.T, Q), mode='economic')\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/scipy/linalg/decomp_lu.py in lu(a=array([[ 0.        ,  0.        ,  0.        , ....  1.23625534,\n        -1.18298639,  0.12343751]]), permute_l=True, overwrite_a=False, check_finite=True)\n    180         a1 = asarray(a)\n    181     if len(a1.shape) != 2:\n    182         raise ValueError('expected matrix')\n    183     overwrite_a = overwrite_a or (_datacopied(a1, a))\n    184     flu, = get_flinalg_funcs(('lu',), (a1,))\n--> 185     p, l, u, info = flu(a1, permute_l=permute_l, overwrite_a=overwrite_a)\n        p = undefined\n        l = undefined\n        u = undefined\n        info = undefined\n        flu = <fortran object>\n        a1 = array([[ 0.        ,  0.        ,  0.        , ....  1.23625534,\n        -1.18298639,  0.12343751]])\n        permute_l = True\n        overwrite_a = False\n    186     if info < 0:\n    187         raise ValueError('illegal value in %d-th argument of '\n    188                                             'internal lu.getrf' % -info)\n    189     if permute_l:\n\nMemoryError: \n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibMemoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5b5d120b7869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr_svd_gridsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_ctv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x_ctv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/dhiraa/sarvam/text_classification/ensembling/spooky/lr.py\u001b[0m in \u001b[0;36mlr_svd_gridsearch\u001b[0;34m(train_x, train_y, val_x, val_y)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Fit Grid Search Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# we can use the full data here but im only using xtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best score: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters set:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibMemoryError\u001b[0m: JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f351acadf60, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/mageswarand/anaconda3/envs/tensorflow1.0/l...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/magesw.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f351acadf60, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/mageswarand/anaconda3/envs/tensorflow1.0/l...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/magesw.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 24, 19, 46, 39, 337264), 'msg_id': '1669C9F0206B4967BF4A889EE8AAFCBD', 'msg_type': 'execute_request', 'session': '2986DFA3063045FB8F031660E5F24205', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1669C9F0206B4967BF4A889EE8AAFCBD', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'2986DFA3063045FB8F031660E5F24205']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 24, 19, 46, 39, 337264), 'msg_id': '1669C9F0206B4967BF4A889EE8AAFCBD', 'msg_type': 'execute_request', 'session': '2986DFA3063045FB8F031660E5F24205', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1669C9F0206B4967BF4A889EE8AAFCBD', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'2986DFA3063045FB8F031660E5F24205'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 24, 19, 46, 39, 337264), 'msg_id': '1669C9F0206B4967BF4A889EE8AAFCBD', 'msg_type': 'execute_request', 'session': '2986DFA3063045FB8F031660E5F24205', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1669C9F0206B4967BF4A889EE8AAFCBD', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-24-5b5d120b7869>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f348b7153c8, executi..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f351266d030, file \"<ipython-input-24-5b5d120b7869>\", line 1>\n        result = <ExecutionResult object at 7f348b7153c8, executi..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f351266d030, file \"<ipython-input-24-5b5d120b7869>\", line 1>, result=<ExecutionResult object at 7f348b7153c8, executi..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f351266d030, file \"<ipython-input-24-5b5d120b7869>\", line 1>\n        self.user_global_ns = {'In': ['', \"get_ipython().magic('load_ext autoreload')\\nget_i...)\\nfrom kaggle.dataset.spooky import SpookyDataset\", 'from ensembling.spooky.tfidf import tfidf, count...embling.spooky.xgboost import xgbst, xgbst_on_vec', 'import xgboost as xgb\\nfrom xgboost.sklearn import XGBClassifier', 'import xgboost as xgb\\nfrom xgb.sklearn import XGBClassifier', 'import xgboost as xgb\\nxgb.XGBClassifier', 'import xgboost as xgb\\nxgb.XGBClassifier', '# import xgboost as xgb\\n# xgb.XGBClassifier', 'import xgboost as xgb\\nxgb.XGBClassifier', 'from ensembling.spooky.tfidf import tfidf, count...ensembling.spooky.tree import xgbst, xgbst_on_vec', '# Use the sarvam utils to load the data set and ..._label()\\n\\ntext_x = dataframe.get_test_text_data()', 'train_x_tfidf, val_x_tfidf = tfidf(train_x, val_x)', 'lr(train_x_tfidf, train_y, val_x_tfidf, val_y)', 'train_x_ctv, val_x_ctv = count_vec(train_x, val_x)', 'lr(train_x_ctv, train_y, val_x_ctv, val_y)', 'xgbst_on_vec(train_x_tfidf, train_y, val_x_tfidf, val_y)', 'xgbst_on_vec(train_x_ctv, train_y, val_x_ctv, val_y)', 'xgbst(train_x_svd_scl, train_y, val_x_svd_scl, val_y)', 'train_x_svd_scl, val_x_svd_scl =  svd(train_x_tfidf, val_x_tfidf)', 'xgbst(train_x_svd_scl, train_y, val_x_svd_scl, val_y)', ...], 'Out': {}, 'SpookyDataset': <class 'kaggle.dataset.spooky.SpookyDataset'>, '_': '', '__': '', '___': '', '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '__doc__': 'Automatically created module for IPython interactive environment', '__loader__': None, ...}\n        self.user_ns = {'In': ['', \"get_ipython().magic('load_ext autoreload')\\nget_i...)\\nfrom kaggle.dataset.spooky import SpookyDataset\", 'from ensembling.spooky.tfidf import tfidf, count...embling.spooky.xgboost import xgbst, xgbst_on_vec', 'import xgboost as xgb\\nfrom xgboost.sklearn import XGBClassifier', 'import xgboost as xgb\\nfrom xgb.sklearn import XGBClassifier', 'import xgboost as xgb\\nxgb.XGBClassifier', 'import xgboost as xgb\\nxgb.XGBClassifier', '# import xgboost as xgb\\n# xgb.XGBClassifier', 'import xgboost as xgb\\nxgb.XGBClassifier', 'from ensembling.spooky.tfidf import tfidf, count...ensembling.spooky.tree import xgbst, xgbst_on_vec', '# Use the sarvam utils to load the data set and ..._label()\\n\\ntext_x = dataframe.get_test_text_data()', 'train_x_tfidf, val_x_tfidf = tfidf(train_x, val_x)', 'lr(train_x_tfidf, train_y, val_x_tfidf, val_y)', 'train_x_ctv, val_x_ctv = count_vec(train_x, val_x)', 'lr(train_x_ctv, train_y, val_x_ctv, val_y)', 'xgbst_on_vec(train_x_tfidf, train_y, val_x_tfidf, val_y)', 'xgbst_on_vec(train_x_ctv, train_y, val_x_ctv, val_y)', 'xgbst(train_x_svd_scl, train_y, val_x_svd_scl, val_y)', 'train_x_svd_scl, val_x_svd_scl =  svd(train_x_tfidf, val_x_tfidf)', 'xgbst(train_x_svd_scl, train_y, val_x_svd_scl, val_y)', ...], 'Out': {}, 'SpookyDataset': <class 'kaggle.dataset.spooky.SpookyDataset'>, '_': '', '__': '', '___': '', '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '__doc__': 'Automatically created module for IPython interactive environment', '__loader__': None, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/opt/dhiraa/sarvam/text_classification/ensembling/spooky/<ipython-input-24-5b5d120b7869> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/opt/dhiraa/sarvam/text_classification/ensembling/spooky/lr.py in lr_svd_gridsearch(train_x=<18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, train_y=array([2, 0, 0, ..., 2, 2, 2]), val_x=<980x400266 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, val_y=array([2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0, 2,...       1, 1, 1, 1, 0, 2, 1, 2, 2, 1, 2, 2, 2, 2]))\n     39     # Initialize Grid Search Model\n     40     model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n     41                          verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n     42 \n     43     # Fit Grid Search Model\n---> 44     model.fit(train_x, train_y)  # we can use the full data here but im only using xtrain\n        model.fit = <bound method GridSearchCV.fit of GridSearchCV(c...ter=False, needs_proba=True),\n       verbose=10)>\n        train_x = <18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>\n        train_y = array([2, 0, 0, ..., 2, 2, 2])\n     45     print(\"Best score: %0.3f\" % model.best_score_)\n     46     print(\"Best parameters set:\")\n     47     best_parameters = model.best_estimator_.get_params()\n     48     for param_name in sorted(param_grid.keys()):\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=2, error_score='raise',\n       e...tter=False, needs_proba=True),\n       verbose=10), X=<18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 2, 2, 2]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...ter=False, needs_proba=True),\n       verbose=10)>\n        X = <18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>\n        y = array([2, 0, 0, ..., 2, 2, 2])\n        groups = None\n        self.param_grid = {'lr__C': [0.1, 1.0, 10], 'lr__penalty': ['l1', 'l2'], 'svd__n_components': [120, 180]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=2, error_score='raise',\n       e...tter=False, needs_proba=True),\n       verbose=10), X=<18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 2, 2, 2]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Sun Dec 24 20:01:04 2017\nPID: 29934Python 3.6.1: /home/mageswarand/anaconda3/envs/tensorflow1.0/bin/python\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), <18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, array([2, 0, 0, ..., 2, 2, 2]), make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True), array([   0,    1,    2, ..., 9383, 9389, 9392]), array([ 9209,  9210,  9213, ..., 18596, 18597, 18598]), 10, {'lr__C': 1.0, 'lr__penalty': 'l2', 'svd__n_components': 180}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), <18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, array([2, 0, 0, ..., 2, 2, 2]), make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True), array([   0,    1,    2, ..., 9383, 9389, 9392]), array([ 9209,  9210,  9213, ..., 18596, 18597, 18598]), 10, {'lr__C': 1.0, 'lr__penalty': 'l2', 'svd__n_components': 180})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), X=<18599x400266 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 2, 2, 2]), scorer=make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True), train=array([   0,    1,    2, ..., 9383, 9389, 9392]), test=array([ 9209,  9210,  9213, ..., 18596, 18597, 18598]), verbose=10, parameters={'lr__C': 1.0, 'lr__penalty': 'l2', 'svd__n_components': 180}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('....0001,\n          verbose=0, warm_start=False))])>\n        X_train = <9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        y_train = array([2, 0, 0, ..., 0, 0, 0])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), X=<9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 0, 0, 0]), **fit_params={})\n    263         Returns\n    264         -------\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n--> 268         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(steps=[(....0001,\n          verbose=0, warm_start=False))])>\n        X = <9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        y = array([2, 0, 0, ..., 0, 0, 0])\n    269         if self._final_estimator is not None:\n    270             self._final_estimator.fit(Xt, y, **fit_params)\n    271         return self\n    272 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(steps=[('svd', TruncatedSVD(algorithm='...0.0001,\n          verbose=0, warm_start=False))]), X=<9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 0, 0, 0]), **fit_params={})\n    229         Xt = X\n    230         for name, transform in self.steps[:-1]:\n    231             if transform is None:\n    232                 pass\n    233             elif hasattr(transform, \"fit_transform\"):\n--> 234                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt = <9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>\n        transform.fit_transform = <bound method TruncatedSVD.fit_transform of Trun...80, n_iter=5,\n       random_state=None, tol=0.0)>\n        y = array([2, 0, 0, ..., 0, 0, 0])\n        fit_params_steps = {'lr': {}, 'scl': {}, 'svd': {}}\n        name = 'svd'\n    235             else:\n    236                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    237                               .transform(Xt)\n    238         if self._final_estimator is None:\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/decomposition/truncated_svd.py in fit_transform(self=TruncatedSVD(algorithm='randomized', n_components=180, n_iter=5,\n       random_state=None, tol=0.0), X=<9301x400266 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 0, 0, 0]))\n    168             if k >= n_features:\n    169                 raise ValueError(\"n_components must be < n_features;\"\n    170                                  \" got %d >= %d\" % (k, n_features))\n    171             U, Sigma, VT = randomized_svd(X, self.n_components,\n    172                                           n_iter=self.n_iter,\n--> 173                                           random_state=random_state)\n        random_state = <mtrand.RandomState object>\n    174         else:\n    175             raise ValueError(\"unknown algorithm %r\" % self.algorithm)\n    176 \n    177         self.components_ = VT\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/utils/extmath.py in randomized_svd(M=<400266x9301 sparse matrix of type '<class 'nump...ored elements in Compressed Sparse Column format>, n_components=180, n_oversamples=10, n_iter=5, power_iteration_normalizer='auto', transpose=True, flip_sign=True, random_state=<mtrand.RandomState object>)\n    359     if transpose:\n    360         # this implementation is a bit faster with smaller shape[1]\n    361         M = M.T\n    362 \n    363     Q = randomized_range_finder(M, n_random, n_iter,\n--> 364                                 power_iteration_normalizer, random_state)\n        power_iteration_normalizer = 'auto'\n        random_state = <mtrand.RandomState object>\n    365 \n    366     # project M to the (k + p) dimensional space using the basis vectors\n    367     B = safe_sparse_dot(Q.T, M)\n    368 \n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/sklearn/utils/extmath.py in randomized_range_finder(A=<400266x9301 sparse matrix of type '<class 'nump...ored elements in Compressed Sparse Column format>, size=190, n_iter=5, power_iteration_normalizer='LU', random_state=<mtrand.RandomState object>)\n    253     for i in range(n_iter):\n    254         if power_iteration_normalizer == 'none':\n    255             Q = safe_sparse_dot(A, Q)\n    256             Q = safe_sparse_dot(A.T, Q)\n    257         elif power_iteration_normalizer == 'LU':\n--> 258             Q, _ = linalg.lu(safe_sparse_dot(A, Q), permute_l=True)\n        Q = array([[-0.12371876, -0.6255367 , -0.45513213, .... -0.24736285,\n        -0.98142483,  0.59128062]])\n        _ = undefined\n        A = <400266x9301 sparse matrix of type '<class 'nump...ored elements in Compressed Sparse Column format>\n    259             Q, _ = linalg.lu(safe_sparse_dot(A.T, Q), permute_l=True)\n    260         elif power_iteration_normalizer == 'QR':\n    261             Q, _ = linalg.qr(safe_sparse_dot(A, Q), mode='economic')\n    262             Q, _ = linalg.qr(safe_sparse_dot(A.T, Q), mode='economic')\n\n...........................................................................\n/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/scipy/linalg/decomp_lu.py in lu(a=array([[ 0.        ,  0.        ,  0.        , ....  1.23625534,\n        -1.18298639,  0.12343751]]), permute_l=True, overwrite_a=False, check_finite=True)\n    180         a1 = asarray(a)\n    181     if len(a1.shape) != 2:\n    182         raise ValueError('expected matrix')\n    183     overwrite_a = overwrite_a or (_datacopied(a1, a))\n    184     flu, = get_flinalg_funcs(('lu',), (a1,))\n--> 185     p, l, u, info = flu(a1, permute_l=permute_l, overwrite_a=overwrite_a)\n        p = undefined\n        l = undefined\n        u = undefined\n        info = undefined\n        flu = <fortran object>\n        a1 = array([[ 0.        ,  0.        ,  0.        , ....  1.23625534,\n        -1.18298639,  0.12343751]])\n        permute_l = True\n        overwrite_a = False\n    186     if info < 0:\n    187         raise ValueError('illegal value in %d-th argument of '\n    188                                             'internal lu.getrf' % -info)\n    189     if permute_l:\n\nMemoryError: \n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "lr_svd_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.567 \n"
     ]
    }
   ],
   "source": [
    "mnb(train_x_tfidf, train_y, val_x_tfidf, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.449 \n"
     ]
    }
   ],
   "source": [
    "mnb(train_x_ctv, train_y, val_x_ctv, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[CV] nb__alpha=0.01 ..................................................\n",
      "[CV] nb__alpha=0.001 .................................................\n",
      "[CV] nb__alpha=0.001 .................................................\n",
      "[CV] nb__alpha=0.01 ..................................................\n",
      "[CV] ................. nb__alpha=0.001, score=-0.625190, total=   0.1s\n",
      "[CV] ................. nb__alpha=0.001, score=-0.597814, total=   0.1s\n",
      "[CV] .................. nb__alpha=0.01, score=-0.515710, total=   0.1s\n",
      "[CV] nb__alpha=0.1 ...................................................\n",
      "[CV] .................. nb__alpha=0.01, score=-0.496752, total=   0.1s\n",
      "[CV] nb__alpha=1 .....................................................\n",
      "[CV] nb__alpha=0.1 ...................................................\n",
      "[CV] nb__alpha=1 .....................................................\n",
      "[CV] ................... nb__alpha=0.1, score=-0.492501, total=   0.0s\n",
      "[CV] ..................... nb__alpha=1, score=-0.660826, total=   0.0s\n",
      "[CV] nb__alpha=10 ....................................................\n",
      "[CV] nb__alpha=100 ...................................................\n",
      "[CV] ..................... nb__alpha=1, score=-0.657716, total=   0.0s\n",
      "[CV] ................... nb__alpha=0.1, score=-0.481711, total=   0.1s\n",
      "[CV] ................... nb__alpha=100, score=-1.066351, total=   0.0s\n",
      "[CV] .................... nb__alpha=10, score=-0.945759, total=   0.0s\n",
      "[CV] nb__alpha=100 ...................................................\n",
      "[CV] nb__alpha=10 ....................................................\n",
      "[CV] ................... nb__alpha=100, score=-1.066400, total=   0.0s\n",
      "[CV] .................... nb__alpha=10, score=-0.945723, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1818s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  12 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    0.3s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.487\n",
      "Best parameters set:\n",
      "\tnb__alpha: 0.1\n"
     ]
    }
   ],
   "source": [
    "mnb_gridsearch(train_x_tfidf, train_y, val_x_tfidf, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[CV] nb__alpha=0.001 .................................................\n",
      "[CV] nb__alpha=0.001 .................................................\n",
      "[CV] nb__alpha=0.01 ..................................................\n",
      "[CV] nb__alpha=0.01 ..................................................\n",
      "[CV] ................. nb__alpha=0.001, score=-1.424465, total=   0.3s\n",
      "[CV] ................. nb__alpha=0.001, score=-1.486892, total=   0.3s\n",
      "[CV] nb__alpha=0.1 ...................................................\n",
      "[CV] nb__alpha=0.1 ...................................................\n",
      "[CV] .................. nb__alpha=0.01, score=-1.119090, total=   0.3s\n",
      "[CV] .................. nb__alpha=0.01, score=-1.073956, total=   0.4s\n",
      "[CV] nb__alpha=1 .....................................................\n",
      "[CV] nb__alpha=1 .....................................................\n",
      "[CV] ................... nb__alpha=0.1, score=-0.730633, total=   0.2s\n",
      "[CV] nb__alpha=10 ....................................................\n",
      "[CV] ................... nb__alpha=0.1, score=-0.756455, total=   0.2s\n",
      "[CV] nb__alpha=10 ....................................................\n",
      "[CV] ..................... nb__alpha=1, score=-0.510067, total=   0.2s\n",
      "[CV] nb__alpha=100 ...................................................\n",
      "[CV] ..................... nb__alpha=1, score=-0.498185, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    0.8s remaining:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] nb__alpha=100 ...................................................\n",
      "[CV] .................... nb__alpha=10, score=-0.569758, total=   0.2s\n",
      "[CV] ................... nb__alpha=100, score=-0.853411, total=   0.1s\n",
      "[CV] ................... nb__alpha=100, score=-0.853695, total=   0.2s\n",
      "[CV] .................... nb__alpha=10, score=-0.567352, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of  12 | elapsed:    0.8s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.504\n",
      "Best parameters set:\n",
      "\tnb__alpha: 1\n"
     ]
    }
   ],
   "source": [
    "mnb_gridsearch(train_x_ctv, train_y, val_x_ctv, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_nb_features\n",
    "train_x_word_tfidf_nb_features, val_x_word_tfidf_nb_features =  generate_nb_features(train_x_word_tfidf, train_y, val_x_word_tfidf, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(980, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x_word_tfidf_nb_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.705 \n"
     ]
    }
   ],
   "source": [
    "svm(train_x_svd_scl, train_y, val_x_svd_scl, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.790 \n"
     ]
    }
   ],
   "source": [
    "xgbst_on_vec(train_x_tfidf, train_y, val_x_tfidf, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.784 \n"
     ]
    }
   ],
   "source": [
    "xgbst_on_vec(train_x_ctv, train_y, val_x_ctv, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.751 \n"
     ]
    }
   ],
   "source": [
    "xgbst(train_x_svd_scl, train_y, val_x_svd_scl, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove.840B.300d.txt\t       GoogleNews-vectors-negative300.bin\r\n",
      "glove.840B.300d.txt.cache.npy  GoogleNews-vectors-negative300.bin.gz\r\n",
      "glove.840B.300d.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /opt/datasets/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.659 \n"
     ]
    }
   ],
   "source": [
    "xgbst(train_x_glove, train_y, val_x_glove, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18599 samples, validate on 980 samples\n",
      "Epoch 1/5\n",
      "18599/18599 [==============================] - 16s - loss: 0.8964 - val_loss: 0.6689\n",
      "Epoch 2/5\n",
      "18599/18599 [==============================] - 2s - loss: 0.6801 - val_loss: 0.6440\n",
      "Epoch 3/5\n",
      "18599/18599 [==============================] - 2s - loss: 0.6185 - val_loss: 0.6250\n",
      "Epoch 4/5\n",
      "18599/18599 [==============================] - 2s - loss: 0.5792 - val_loss: 0.6069\n",
      "Epoch 5/5\n",
      "18599/18599 [==============================] - 1s - loss: 0.5349 - val_loss: 0.6276\n"
     ]
    }
   ],
   "source": [
    "simple_net(train_x_glove_scl, train_y_one_hot_encoded, val_x_glove_scl, val_y_one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25943/25943 [00:00<00:00, 351968.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18599 samples, validate on 980 samples\n",
      "Epoch 1/100\n",
      "18599/18599 [==============================] - 153s - loss: 0.9719 - val_loss: 0.8440\n",
      "Epoch 2/100\n",
      "18599/18599 [==============================] - 165s - loss: 0.8520 - val_loss: 0.7198\n",
      "Epoch 3/100\n",
      "18599/18599 [==============================] - 168s - loss: 0.7864 - val_loss: 0.6656\n",
      "Epoch 4/100\n",
      "18599/18599 [==============================] - 150s - loss: 0.7510 - val_loss: 0.6594\n",
      "Epoch 5/100\n",
      "18599/18599 [==============================] - 149s - loss: 0.7136 - val_loss: 0.6283\n",
      "Epoch 6/100\n",
      "18599/18599 [==============================] - 149s - loss: 0.6805 - val_loss: 0.5926\n",
      "Epoch 7/100\n",
      "18599/18599 [==============================] - 149s - loss: 0.6427 - val_loss: 0.5881\n",
      "Epoch 8/100\n",
      "18599/18599 [==============================] - 149s - loss: 0.6104 - val_loss: 0.5591\n",
      "Epoch 9/100\n",
      "18599/18599 [==============================] - 151s - loss: 0.5823 - val_loss: 0.5587\n",
      "Epoch 10/100\n",
      "18599/18599 [==============================] - 149s - loss: 0.5558 - val_loss: 0.5179\n",
      "Epoch 11/100\n",
      "18599/18599 [==============================] - 150s - loss: 0.5261 - val_loss: 0.5198\n",
      "Epoch 12/100\n",
      "18599/18599 [==============================] - 151s - loss: 0.5117 - val_loss: 0.5389\n",
      "Epoch 13/100\n",
      "18599/18599 [==============================] - 151s - loss: 0.4845 - val_loss: 0.5550\n",
      "Epoch 14/100\n",
      "18599/18599 [==============================] - 162s - loss: 0.4601 - val_loss: 0.5041\n",
      "Epoch 15/100\n",
      "18599/18599 [==============================] - 149s - loss: 0.4452 - val_loss: 0.5259\n",
      "Epoch 16/100\n",
      "18599/18599 [==============================] - 183s - loss: 0.4220 - val_loss: 0.5207\n",
      "Epoch 17/100\n",
      "18599/18599 [==============================] - 185s - loss: 0.4167 - val_loss: 0.4982\n",
      "Epoch 18/100\n",
      "18599/18599 [==============================] - 176s - loss: 0.3889 - val_loss: 0.4988\n",
      "Epoch 19/100\n",
      "18599/18599 [==============================] - 175s - loss: 0.3819 - val_loss: 0.4816\n",
      "Epoch 20/100\n",
      "18599/18599 [==============================] - 175s - loss: 0.3636 - val_loss: 0.4982\n",
      "Epoch 21/100\n",
      "18599/18599 [==============================] - 170s - loss: 0.3616 - val_loss: 0.4936\n",
      "Epoch 22/100\n",
      "18599/18599 [==============================] - 169s - loss: 0.3339 - val_loss: 0.5144\n",
      "Epoch 23/100\n",
      "18599/18599 [==============================] - 172s - loss: 0.3325 - val_loss: 0.4982\n"
     ]
    }
   ],
   "source": [
    "bilstm_net(train_x, train_y_one_hot_encoded,\n",
    "               val_x, val_y_one_hot_encoded, embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import xgboost as xgb\n",
    "from tc_utils.losses import multiclass_logloss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:56:57] INFO Found 3 classes\n",
      "[08:56:57] INFO Training Level 0 Fold # 1. Model # 0\n",
      "[08:56:57] INFO Predicting Level 0. Fold # 1. Model # 0\n",
      "[08:56:57] INFO Level 0. Fold # 1. Model # 0. Validation Score = 0.675661\n",
      "[08:56:57] INFO Training Level 0 Fold # 2. Model # 0\n",
      "[08:56:58] INFO Predicting Level 0. Fold # 2. Model # 0\n",
      "[08:56:58] INFO Level 0. Fold # 2. Model # 0. Validation Score = 0.660172\n",
      "[08:56:58] INFO Training Level 0 Fold # 3. Model # 0\n",
      "[08:56:58] INFO Predicting Level 0. Fold # 3. Model # 0\n",
      "[08:56:58] INFO Level 0. Fold # 3. Model # 0. Validation Score = 0.668261\n",
      "[08:56:58] INFO Level 0. Model # 0. Mean Score = 0.668031. Std Dev = 0.006325\n",
      "[08:56:58] INFO Training Level 0 Fold # 1. Model # 1\n",
      "[08:57:01] INFO Predicting Level 0. Fold # 1. Model # 1\n",
      "[08:57:01] INFO Level 0. Fold # 1. Model # 1. Validation Score = 0.577250\n",
      "[08:57:01] INFO Training Level 0 Fold # 2. Model # 1\n",
      "[08:57:03] INFO Predicting Level 0. Fold # 2. Model # 1\n",
      "[08:57:03] INFO Level 0. Fold # 2. Model # 1. Validation Score = 0.544846\n",
      "[08:57:03] INFO Training Level 0 Fold # 3. Model # 1\n",
      "[08:57:06] INFO Predicting Level 0. Fold # 3. Model # 1\n",
      "[08:57:06] INFO Level 0. Fold # 3. Model # 1. Validation Score = 0.562898\n",
      "[08:57:06] INFO Level 0. Model # 1. Mean Score = 0.561665. Std Dev = 0.013258\n",
      "[08:57:06] INFO Training Level 0 Fold # 1. Model # 2\n",
      "[08:57:06] INFO Predicting Level 0. Fold # 1. Model # 2\n",
      "[08:57:06] INFO Level 0. Fold # 1. Model # 2. Validation Score = 0.467565\n",
      "[08:57:06] INFO Training Level 0 Fold # 2. Model # 2\n",
      "[08:57:06] INFO Predicting Level 0. Fold # 2. Model # 2\n",
      "[08:57:06] INFO Level 0. Fold # 2. Model # 2. Validation Score = 0.449744\n",
      "[08:57:06] INFO Training Level 0 Fold # 3. Model # 2\n",
      "[08:57:06] INFO Predicting Level 0. Fold # 3. Model # 2\n",
      "[08:57:06] INFO Level 0. Fold # 3. Model # 2. Validation Score = 0.456880\n",
      "[08:57:06] INFO Level 0. Model # 2. Mean Score = 0.458063. Std Dev = 0.007324\n",
      "[08:57:06] INFO Training Level 0 Fold # 1. Model # 3\n",
      "[08:57:06] INFO Predicting Level 0. Fold # 1. Model # 3\n",
      "[08:57:06] INFO Level 0. Fold # 1. Model # 3. Validation Score = 0.490305\n",
      "[08:57:06] INFO Training Level 0 Fold # 2. Model # 3\n",
      "[08:57:06] INFO Predicting Level 0. Fold # 2. Model # 3\n",
      "[08:57:06] INFO Level 0. Fold # 2. Model # 3. Validation Score = 0.442995\n",
      "[08:57:06] INFO Training Level 0 Fold # 3. Model # 3\n",
      "[08:57:06] INFO Predicting Level 0. Fold # 3. Model # 3\n",
      "[08:57:06] INFO Level 0. Fold # 3. Model # 3. Validation Score = 0.496304\n",
      "[08:57:06] INFO Level 0. Model # 3. Mean Score = 0.476535. Std Dev = 0.023842\n",
      "[08:57:06] INFO Saving predictions for level # 0\n",
      "[08:57:06] INFO Training Level 1 Fold # 1. Model # 0\n",
      "[08:57:11] INFO Predicting Level 1. Fold # 1. Model # 0\n",
      "[08:57:11] INFO Level 1. Fold # 1. Model # 0. Validation Score = 0.443273\n",
      "[08:57:11] INFO Training Level 1 Fold # 2. Model # 0\n",
      "[08:57:16] INFO Predicting Level 1. Fold # 2. Model # 0\n",
      "[08:57:16] INFO Level 1. Fold # 2. Model # 0. Validation Score = 0.415367\n",
      "[08:57:16] INFO Training Level 1 Fold # 3. Model # 0\n",
      "[08:57:23] INFO Predicting Level 1. Fold # 3. Model # 0\n",
      "[08:57:23] INFO Level 1. Fold # 3. Model # 0. Validation Score = 0.444744\n",
      "[08:57:23] INFO Level 1. Model # 0. Mean Score = 0.434461. Std Dev = 0.013515\n",
      "[08:57:23] INFO Saving predictions for level # 1\n",
      "[08:57:23] INFO Training Fulldata Level 0. Model # 0\n",
      "[08:57:25] INFO Predicting Test Level 0. Model # 0\n",
      "[08:57:25] INFO Training Fulldata Level 0. Model # 1\n",
      "[08:57:29] INFO Predicting Test Level 0. Model # 1\n",
      "[08:57:29] INFO Training Fulldata Level 0. Model # 2\n",
      "[08:57:29] INFO Predicting Test Level 0. Model # 2\n",
      "[08:57:29] INFO Training Fulldata Level 0. Model # 3\n",
      "[08:57:29] INFO Predicting Test Level 0. Model # 3\n",
      "[08:57:29] INFO Training Fulldata Level 1. Model # 0\n",
      "[08:57:37] INFO Predicting Test Level 1. Model # 0\n"
     ]
    }
   ],
   "source": [
    "# specify the data to be used for every level of ensembling:\n",
    "train_data_dict = {0: [train_x_tfidf, train_x_ctv, train_x_tfidf, train_x_ctv], 1: [train_x_glove]}\n",
    "test_data_dict = {0: [val_x_tfidf, val_x_ctv, val_x_tfidf, val_x_ctv], 1: [val_x_glove]}\n",
    "\n",
    "model_dict = {0: [LogisticRegression(), LogisticRegression(), MultinomialNB(alpha=0.1), MultinomialNB()],\n",
    "\n",
    "              1: [xgb.XGBClassifier(silent=True, n_estimators=120, max_depth=7)]}\n",
    "\n",
    "ens = Ensembler(model_dict=model_dict, num_folds=3, task_type='classification',\n",
    "                optimize=multiclass_logloss, lower_is_better=True, save_path='')\n",
    "\n",
    "ens.fit(train_data_dict, train_y, lentrain=train_x_glove.shape[0])\n",
    "preds = ens.predict(test_data_dict, lentest=val_x_glove.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39777932094927465"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check error:\n",
    "multiclass_logloss(val_y, preds[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sarvam.eda.meta_features.cnn_features import get_cnn_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 10)           300000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 98, 16)            496       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 300,819\n",
      "Trainable params: 300,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14096 samples, validate on 1567 samples\n",
      "Epoch 1/10\n",
      "Epoch 00000: val_loss improved from inf to 0.94535, saving model to /tmp/nn_model.h5\n",
      "24s - loss: 1.0500 - acc: 0.4454 - val_loss: 0.9453 - val_acc: 0.5290\n",
      "Epoch 2/10\n",
      "Epoch 00001: val_loss improved from 0.94535 to 0.69920, saving model to /tmp/nn_model.h5\n",
      "3s - loss: 0.8104 - acc: 0.5950 - val_loss: 0.6992 - val_acc: 0.6924\n",
      "Epoch 3/10\n",
      "Epoch 00002: val_loss improved from 0.69920 to 0.49061, saving model to /tmp/nn_model.h5\n",
      "3s - loss: 0.5336 - acc: 0.8056 - val_loss: 0.4906 - val_acc: 0.8181\n",
      "Epoch 4/10\n",
      "Epoch 00003: val_loss improved from 0.49061 to 0.44165, saving model to /tmp/nn_model.h5\n",
      "3s - loss: 0.3097 - acc: 0.8911 - val_loss: 0.4416 - val_acc: 0.8277\n",
      "Epoch 5/10\n",
      "Epoch 00004: val_loss did not improve\n",
      "3s - loss: 0.2041 - acc: 0.9316 - val_loss: 0.4481 - val_acc: 0.8334\n",
      "Epoch 6/10\n",
      "Epoch 00005: val_loss did not improve\n",
      "3s - loss: 0.1471 - acc: 0.9517 - val_loss: 0.4813 - val_acc: 0.8226\n",
      "Epoch 7/10\n",
      "Epoch 00006: val_loss did not improve\n",
      "3s - loss: 0.1111 - acc: 0.9674 - val_loss: 0.5434 - val_acc: 0.8207\n",
      "Epoch 8/10\n",
      "Epoch 00007: val_loss did not improve\n",
      "3s - loss: 0.0876 - acc: 0.9732 - val_loss: 0.5967 - val_acc: 0.8098\n",
      "Epoch 9/10\n",
      "Epoch 00008: val_loss did not improve\n",
      "3s - loss: 0.0700 - acc: 0.9799 - val_loss: 0.6837 - val_acc: 0.7996\n",
      "Epoch 10/10\n",
      "Epoch 00009: val_loss did not improve\n",
      "3s - loss: 0.0550 - acc: 0.9843 - val_loss: 0.7478 - val_acc: 0.7932\n",
      "------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 10)           300000    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 98, 16)            496       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 300,819\n",
      "Trainable params: 300,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14096 samples, validate on 1567 samples\n",
      "Epoch 1/10\n",
      "Epoch 00000: val_loss improved from inf to 0.85522, saving model to /tmp/nn_model.h5\n",
      "4s - loss: 1.0255 - acc: 0.4655 - val_loss: 0.8552 - val_acc: 0.5948\n",
      "Epoch 2/10\n",
      "Epoch 00001: val_loss improved from 0.85522 to 0.69181, saving model to /tmp/nn_model.h5\n",
      "4s - loss: 0.7430 - acc: 0.6249 - val_loss: 0.6918 - val_acc: 0.6975\n",
      "Epoch 3/10\n",
      "Epoch 00002: val_loss improved from 0.69181 to 0.53412, saving model to /tmp/nn_model.h5\n",
      "4s - loss: 0.5206 - acc: 0.7909 - val_loss: 0.5341 - val_acc: 0.7900\n",
      "Epoch 4/10\n",
      "Epoch 00003: val_loss improved from 0.53412 to 0.47409, saving model to /tmp/nn_model.h5\n",
      "5s - loss: 0.3290 - acc: 0.8801 - val_loss: 0.4741 - val_acc: 0.8271\n",
      "Epoch 5/10\n",
      "Epoch 00004: val_loss improved from 0.47409 to 0.46682, saving model to /tmp/nn_model.h5\n",
      "4s - loss: 0.2209 - acc: 0.9254 - val_loss: 0.4668 - val_acc: 0.8360\n",
      "Epoch 6/10\n",
      "Epoch 00005: val_loss did not improve\n",
      "4s - loss: 0.1566 - acc: 0.9497 - val_loss: 0.4826 - val_acc: 0.8379\n",
      "Epoch 7/10\n",
      "Epoch 00006: val_loss did not improve\n",
      "5s - loss: 0.1171 - acc: 0.9654 - val_loss: 0.5146 - val_acc: 0.8405\n",
      "Epoch 8/10\n",
      "Epoch 00007: val_loss did not improve\n",
      "4s - loss: 0.0897 - acc: 0.9740 - val_loss: 0.5562 - val_acc: 0.8411\n",
      "Epoch 9/10\n",
      "Epoch 00008: val_loss did not improve\n",
      "4s - loss: 0.0722 - acc: 0.9782 - val_loss: 0.6052 - val_acc: 0.8302\n",
      "Epoch 10/10\n",
      "Epoch 00009: val_loss did not improve\n",
      "4s - loss: 0.0580 - acc: 0.9836 - val_loss: 0.6765 - val_acc: 0.8360\n",
      "------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 10)           300000    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 98, 16)            496       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 300,819\n",
      "Trainable params: 300,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14096 samples, validate on 1567 samples\n",
      "Epoch 1/10\n",
      "Epoch 00000: val_loss improved from inf to 0.85584, saving model to /tmp/nn_model.h5\n",
      "4s - loss: 1.0265 - acc: 0.4686 - val_loss: 0.8558 - val_acc: 0.5973\n",
      "Epoch 2/10\n",
      "Epoch 00001: val_loss improved from 0.85584 to 0.57693, saving model to /tmp/nn_model.h5\n",
      "4s - loss: 0.6740 - acc: 0.7070 - val_loss: 0.5769 - val_acc: 0.7722\n",
      "Epoch 3/10\n",
      "Epoch 00002: val_loss improved from 0.57693 to 0.46327, saving model to /tmp/nn_model.h5\n",
      "4s - loss: 0.4132 - acc: 0.8500 - val_loss: 0.4633 - val_acc: 0.8258\n",
      "Epoch 4/10\n",
      "Epoch 00003: val_loss improved from 0.46327 to 0.42565, saving model to /tmp/nn_model.h5\n",
      "4s - loss: 0.2738 - acc: 0.9083 - val_loss: 0.4257 - val_acc: 0.8481\n",
      "Epoch 5/10\n",
      "Epoch 00004: val_loss did not improve\n",
      "4s - loss: 0.1935 - acc: 0.9379 - val_loss: 0.4339 - val_acc: 0.8443\n",
      "Epoch 6/10\n",
      "Epoch 00005: val_loss did not improve\n",
      "4s - loss: 0.1438 - acc: 0.9564 - val_loss: 0.4577 - val_acc: 0.8488\n",
      "Epoch 7/10\n",
      "Epoch 00006: val_loss did not improve\n",
      "4s - loss: 0.1100 - acc: 0.9661 - val_loss: 0.4922 - val_acc: 0.8481\n",
      "Epoch 8/10\n",
      "Epoch 00007: val_loss did not improve\n",
      "4s - loss: 0.0853 - acc: 0.9748 - val_loss: 0.5381 - val_acc: 0.8417\n",
      "Epoch 9/10\n",
      "Epoch 00008: val_loss did not improve\n",
      "4s - loss: 0.0657 - acc: 0.9803 - val_loss: 0.5885 - val_acc: 0.8411\n",
      "Epoch 10/10\n",
      "Epoch 00009: val_loss did not improve\n",
      "4s - loss: 0.0521 - acc: 0.9852 - val_loss: 0.6509 - val_acc: 0.8347\n",
      "------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 10)           300000    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 98, 16)            496       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 300,819\n",
      "Trainable params: 300,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14096 samples, validate on 1567 samples\n",
      "Epoch 1/10\n",
      "Epoch 00000: val_loss improved from inf to 0.79902, saving model to /tmp/nn_model.h5\n",
      "4s - loss: 1.0263 - acc: 0.4780 - val_loss: 0.7990 - val_acc: 0.6886\n",
      "Epoch 2/10\n",
      "Epoch 00001: val_loss improved from 0.79902 to 0.47703, saving model to /tmp/nn_model.h5\n",
      "4s - loss: 0.5569 - acc: 0.7889 - val_loss: 0.4770 - val_acc: 0.8226\n",
      "Epoch 3/10\n",
      "Epoch 00002: val_loss improved from 0.47703 to 0.40915, saving model to /tmp/nn_model.h5\n",
      "3s - loss: 0.3180 - acc: 0.8875 - val_loss: 0.4092 - val_acc: 0.8443\n",
      "Epoch 4/10\n",
      "Epoch 00003: val_loss improved from 0.40915 to 0.40559, saving model to /tmp/nn_model.h5\n",
      "4s - loss: 0.2121 - acc: 0.9276 - val_loss: 0.4056 - val_acc: 0.8481\n",
      "Epoch 5/10\n",
      "Epoch 00004: val_loss did not improve\n",
      "4s - loss: 0.1505 - acc: 0.9508 - val_loss: 0.4279 - val_acc: 0.8513\n",
      "Epoch 6/10\n",
      "Epoch 00005: val_loss did not improve\n",
      "4s - loss: 0.1081 - acc: 0.9667 - val_loss: 0.4618 - val_acc: 0.8468\n",
      "Epoch 7/10\n",
      "Epoch 00006: val_loss did not improve\n",
      "4s - loss: 0.0801 - acc: 0.9755 - val_loss: 0.5130 - val_acc: 0.8437\n",
      "Epoch 8/10\n",
      "Epoch 00007: val_loss did not improve\n",
      "4s - loss: 0.0634 - acc: 0.9813 - val_loss: 0.5682 - val_acc: 0.8411\n",
      "Epoch 9/10\n",
      "Epoch 00008: val_loss did not improve\n",
      "4s - loss: 0.0488 - acc: 0.9862 - val_loss: 0.6267 - val_acc: 0.8341\n",
      "Epoch 10/10\n",
      "Epoch 00009: val_loss did not improve\n",
      "4s - loss: 0.0402 - acc: 0.9897 - val_loss: 0.6798 - val_acc: 0.8341\n",
      "------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 10)           300000    \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 98, 16)            496       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_5 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 300,819\n",
      "Trainable params: 300,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14097 samples, validate on 1567 samples\n",
      "Epoch 1/10\n",
      "Epoch 00000: val_loss improved from inf to 0.82892, saving model to /tmp/nn_model.h5\n",
      "5s - loss: 1.0156 - acc: 0.4834 - val_loss: 0.8289 - val_acc: 0.6605\n",
      "Epoch 2/10\n",
      "Epoch 00001: val_loss improved from 0.82892 to 0.48177, saving model to /tmp/nn_model.h5\n",
      "4s - loss: 0.5943 - acc: 0.7768 - val_loss: 0.4818 - val_acc: 0.8111\n",
      "Epoch 3/10\n",
      "Epoch 00002: val_loss improved from 0.48177 to 0.42401, saving model to /tmp/nn_model.h5\n",
      "4s - loss: 0.3323 - acc: 0.8822 - val_loss: 0.4240 - val_acc: 0.8411\n",
      "Epoch 4/10\n",
      "Epoch 00003: val_loss did not improve\n",
      "4s - loss: 0.2148 - acc: 0.9286 - val_loss: 0.4253 - val_acc: 0.8430\n",
      "Epoch 5/10\n",
      "Epoch 00004: val_loss did not improve\n",
      "4s - loss: 0.1511 - acc: 0.9512 - val_loss: 0.4552 - val_acc: 0.8411\n",
      "Epoch 6/10\n",
      "Epoch 00005: val_loss did not improve\n",
      "4s - loss: 0.1111 - acc: 0.9668 - val_loss: 0.4977 - val_acc: 0.8379\n",
      "Epoch 7/10\n",
      "Epoch 00006: val_loss did not improve\n",
      "4s - loss: 0.0824 - acc: 0.9767 - val_loss: 0.5611 - val_acc: 0.8347\n",
      "Epoch 8/10\n",
      "Epoch 00007: val_loss did not improve\n",
      "4s - loss: 0.0615 - acc: 0.9843 - val_loss: 0.6109 - val_acc: 0.8315\n",
      "Epoch 9/10\n",
      "Epoch 00008: val_loss did not improve\n",
      "4s - loss: 0.0486 - acc: 0.9874 - val_loss: 0.6633 - val_acc: 0.8264\n",
      "Epoch 10/10\n",
      "Epoch 00009: val_loss did not improve\n",
      "4s - loss: 0.0392 - acc: 0.9899 - val_loss: 0.7254 - val_acc: 0.8220\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "train_pred, test_pred, best_val_train_pred, best_val_test_pred = \\\n",
    "get_cnn_feats(train_df, test_df, TEXT_COL, CATEGORY_COL, rnd=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19579, 3), (8392, 3), (19579, 3), (8392, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred.shape, test_pred.shape, best_val_train_pred.shape, best_val_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensembling.spooky.meta_features.extra_features import *\n",
    "from ensembling.spooky.meta_features.spacy_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:36<00:00,  1.40s/it]\n",
      "100%|██████████| 26/26 [01:39<00:00,  3.81s/it]\n",
      " 35%|███▍      | 9/26 [03:52<07:18, 25.79s/it]"
     ]
    }
   ],
   "source": [
    "new_train_hand_features_df = extract_features(train_df, train_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_test_hand_features_df = extract_features(test_df, train_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spacy_features = get_spacy_features(train_df, TEXT_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8392/8392 [03:08<00:00, 44.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done creating spacy features 188.77141976356506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_spacy_features = get_spacy_features(test_df, TEXT_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_txt</th>\n",
       "      <th>tag_txt</th>\n",
       "      <th>dep_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DET NOUN PUNCT ADV PUNCT VERB PRON DET NOUN A...</td>\n",
       "      <td>DT NN , RB , VBD PRP DT NNS IN VBG DT NNS IN ...</td>\n",
       "      <td>det nsubj punct advmod punct ccomp dobj det d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRON ADV ADV VERB ADP PRON ADP DET NOUN VERB ...</td>\n",
       "      <td>PRP RB RB VBD IN PRP IN DT NN MD VB DT JJ NN .</td>\n",
       "      <td>nsubj neg advmod ROOT prep pobj mark det nsub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADP ADJ ADJ NOUN VERB DET ADJ NOUN NOUN PUNCT...</td>\n",
       "      <td>IN PRP$ JJ NN VBD DT JJ NN NN , IN WDT , IN P...</td>\n",
       "      <td>prep poss amod pobj ROOT det compound compoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADV ADJ VERB NOUN ADP PRON VERB ADP PROPN PRO...</td>\n",
       "      <td>WRB JJ VBZ NN IN PRP VBD IN NNP NNP IN DT CD ...</td>\n",
       "      <td>advmod acomp ROOT nsubj mark nsubj advcl prep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VERB NOUN ADV PUNCT ADV ADV NOUN PUNCT DET PR...</td>\n",
       "      <td>VBG NN RB , RB RB NN , DT NNP VBD PRP$ NNS : ...</td>\n",
       "      <td>advcl dobj advmod punct neg advmod dep punct ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DET NOUN VERB ADP NOUN PUNCT ADJ ADJ NOUN VER...</td>\n",
       "      <td>DT NN VBD IN NN , PRP$ JJS NNS VBN IN PRP$ JJ...</td>\n",
       "      <td>det nsubj acl prep pobj punct poss amod nsubj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DET NOUN PUNCT ADV PUNCT ADP DET NOUN PUNCT V...</td>\n",
       "      <td>DT NN , RB , IN DT NN , VBD NN IN DT NN IN AF...</td>\n",
       "      <td>det nsubj punct advmod punct prep det pobj pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DET NOUN VERB ADP NOUN ADP ADJ NOUN PUNCT</td>\n",
       "      <td>DT NN VBD IN NNS IN PRP$ NN .</td>\n",
       "      <td>det nsubj ROOT prep pobj prep poss pobj punct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PRON VERB ADP PRON VERB ADV VERB ADP PRON PUN...</td>\n",
       "      <td>PRP VBD IN PRP MD RB VB IN PRP `` NN '' IN VB...</td>\n",
       "      <td>nsubj ROOT mark nsubj aux neg ccomp prep poss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PRON VERB ADP CCONJ DET NOUN ADP NOUN PUNCT C...</td>\n",
       "      <td>PRP VBP IN CC DT NN IN NNS , CC DT NN IN NNS ...</td>\n",
       "      <td>nsubj ROOT mark preconj det nsubj prep pobj p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PRON VERB VERB ADP PRON VERB VERB ADJ NOUN PU...</td>\n",
       "      <td>PRP MD VB IN PRP MD VB PRP$ NNS : PRP MD VB T...</td>\n",
       "      <td>nsubj aux ccomp mark nsubj aux ccomp poss dob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ADV PRON VERB PRON PUNCT CCONJ PUNCT ADP DET ...</td>\n",
       "      <td>RB PRP VBD PRP , CC , IN DT JJ VBD JJ .</td>\n",
       "      <td>advmod nsubj ROOT dobj punct cc punct prep de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PROPN PROPN VERB ADJ NOUN ADP ADJ NOUN NOUN V...</td>\n",
       "      <td>NNP NNP VBD JJ NNS IN PRP$ NN NN VBD DT NN IN...</td>\n",
       "      <td>compound nsubj ROOT amod dobj mark poss compo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DET NOUN ADP NOUN VERB ADV ADV ADV ADP DET NO...</td>\n",
       "      <td>DT NN IN NNS VBD RB RB RB IN DT NN , RB IN NN...</td>\n",
       "      <td>det ROOT prep pobj acl advmod advmod advmod p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CCONJ DET NOUN VERB VERB DET NOUN ADP DET NOU...</td>\n",
       "      <td>CC DT NN MD VB DT NN IN DT NN .</td>\n",
       "      <td>cc det nsubj aux ROOT det dobj prep det pobj ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PRON VERB VERB PRON PUNCT CCONJ PRON VERB VER...</td>\n",
       "      <td>PRP VBD VBN PRP , CC PRP MD VB DT JJ CC RB JJ...</td>\n",
       "      <td>nsubj aux ROOT dobj punct cc nsubj aux conj d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ADP DET NOUN PRON VERB PUNCT ADP NOUN PUNCT A...</td>\n",
       "      <td>IN DT NNS PRP VBD , IN NN , PRP$ JJ NN , VBG ...</td>\n",
       "      <td>prep det pobj nsubj relcl punct prep pobj pun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ADJ ADJ NOUN VERB DET ADJ NOUN PUNCT CCONJ AD...</td>\n",
       "      <td>PRP$ JJ NN VBD DT JJ NN , CC PRP$ JJ NN VBD V...</td>\n",
       "      <td>poss amod nsubj ROOT det amod dobj punct cc p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PRON ADV VERB ADV ADV ADP PART VERB ADP DET A...</td>\n",
       "      <td>PRP RB VBD RB RB IN TO VB IN DT RB JJ NN IN W...</td>\n",
       "      <td>nsubj advmod ROOT advmod advmod mark aux advc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ADJ ADJ NOUN PUNCT ADV PUNCT VERB ADJ ADP ADJ...</td>\n",
       "      <td>PRP$ JJ NN , RB , VBD JJ IN PRP$ NN : IN IN P...</td>\n",
       "      <td>poss amod nsubj punct advmod punct ROOT acomp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ADV DET ADJ NOUN VERB ADV ADV VERB ADP DET NO...</td>\n",
       "      <td>RB DT JJ NN VBD RB RB VBN IN DT NN , CC VBN I...</td>\n",
       "      <td>advmod det amod nsubjpass auxpass neg advmod ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PRON VERB ADV ADP DET NOUN VERB ADJ PUNCT ADP...</td>\n",
       "      <td>PRP VBD RB IN DT NNS VBD JJ , IN PRP VBD RB :...</td>\n",
       "      <td>nsubj ROOT neg mark det nsubj ccomp acomp pun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ADP DET NOUN VERB DET NOUN ADP NOUN PUNCT ADP...</td>\n",
       "      <td>IN DT NN VBD DT NN IN NNS , IN NNS , IN NNS ,...</td>\n",
       "      <td>prep det pobj ROOT det nsubj prep pobj punct ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ADP ADV ADJ DET NOUN ADP NOUN CCONJ NOUN VERB...</td>\n",
       "      <td>IN WRB JJ DT NN IN NN CC NN VBD PRP MD RB TO ...</td>\n",
       "      <td>mark advmod amod det nsubj prep pobj cc conj ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DET ADJ NOUN ADP NOUN VERB VERB ADP NOUN ADV ...</td>\n",
       "      <td>DT JJ NNS IN NN VBD VBN IN NNS RB JJ .</td>\n",
       "      <td>det amod nsubjpass prep pobj auxpass ROOT age...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ADP ADJ NOUN CCONJ NOUN VERB VERB NOUN PUNCT ...</td>\n",
       "      <td>IN JJ NNS CC NNS VBD VBN NN , CC RB CC RB , I...</td>\n",
       "      <td>prep amod pobj cc conj aux ROOT dobj punct cc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DET DET ADP ADV VERB ADV VERB VERB PART VERB ...</td>\n",
       "      <td>DT DT IN RB MD RB VB VBN TO VB VBN VBZ , IN `...</td>\n",
       "      <td>predet nsubjpass prep pcomp aux advmod auxpas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PRON VERB PART VERB ADP DET NOUN ADP NOUN ADP...</td>\n",
       "      <td>PRP VBD TO VB IN DT NN IN NN IN NN TO VB NNS ...</td>\n",
       "      <td>nsubj ROOT aux xcomp prep det pobj prep pobj ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ADJ NOUN PUNCT NOUN NOUN PUNCT CCONJ ADJ ADJ ...</td>\n",
       "      <td>PRP$ NNS , NN NNS , CC JJ JJ NNS VBD VBN : IN...</td>\n",
       "      <td>poss nsubjpass punct compound conj punct cc a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DET DET ADJ NOUN VERB ADV ADP PRON ADP PROPN ...</td>\n",
       "      <td>DT DT JJ NNS VBD RB IN PRP IN NNP IN DT NN IN...</td>\n",
       "      <td>dobj det amod nsubj ROOT advmod prep pobj pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19549</th>\n",
       "      <td>CCONJ PRON VERB ADV ADV PUNCT PRON VERB DET A...</td>\n",
       "      <td>CC PRP VBD RB RB : PRP VBD DT JJ IN NN , IN J...</td>\n",
       "      <td>cc nsubj ccomp neg advmod punct nsubj ROOT de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19550</th>\n",
       "      <td>PRON ADV VERB DET NOUN PRON PUNCT CCONJ VERB ...</td>\n",
       "      <td>PRP RB VBD DT NN PRP , CC VBD PRP DT NN RB .</td>\n",
       "      <td>nsubj advmod ROOT det dobj appos punct cc con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19551</th>\n",
       "      <td>PUNCT PROPN PROPN PROPN PUNCT NOUN ADP PROPN ...</td>\n",
       "      <td>`` NNP NNP NNP , NN IN NNP NNP NNP , VBZ IN I...</td>\n",
       "      <td>punct compound compound ROOT punct appos prep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19552</th>\n",
       "      <td>CCONJ ADP DET NOUN ADP ADJ NOUN ADP DET NOUN ...</td>\n",
       "      <td>CC IN DT NN IN PRP$ NNS IN DT NNS IN NN DT NN...</td>\n",
       "      <td>cc prep det pobj prep poss pobj prep det pobj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19553</th>\n",
       "      <td>PRON VERB DET NOUN ADP NOUN ADP DET NOUN VERB...</td>\n",
       "      <td>PRP VBZ DT NN IN NN IN DT NN VBZ , VBG DT NN ...</td>\n",
       "      <td>nsubj ROOT det dobj prep pobj mark det nsubj ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19554</th>\n",
       "      <td>PRON VERB PRON VERB VERB ADJ PUNCT CCONJ DET ...</td>\n",
       "      <td>PRP VBD PRP VBD VBN JJ , CC DT VBD PRP VBD VB...</td>\n",
       "      <td>nsubj ROOT nsubj aux ccomp acomp punct cc nsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19555</th>\n",
       "      <td>DET NOUN ADP DET ADV VERB NOUN VERB PART ADP ...</td>\n",
       "      <td>DT NNS IN DT RB VBN NN VBN RP IN DT NN , IN N...</td>\n",
       "      <td>det nsubj prep det advmod amod pobj acl prt p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19556</th>\n",
       "      <td>ADP DET NOUN ADP DET ADJ NOUN DET ADJ NOUN AD...</td>\n",
       "      <td>IN DT NN IN DT JJ NN DT JJ NNS IN DT NN RB VB...</td>\n",
       "      <td>prep det pobj prep det amod pobj det amod nsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19557</th>\n",
       "      <td>DET NOUN ADP DET NOUN ADP NOUN PRON VERB ADV ...</td>\n",
       "      <td>DT NNS IN DT NNS IN NN PRP MD RB VB .</td>\n",
       "      <td>det nsubj prep det pobj prep pobj nsubj aux n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19558</th>\n",
       "      <td>PRON VERB VERB PUNCT ADP PRON VERB VERB PUNCT...</td>\n",
       "      <td>PRP VBD VBN , IN PRP VBD VBN , IN DT NN RB JJ...</td>\n",
       "      <td>nsubjpass auxpass ROOT punct mark nsubj aux a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19559</th>\n",
       "      <td>ADV DET NOUN VERB ADP DET ADJ NOUN PRON VERB ...</td>\n",
       "      <td>WRB DT NN VBD IN DT JJ NNS PRP VBD RB IN DT N...</td>\n",
       "      <td>advmod det nsubj ROOT prep det amod pobj nsub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19560</th>\n",
       "      <td>CCONJ ADV ADV VERB DET NOUN NOUN PUNCT CCONJ ...</td>\n",
       "      <td>CC RB EX VBZ DT NN NN , CC NN , WDT VBZ RB VB...</td>\n",
       "      <td>cc advmod expl ROOT det compound attr punct c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19561</th>\n",
       "      <td>ADJ NOUN ADP NOUN CCONJ NOUN PROPN PROPN PART...</td>\n",
       "      <td>JJ NNS IN NN CC NN NNP NNP POS JJ `` NN IN DT...</td>\n",
       "      <td>amod nsubj prep pobj cc compound compound pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19562</th>\n",
       "      <td>DET NOUN CCONJ NOUN ADP DET NOUN ADP NOUN VER...</td>\n",
       "      <td>DT NNS CC NNS IN DT NN IN NN VBP RB VBN IN DT...</td>\n",
       "      <td>det nsubj cc conj prep det pobj prep pobj ROO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19563</th>\n",
       "      <td>CCONJ ADP NOUN VERB ADV DET ADJ NOUN NOUN ADV...</td>\n",
       "      <td>CC IN WP VBZ RB DT JJ NN NN RB DT JJ NN .</td>\n",
       "      <td>cc prep pobj aux neg det amod nsubj ROOT advm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19564</th>\n",
       "      <td>PROPN PROPN INTJ PUNCT INTJ PRON VERB PRON VE...</td>\n",
       "      <td>NNP NNP UH , UH PRP VBD PRP VBD PRP VBD PRP V...</td>\n",
       "      <td>compound ROOT ROOT punct ROOT nsubj ROOT nsub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19565</th>\n",
       "      <td>PRON VERB PRON VERB ADV VERB ADV ADJ ADP PART...</td>\n",
       "      <td>PRP VBP PRP VBP RB VBN RB JJ IN TO VB NN IN D...</td>\n",
       "      <td>nsubj ROOT nsubj aux neg ccomp advmod acomp m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19566</th>\n",
       "      <td>DET NOUN VERB ADJ NOUN VERB PUNCT ADP PRON VE...</td>\n",
       "      <td>DT NNS VBD PRP$ NNS VB , IN PRP MD VB IN DT N...</td>\n",
       "      <td>det nsubj ROOT poss nsubj ccomp punct mark ns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19567</th>\n",
       "      <td>ADP ADV VERB DET NOUN ADP ADJ NOUN ADP PUNCT</td>\n",
       "      <td>IN EX VBD DT NNS IN JJ NN IN .</td>\n",
       "      <td>mark expl ROOT det attr prep amod pobj prep p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19568</th>\n",
       "      <td>ADP VERB ADP PRON VERB ADP DET NOUN PUNCT VER...</td>\n",
       "      <td>IN VBG IN PRP VBD IN DT NN , VBD RP DT NN , C...</td>\n",
       "      <td>prep pcomp prt nsubj ROOT prt det pobj punct ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19569</th>\n",
       "      <td>ADP ADJ NOUN VERB VERB ADP NOUN ADP NOUN PUNC...</td>\n",
       "      <td>IN PRP$ NN VBD VBN IN NNS IN NN , IN NN , CC ...</td>\n",
       "      <td>mark poss nsubjpass auxpass ROOT prep pobj pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19570</th>\n",
       "      <td>INTJ PUNCT PRON VERB VERB VERB ADP DET NOUN P...</td>\n",
       "      <td>UH , PRP MD VB VBN IN DT WP PRP MD VB : CC VB...</td>\n",
       "      <td>intj punct nsubj aux aux ROOT prep pobj dobj ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19571</th>\n",
       "      <td>ADJ NOUN VERB ADV VERB PUNCT CCONJ VERB PRON ...</td>\n",
       "      <td>PRP$ NN VBD RB VBG , CC VBD PRP IN DT NN VBD ...</td>\n",
       "      <td>poss nsubj aux advmod ROOT punct cc conj dobj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19572</th>\n",
       "      <td>CCONJ DET CCONJ ADJ NOUN VERB NOUN PUNCT ADP ...</td>\n",
       "      <td>CC DT CC JJ NNS VBG NN , IN PRP VBD IN DT NNS...</td>\n",
       "      <td>cc nsubj cc amod conj acl dobj punct mark nsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19573</th>\n",
       "      <td>NOUN ADP NOUN VERB PRON PART DET PROPN PROPN ...</td>\n",
       "      <td>NN IN NN VBD PRP RP DT NNP NNP : CC , PRP$ NN...</td>\n",
       "      <td>nsubj prep pobj ccomp dobj prep det compound ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>PRON VERB VERB VERB PUNCT ADP PRON VERB ADP P...</td>\n",
       "      <td>PRP MD VB VBN , IN PRP VBD IN PRP , IN DT JJ ...</td>\n",
       "      <td>nsubj aux aux ROOT punct mark nsubj advcl pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>DET NOUN VERB PRON ADV ADP ADP ADP DET NOUN P...</td>\n",
       "      <td>DT NNS VBD PRP RB IN IN IN DT NN .</td>\n",
       "      <td>det nsubj ROOT dobj advmod mark advcl prep de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>PROPN X NOUN NOUN DET VERB PART VERB PUNCT DE...</td>\n",
       "      <td>NNP FW NN NN DT VBZ TO VB , DT NNP RB VBZ RB .</td>\n",
       "      <td>compound nsubj ROOT dobj nsubj relcl aux xcom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>ADP DET NOUN ADP NOUN ADP DET PUNCT PRON VERB...</td>\n",
       "      <td>IN DT NN IN NN IN DT , PRP VBZ PRP PRP VBD RB...</td>\n",
       "      <td>prep det pobj prep pobj prep pobj punct nsubj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>PRON VERB DET VERB NOUN ADP ADJ NOUN PUNCT CC...</td>\n",
       "      <td>PRP VBD DT VBN NN IN PRP$ NN , CC PRP VBD IN ...</td>\n",
       "      <td>nsubj ROOT det amod dobj prep poss pobj punct...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 pos_txt  \\\n",
       "0       DET NOUN PUNCT ADV PUNCT VERB PRON DET NOUN A...   \n",
       "1       PRON ADV ADV VERB ADP PRON ADP DET NOUN VERB ...   \n",
       "2       ADP ADJ ADJ NOUN VERB DET ADJ NOUN NOUN PUNCT...   \n",
       "3       ADV ADJ VERB NOUN ADP PRON VERB ADP PROPN PRO...   \n",
       "4       VERB NOUN ADV PUNCT ADV ADV NOUN PUNCT DET PR...   \n",
       "5       DET NOUN VERB ADP NOUN PUNCT ADJ ADJ NOUN VER...   \n",
       "6       DET NOUN PUNCT ADV PUNCT ADP DET NOUN PUNCT V...   \n",
       "7              DET NOUN VERB ADP NOUN ADP ADJ NOUN PUNCT   \n",
       "8       PRON VERB ADP PRON VERB ADV VERB ADP PRON PUN...   \n",
       "9       PRON VERB ADP CCONJ DET NOUN ADP NOUN PUNCT C...   \n",
       "10      PRON VERB VERB ADP PRON VERB VERB ADJ NOUN PU...   \n",
       "11      ADV PRON VERB PRON PUNCT CCONJ PUNCT ADP DET ...   \n",
       "12      PROPN PROPN VERB ADJ NOUN ADP ADJ NOUN NOUN V...   \n",
       "13      DET NOUN ADP NOUN VERB ADV ADV ADV ADP DET NO...   \n",
       "14      CCONJ DET NOUN VERB VERB DET NOUN ADP DET NOU...   \n",
       "15      PRON VERB VERB PRON PUNCT CCONJ PRON VERB VER...   \n",
       "16      ADP DET NOUN PRON VERB PUNCT ADP NOUN PUNCT A...   \n",
       "17      ADJ ADJ NOUN VERB DET ADJ NOUN PUNCT CCONJ AD...   \n",
       "18      PRON ADV VERB ADV ADV ADP PART VERB ADP DET A...   \n",
       "19      ADJ ADJ NOUN PUNCT ADV PUNCT VERB ADJ ADP ADJ...   \n",
       "20      ADV DET ADJ NOUN VERB ADV ADV VERB ADP DET NO...   \n",
       "21      PRON VERB ADV ADP DET NOUN VERB ADJ PUNCT ADP...   \n",
       "22      ADP DET NOUN VERB DET NOUN ADP NOUN PUNCT ADP...   \n",
       "23      ADP ADV ADJ DET NOUN ADP NOUN CCONJ NOUN VERB...   \n",
       "24      DET ADJ NOUN ADP NOUN VERB VERB ADP NOUN ADV ...   \n",
       "25      ADP ADJ NOUN CCONJ NOUN VERB VERB NOUN PUNCT ...   \n",
       "26      DET DET ADP ADV VERB ADV VERB VERB PART VERB ...   \n",
       "27      PRON VERB PART VERB ADP DET NOUN ADP NOUN ADP...   \n",
       "28      ADJ NOUN PUNCT NOUN NOUN PUNCT CCONJ ADJ ADJ ...   \n",
       "29      DET DET ADJ NOUN VERB ADV ADP PRON ADP PROPN ...   \n",
       "...                                                  ...   \n",
       "19549   CCONJ PRON VERB ADV ADV PUNCT PRON VERB DET A...   \n",
       "19550   PRON ADV VERB DET NOUN PRON PUNCT CCONJ VERB ...   \n",
       "19551   PUNCT PROPN PROPN PROPN PUNCT NOUN ADP PROPN ...   \n",
       "19552   CCONJ ADP DET NOUN ADP ADJ NOUN ADP DET NOUN ...   \n",
       "19553   PRON VERB DET NOUN ADP NOUN ADP DET NOUN VERB...   \n",
       "19554   PRON VERB PRON VERB VERB ADJ PUNCT CCONJ DET ...   \n",
       "19555   DET NOUN ADP DET ADV VERB NOUN VERB PART ADP ...   \n",
       "19556   ADP DET NOUN ADP DET ADJ NOUN DET ADJ NOUN AD...   \n",
       "19557   DET NOUN ADP DET NOUN ADP NOUN PRON VERB ADV ...   \n",
       "19558   PRON VERB VERB PUNCT ADP PRON VERB VERB PUNCT...   \n",
       "19559   ADV DET NOUN VERB ADP DET ADJ NOUN PRON VERB ...   \n",
       "19560   CCONJ ADV ADV VERB DET NOUN NOUN PUNCT CCONJ ...   \n",
       "19561   ADJ NOUN ADP NOUN CCONJ NOUN PROPN PROPN PART...   \n",
       "19562   DET NOUN CCONJ NOUN ADP DET NOUN ADP NOUN VER...   \n",
       "19563   CCONJ ADP NOUN VERB ADV DET ADJ NOUN NOUN ADV...   \n",
       "19564   PROPN PROPN INTJ PUNCT INTJ PRON VERB PRON VE...   \n",
       "19565   PRON VERB PRON VERB ADV VERB ADV ADJ ADP PART...   \n",
       "19566   DET NOUN VERB ADJ NOUN VERB PUNCT ADP PRON VE...   \n",
       "19567       ADP ADV VERB DET NOUN ADP ADJ NOUN ADP PUNCT   \n",
       "19568   ADP VERB ADP PRON VERB ADP DET NOUN PUNCT VER...   \n",
       "19569   ADP ADJ NOUN VERB VERB ADP NOUN ADP NOUN PUNC...   \n",
       "19570   INTJ PUNCT PRON VERB VERB VERB ADP DET NOUN P...   \n",
       "19571   ADJ NOUN VERB ADV VERB PUNCT CCONJ VERB PRON ...   \n",
       "19572   CCONJ DET CCONJ ADJ NOUN VERB NOUN PUNCT ADP ...   \n",
       "19573   NOUN ADP NOUN VERB PRON PART DET PROPN PROPN ...   \n",
       "19574   PRON VERB VERB VERB PUNCT ADP PRON VERB ADP P...   \n",
       "19575   DET NOUN VERB PRON ADV ADP ADP ADP DET NOUN P...   \n",
       "19576   PROPN X NOUN NOUN DET VERB PART VERB PUNCT DE...   \n",
       "19577   ADP DET NOUN ADP NOUN ADP DET PUNCT PRON VERB...   \n",
       "19578   PRON VERB DET VERB NOUN ADP ADJ NOUN PUNCT CC...   \n",
       "\n",
       "                                                 tag_txt  \\\n",
       "0       DT NN , RB , VBD PRP DT NNS IN VBG DT NNS IN ...   \n",
       "1         PRP RB RB VBD IN PRP IN DT NN MD VB DT JJ NN .   \n",
       "2       IN PRP$ JJ NN VBD DT JJ NN NN , IN WDT , IN P...   \n",
       "3       WRB JJ VBZ NN IN PRP VBD IN NNP NNP IN DT CD ...   \n",
       "4       VBG NN RB , RB RB NN , DT NNP VBD PRP$ NNS : ...   \n",
       "5       DT NN VBD IN NN , PRP$ JJS NNS VBN IN PRP$ JJ...   \n",
       "6       DT NN , RB , IN DT NN , VBD NN IN DT NN IN AF...   \n",
       "7                          DT NN VBD IN NNS IN PRP$ NN .   \n",
       "8       PRP VBD IN PRP MD RB VB IN PRP `` NN '' IN VB...   \n",
       "9       PRP VBP IN CC DT NN IN NNS , CC DT NN IN NNS ...   \n",
       "10      PRP MD VB IN PRP MD VB PRP$ NNS : PRP MD VB T...   \n",
       "11               RB PRP VBD PRP , CC , IN DT JJ VBD JJ .   \n",
       "12      NNP NNP VBD JJ NNS IN PRP$ NN NN VBD DT NN IN...   \n",
       "13      DT NN IN NNS VBD RB RB RB IN DT NN , RB IN NN...   \n",
       "14                       CC DT NN MD VB DT NN IN DT NN .   \n",
       "15      PRP VBD VBN PRP , CC PRP MD VB DT JJ CC RB JJ...   \n",
       "16      IN DT NNS PRP VBD , IN NN , PRP$ JJ NN , VBG ...   \n",
       "17      PRP$ JJ NN VBD DT JJ NN , CC PRP$ JJ NN VBD V...   \n",
       "18      PRP RB VBD RB RB IN TO VB IN DT RB JJ NN IN W...   \n",
       "19      PRP$ JJ NN , RB , VBD JJ IN PRP$ NN : IN IN P...   \n",
       "20      RB DT JJ NN VBD RB RB VBN IN DT NN , CC VBN I...   \n",
       "21      PRP VBD RB IN DT NNS VBD JJ , IN PRP VBD RB :...   \n",
       "22      IN DT NN VBD DT NN IN NNS , IN NNS , IN NNS ,...   \n",
       "23      IN WRB JJ DT NN IN NN CC NN VBD PRP MD RB TO ...   \n",
       "24                DT JJ NNS IN NN VBD VBN IN NNS RB JJ .   \n",
       "25      IN JJ NNS CC NNS VBD VBN NN , CC RB CC RB , I...   \n",
       "26      DT DT IN RB MD RB VB VBN TO VB VBN VBZ , IN `...   \n",
       "27      PRP VBD TO VB IN DT NN IN NN IN NN TO VB NNS ...   \n",
       "28      PRP$ NNS , NN NNS , CC JJ JJ NNS VBD VBN : IN...   \n",
       "29      DT DT JJ NNS VBD RB IN PRP IN NNP IN DT NN IN...   \n",
       "...                                                  ...   \n",
       "19549   CC PRP VBD RB RB : PRP VBD DT JJ IN NN , IN J...   \n",
       "19550       PRP RB VBD DT NN PRP , CC VBD PRP DT NN RB .   \n",
       "19551   `` NNP NNP NNP , NN IN NNP NNP NNP , VBZ IN I...   \n",
       "19552   CC IN DT NN IN PRP$ NNS IN DT NNS IN NN DT NN...   \n",
       "19553   PRP VBZ DT NN IN NN IN DT NN VBZ , VBG DT NN ...   \n",
       "19554   PRP VBD PRP VBD VBN JJ , CC DT VBD PRP VBD VB...   \n",
       "19555   DT NNS IN DT RB VBN NN VBN RP IN DT NN , IN N...   \n",
       "19556   IN DT NN IN DT JJ NN DT JJ NNS IN DT NN RB VB...   \n",
       "19557              DT NNS IN DT NNS IN NN PRP MD RB VB .   \n",
       "19558   PRP VBD VBN , IN PRP VBD VBN , IN DT NN RB JJ...   \n",
       "19559   WRB DT NN VBD IN DT JJ NNS PRP VBD RB IN DT N...   \n",
       "19560   CC RB EX VBZ DT NN NN , CC NN , WDT VBZ RB VB...   \n",
       "19561   JJ NNS IN NN CC NN NNP NNP POS JJ `` NN IN DT...   \n",
       "19562   DT NNS CC NNS IN DT NN IN NN VBP RB VBN IN DT...   \n",
       "19563          CC IN WP VBZ RB DT JJ NN NN RB DT JJ NN .   \n",
       "19564   NNP NNP UH , UH PRP VBD PRP VBD PRP VBD PRP V...   \n",
       "19565   PRP VBP PRP VBP RB VBN RB JJ IN TO VB NN IN D...   \n",
       "19566   DT NNS VBD PRP$ NNS VB , IN PRP MD VB IN DT N...   \n",
       "19567                     IN EX VBD DT NNS IN JJ NN IN .   \n",
       "19568   IN VBG IN PRP VBD IN DT NN , VBD RP DT NN , C...   \n",
       "19569   IN PRP$ NN VBD VBN IN NNS IN NN , IN NN , CC ...   \n",
       "19570   UH , PRP MD VB VBN IN DT WP PRP MD VB : CC VB...   \n",
       "19571   PRP$ NN VBD RB VBG , CC VBD PRP IN DT NN VBD ...   \n",
       "19572   CC DT CC JJ NNS VBG NN , IN PRP VBD IN DT NNS...   \n",
       "19573   NN IN NN VBD PRP RP DT NNP NNP : CC , PRP$ NN...   \n",
       "19574   PRP MD VB VBN , IN PRP VBD IN PRP , IN DT JJ ...   \n",
       "19575                 DT NNS VBD PRP RB IN IN IN DT NN .   \n",
       "19576     NNP FW NN NN DT VBZ TO VB , DT NNP RB VBZ RB .   \n",
       "19577   IN DT NN IN NN IN DT , PRP VBZ PRP PRP VBD RB...   \n",
       "19578   PRP VBD DT VBN NN IN PRP$ NN , CC PRP VBD IN ...   \n",
       "\n",
       "                                                 dep_txt  \n",
       "0       det nsubj punct advmod punct ccomp dobj det d...  \n",
       "1       nsubj neg advmod ROOT prep pobj mark det nsub...  \n",
       "2       prep poss amod pobj ROOT det compound compoun...  \n",
       "3       advmod acomp ROOT nsubj mark nsubj advcl prep...  \n",
       "4       advcl dobj advmod punct neg advmod dep punct ...  \n",
       "5       det nsubj acl prep pobj punct poss amod nsubj...  \n",
       "6       det nsubj punct advmod punct prep det pobj pu...  \n",
       "7          det nsubj ROOT prep pobj prep poss pobj punct  \n",
       "8       nsubj ROOT mark nsubj aux neg ccomp prep poss...  \n",
       "9       nsubj ROOT mark preconj det nsubj prep pobj p...  \n",
       "10      nsubj aux ccomp mark nsubj aux ccomp poss dob...  \n",
       "11      advmod nsubj ROOT dobj punct cc punct prep de...  \n",
       "12      compound nsubj ROOT amod dobj mark poss compo...  \n",
       "13      det ROOT prep pobj acl advmod advmod advmod p...  \n",
       "14      cc det nsubj aux ROOT det dobj prep det pobj ...  \n",
       "15      nsubj aux ROOT dobj punct cc nsubj aux conj d...  \n",
       "16      prep det pobj nsubj relcl punct prep pobj pun...  \n",
       "17      poss amod nsubj ROOT det amod dobj punct cc p...  \n",
       "18      nsubj advmod ROOT advmod advmod mark aux advc...  \n",
       "19      poss amod nsubj punct advmod punct ROOT acomp...  \n",
       "20      advmod det amod nsubjpass auxpass neg advmod ...  \n",
       "21      nsubj ROOT neg mark det nsubj ccomp acomp pun...  \n",
       "22      prep det pobj ROOT det nsubj prep pobj punct ...  \n",
       "23      mark advmod amod det nsubj prep pobj cc conj ...  \n",
       "24      det amod nsubjpass prep pobj auxpass ROOT age...  \n",
       "25      prep amod pobj cc conj aux ROOT dobj punct cc...  \n",
       "26      predet nsubjpass prep pcomp aux advmod auxpas...  \n",
       "27      nsubj ROOT aux xcomp prep det pobj prep pobj ...  \n",
       "28      poss nsubjpass punct compound conj punct cc a...  \n",
       "29      dobj det amod nsubj ROOT advmod prep pobj pre...  \n",
       "...                                                  ...  \n",
       "19549   cc nsubj ccomp neg advmod punct nsubj ROOT de...  \n",
       "19550   nsubj advmod ROOT det dobj appos punct cc con...  \n",
       "19551   punct compound compound ROOT punct appos prep...  \n",
       "19552   cc prep det pobj prep poss pobj prep det pobj...  \n",
       "19553   nsubj ROOT det dobj prep pobj mark det nsubj ...  \n",
       "19554   nsubj ROOT nsubj aux ccomp acomp punct cc nsu...  \n",
       "19555   det nsubj prep det advmod amod pobj acl prt p...  \n",
       "19556   prep det pobj prep det amod pobj det amod nsu...  \n",
       "19557   det nsubj prep det pobj prep pobj nsubj aux n...  \n",
       "19558   nsubjpass auxpass ROOT punct mark nsubj aux a...  \n",
       "19559   advmod det nsubj ROOT prep det amod pobj nsub...  \n",
       "19560   cc advmod expl ROOT det compound attr punct c...  \n",
       "19561   amod nsubj prep pobj cc compound compound pos...  \n",
       "19562   det nsubj cc conj prep det pobj prep pobj ROO...  \n",
       "19563   cc prep pobj aux neg det amod nsubj ROOT advm...  \n",
       "19564   compound ROOT ROOT punct ROOT nsubj ROOT nsub...  \n",
       "19565   nsubj ROOT nsubj aux neg ccomp advmod acomp m...  \n",
       "19566   det nsubj ROOT poss nsubj ccomp punct mark ns...  \n",
       "19567   mark expl ROOT det attr prep amod pobj prep p...  \n",
       "19568   prep pcomp prt nsubj ROOT prt det pobj punct ...  \n",
       "19569   mark poss nsubjpass auxpass ROOT prep pobj pr...  \n",
       "19570   intj punct nsubj aux aux ROOT prep pobj dobj ...  \n",
       "19571   poss nsubj aux advmod ROOT punct cc conj dobj...  \n",
       "19572   cc nsubj cc amod conj acl dobj punct mark nsu...  \n",
       "19573   nsubj prep pobj ccomp dobj prep det compound ...  \n",
       "19574   nsubj aux aux ROOT punct mark nsubj advcl pre...  \n",
       "19575   det nsubj ROOT dobj advmod mark advcl prep de...  \n",
       "19576   compound nsubj ROOT dobj nsubj relcl aux xcom...  \n",
       "19577   prep det pobj prep pobj prep pobj punct nsubj...  \n",
       "19578   nsubj ROOT det amod dobj prep poss pobj punct...  \n",
       "\n",
       "[19579 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_spacy_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_spacy_tag_cnt_feature, test_x_spacy_tag_cnt_feature = count_vec(train_spacy_features[\"tag_txt\"].values, test_spacy_features[\"tag_txt\"].values, lowercase=False, ngram=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_spacy_pos_cnt_feature, test_x_spacy_pos_cnt_feature = count_vec(train_spacy_features[\"pos_txt\"].values, test_spacy_features[\"pos_txt\"].values, lowercase=False, ngram=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_spacy_dep_cnt_feature, test_x_spacy_dep_cnt_feature = count_vec(train_spacy_features[\"dep_txt\"].values, test_spacy_features[\"dep_txt\"].values, lowercase=False, ngram=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sarvam.eda.meta_features.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
