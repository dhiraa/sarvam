{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Have you ever wondered how to take tensorflow code to production?   \n",
    "# How to isolate the dataset, the model and the TensorFlow environment set up?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper:\n",
    "\n",
    "https://terrytangyuan.github.io/data/papers/tf-estimators-kdd-paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Urls:\n",
    "https://www.tensorflow.org/api_docs/python/tf/contrib/data/Dataset  \n",
    "https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Experiment  \n",
    "https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/800/1*zoNZvvuJb06yAghetc6BfQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Script to illustrate usage of tf.estimator.Estimator in TF v1.3\"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data as mnist_data\n",
    "from tensorflow.contrib import slim\n",
    "from tensorflow.contrib.learn import ModeKeys\n",
    "from tensorflow.contrib.learn import learn_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Environment Initialization/Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show debugging output\n",
    "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "\n",
    "# Set default flags for the output directories\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    flag_name='model_dir', \n",
    "    default_value='./mnist_training',\n",
    "    docstring='Output directory for model and training stats.')\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    flag_name='data_dir', \n",
    "    default_value='./mnist_data',\n",
    "    docstring='Directory to download the data to.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To iterate over the data we need to create an iterator from the dataset. Because we are using a placeholder we need to initialize the placeholder in the relevant session with the NumPy data. We can do this by creating an initializable iterator. We will create a custom defined IteratorInitializerHook object to initialize the iterator when the graph is created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define data loaders #####################################\n",
    "class IteratorInitializerHook(tf.train.SessionRunHook):\n",
    "    \"\"\"Hook to initialise data iterator after Session is created.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(IteratorInitializerHook, self).__init__()\n",
    "        self.iterator_initializer_func = None\n",
    "\n",
    "    def after_create_session(self, session, coord):\n",
    "        \"\"\"Initialise the iterator after the session has been created.\"\"\"\n",
    "        self.iterator_initializer_func(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IteratorInitializerHook inherits from SessionRunHook. This hook will call after_create_session as soon as the relevant session is created, and initialize the placeholder with the right data. This hook is returned by our get_train_inputs function and will be passed to the Experiment object upon creation.\n",
    "The data loading operations returned by the train_inputs function are TensorFlow operations that will return a new batch every time they are evaluated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "### Train Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the training inputs\n",
    "def get_train_inputs(batch_size, mnist_data):\n",
    "    \"\"\"Return the input function to get the training data.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): Batch size of training iterator that is returned\n",
    "                          by the input function.\n",
    "        mnist_data (Object): Object holding the loaded mnist data.\n",
    "\n",
    "    Returns:\n",
    "        (Input function, IteratorInitializerHook):\n",
    "            - Function that returns (features, labels) when called.\n",
    "            - Hook to initialise input iterator.\n",
    "    \"\"\"\n",
    "    iterator_initializer_hook = IteratorInitializerHook()\n",
    "\n",
    "    def train_inputs():\n",
    "        \"\"\"Returns training set as Operations.\n",
    "\n",
    "        Returns:\n",
    "            (features, labels) Operations that iterate over the dataset\n",
    "            on every evaluation\n",
    "        \"\"\"\n",
    "        with tf.name_scope('Training_data'):\n",
    "            # Get Mnist data\n",
    "            images = mnist_data.train.images.reshape([-1, 28, 28, 1])\n",
    "            labels = mnist_data.train.labels\n",
    "            # Define placeholders\n",
    "            images_placeholder = tf.placeholder(\n",
    "                images.dtype, images.shape)\n",
    "            labels_placeholder = tf.placeholder(\n",
    "                labels.dtype, labels.shape)\n",
    "            # Build dataset iterator\n",
    "            dataset = tf.contrib.data.Dataset.from_tensor_slices(\n",
    "                (images_placeholder, labels_placeholder))\n",
    "            dataset = dataset.repeat(None)  # Infinite iterations\n",
    "            dataset = dataset.shuffle(buffer_size=10000)\n",
    "            dataset = dataset.batch(batch_size)\n",
    "            iterator = dataset.make_initializable_iterator()\n",
    "            next_example, next_label = iterator.get_next()\n",
    "            # Set runhook to initialize iterator\n",
    "            iterator_initializer_hook.iterator_initializer_func = \\\n",
    "                lambda sess: sess.run(\n",
    "                    iterator.initializer,\n",
    "                    feed_dict={images_placeholder: images,\n",
    "                               labels_placeholder: labels})\n",
    "            # Return batched (features, labels)\n",
    "            return next_example, next_label\n",
    "\n",
    "    # Return function and hook\n",
    "    return train_inputs, iterator_initializer_hook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_inputs(batch_size, mnist_data):\n",
    "    \"\"\"Return the input function to get the test data.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): Batch size of training iterator that is returned\n",
    "                          by the input function.\n",
    "        mnist_data (Object): Object holding the loaded mnist data.\n",
    "\n",
    "    Returns:\n",
    "        (Input function, IteratorInitializerHook):\n",
    "            - Function that returns (features, labels) when called.\n",
    "            - Hook to initialise input iterator.\n",
    "    \"\"\"\n",
    "    iterator_initializer_hook = IteratorInitializerHook()\n",
    "\n",
    "    def test_inputs():\n",
    "        \"\"\"Returns training set as Operations.\n",
    "\n",
    "        Returns:\n",
    "            (features, labels) Operations that iterate over the dataset\n",
    "            on every evaluation\n",
    "        \"\"\"\n",
    "        with tf.name_scope('Test_data'):\n",
    "            # Get Mnist data\n",
    "            images = mnist_data.test.images.reshape([-1, 28, 28, 1])\n",
    "            labels = mnist_data.test.labels\n",
    "            # Define placeholders\n",
    "            images_placeholder = tf.placeholder(\n",
    "                images.dtype, images.shape)\n",
    "            labels_placeholder = tf.placeholder(\n",
    "                labels.dtype, labels.shape)\n",
    "            # Build dataset iterator\n",
    "            dataset = tf.contrib.data.Dataset.from_tensor_slices(\n",
    "                (images_placeholder, labels_placeholder))\n",
    "            dataset = dataset.batch(batch_size)\n",
    "            iterator = dataset.make_initializable_iterator()\n",
    "            next_example, next_label = iterator.get_next()\n",
    "            # Set runhook to initialize iterator\n",
    "            iterator_initializer_hook.iterator_initializer_func = \\\n",
    "                lambda sess: sess.run(\n",
    "                    iterator.initializer,\n",
    "                    feed_dict={images_placeholder: images,\n",
    "                               labels_placeholder: labels})\n",
    "            return next_example, next_label\n",
    "\n",
    "    # Return function and hook\n",
    "    return test_inputs, iterator_initializer_hook\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_op_fn(loss, params):\n",
    "    \"\"\"Get the training Op.\n",
    "\n",
    "    Args:\n",
    "         loss (Tensor): Scalar Tensor that represents the loss function.\n",
    "         params (HParams): Hyperparameters (needs to have `learning_rate`)\n",
    "\n",
    "    Returns:\n",
    "        Training Op\n",
    "    \"\"\"\n",
    "    return tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.contrib.framework.get_global_step(),\n",
    "        optimizer=tf.train.AdamOptimizer,\n",
    "        learning_rate=params.learning_rate\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_eval_metric_ops(labels, predictions):\n",
    "    \"\"\"Return a dict of the evaluation Ops.\n",
    "\n",
    "    Args:\n",
    "        labels (Tensor): Labels tensor for training and evaluation.\n",
    "        predictions (Tensor): Predictions Tensor.\n",
    "    Returns:\n",
    "        Dict of metric results keyed by name.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'Accuracy': tf.metrics.accuracy(\n",
    "            labels=labels,\n",
    "            predictions=predictions,\n",
    "            name='accuracy')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def architecture(inputs, is_training, scope='MnistConvNet'):\n",
    "    \"\"\"Return the output operation following the network architecture.\n",
    "\n",
    "    Args:\n",
    "        inputs (Tensor): Input Tensor\n",
    "        is_training (bool): True iff in training mode\n",
    "        scope (str): Name of the scope of the architecture\n",
    "\n",
    "    Returns:\n",
    "         Logits output Op for the network.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        with slim.arg_scope(\n",
    "                [slim.conv2d, slim.fully_connected],\n",
    "                weights_initializer=tf.contrib.layers.xavier_initializer()):\n",
    "            net = slim.conv2d(inputs, 20, [5, 5], padding='VALID',\n",
    "                              scope='conv1')\n",
    "            net = slim.max_pool2d(net, 2, stride=2, scope='pool2')\n",
    "            net = slim.conv2d(net, 40, [5, 5], padding='VALID',\n",
    "                              scope='conv3')\n",
    "            net = slim.max_pool2d(net, 2, stride=2, scope='pool4')\n",
    "            net = tf.reshape(net, [-1, 4 * 4 * 40])\n",
    "            net = slim.fully_connected(net, 256, scope='fn5')\n",
    "            net = slim.dropout(net, is_training=is_training,\n",
    "                               scope='dropout5')\n",
    "            net = slim.fully_connected(net, 256, scope='fn6')\n",
    "            net = slim.dropout(net, is_training=is_training,\n",
    "                               scope='dropout6')\n",
    "            net = slim.fully_connected(net, 10, scope='output',\n",
    "                                       activation_fn=None)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    \"\"\"Model function used in the estimator.\n",
    "\n",
    "    Args:\n",
    "        features (Tensor): Input features to the model.\n",
    "        labels (Tensor): Labels tensor for training and evaluation.\n",
    "        mode (ModeKeys): Specifies if training, evaluation or prediction.\n",
    "        params (HParams): hyperparameters.\n",
    "\n",
    "    Returns:\n",
    "        (EstimatorSpec): Model to be run by Estimator.\n",
    "    \"\"\"\n",
    "    is_training = mode == ModeKeys.TRAIN\n",
    "    # Define model's architecture\n",
    "    logits = architecture(features, is_training=is_training)\n",
    "    predictions = tf.argmax(logits, axis=-1)\n",
    "    # Loss, training and eval operations are not needed during inference.\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = {}\n",
    "    if mode != ModeKeys.INFER:\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "            labels=tf.cast(labels, tf.int32),\n",
    "            logits=logits)\n",
    "        train_op = get_train_op_fn(loss, params)\n",
    "        eval_metric_ops = get_eval_metric_ops(labels, predictions)\n",
    "        \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define model ############################################\n",
    "def get_estimator(run_config, params):\n",
    "    \"\"\"Return the model as a Tensorflow Estimator object.\n",
    "\n",
    "    Args:\n",
    "         run_config (RunConfig): Configuration for Estimator run.\n",
    "         params (HParams): hyperparameters.\n",
    "    \"\"\"\n",
    "    return tf.estimator.Estimator(\n",
    "        model_fn=model_fn,  # First-class function\n",
    "        params=params,  # HParams\n",
    "        config=run_config  # RunConfig\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def experiment_fn(run_config, params):\n",
    "    \"\"\"Create an experiment to train and evaluate the model.\n",
    "\n",
    "    Args:\n",
    "        run_config (RunConfig): Configuration for Estimator run.\n",
    "        params (HParam): Hyperparameters\n",
    "\n",
    "    Returns:\n",
    "        (Experiment) Experiment for training the mnist model.\n",
    "    \"\"\"\n",
    "    # You can change a subset of the run_config properties as\n",
    "    run_config = run_config.replace(save_checkpoints_steps=params.min_eval_frequency)\n",
    "    \n",
    "    # Define the mnist classifier\n",
    "    estimator = get_estimator(run_config, params)\n",
    "    \n",
    "    # Setup data loaders\n",
    "    mnist = mnist_data.read_data_sets(FLAGS.data_dir, one_hot=False)\n",
    "    \n",
    "    train_input_fn, train_input_hook = get_train_inputs(batch_size=128, mnist_data=mnist)\n",
    "    \n",
    "    eval_input_fn, eval_input_hook = get_test_inputs(batch_size=128, mnist_data=mnist)\n",
    "    \n",
    "    # Define the experiment\n",
    "    experiment = tf.contrib.learn.Experiment(\n",
    "        estimator=estimator,  # Estimator\n",
    "        train_input_fn=train_input_fn,  # First-class function\n",
    "        eval_input_fn=eval_input_fn,  # First-class function\n",
    "        train_steps=params.train_steps,  # Minibatch steps\n",
    "        min_eval_frequency=params.min_eval_frequency,  # Eval frequency\n",
    "        train_monitors=[train_input_hook],  # Hooks for training\n",
    "        eval_hooks=[eval_input_hook],  # Hooks for evaluation\n",
    "        eval_steps=None  # Use evaluation feeder until its empty\n",
    "    )\n",
    "    \n",
    "    return experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define and run experiment ###############################\n",
    "def run_experiment(argv=None):\n",
    "    \"\"\"Run the training experiment.\"\"\"\n",
    "    # Define model parameters\n",
    "    params = tf.contrib.training.HParams(\n",
    "        learning_rate=0.002,\n",
    "        n_classes=10,\n",
    "        train_steps=10000,\n",
    "        min_eval_frequency=100\n",
    "    )\n",
    "\n",
    "    # Set the run_config and the directory to save the model and stats\n",
    "    run_config = tf.contrib.learn.RunConfig()\n",
    "    run_config = run_config.replace(model_dir=FLAGS.model_dir)\n",
    "\n",
    "    learn_runner.run(\n",
    "        experiment_fn=experiment_fn,  # First-class function\n",
    "        run_config=run_config,  # RunConfig\n",
    "        schedule=\"train_and_evaluate\",  # What to run\n",
    "        hparams=params  # HParams\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the TF Application to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TF App ---> Run Experiment \n",
    "       ---> Experiment Function + RunConfig + Params \n",
    "       ---> Estimator \n",
    "       ---> model_func \n",
    "       ---> Dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4959a8c828>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': 100, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './mnist_training'}\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./mnist_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./mnist_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./mnist_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "WARNING:tensorflow:From /home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:269: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./mnist_training/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.34068, step = 1\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-28-10:34:53\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_training/model.ckpt-1\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-28-10:34:55\n",
      "INFO:tensorflow:Saving dict for global step 1: Accuracy = 0.12, global_step = 1, loss = 2.26967\n",
      "INFO:tensorflow:Validation (step 100): Accuracy = 0.12, loss = 2.26967, global_step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 101 into ./mnist_training/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.26934\n",
      "INFO:tensorflow:loss = 0.151617, step = 101 (12.094 sec)\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-28-10:35:05\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_training/model.ckpt-101\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-28-10:35:07\n",
      "INFO:tensorflow:Saving dict for global step 101: Accuracy = 0.9646, global_step = 101, loss = 0.116229\n",
      "INFO:tensorflow:Validation (step 200): Accuracy = 0.9646, loss = 0.116229, global_step = 101\n",
      "INFO:tensorflow:Saving checkpoints for 201 into ./mnist_training/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.50736\n",
      "INFO:tensorflow:loss = 0.0871352, step = 201 (11.755 sec)\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-28-10:35:16\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_training/model.ckpt-201\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-28-10:35:19\n",
      "INFO:tensorflow:Saving dict for global step 201: Accuracy = 0.9757, global_step = 201, loss = 0.0756105\n",
      "INFO:tensorflow:Validation (step 300): Accuracy = 0.9757, loss = 0.0756105, global_step = 201\n",
      "INFO:tensorflow:Saving checkpoints for 301 into ./mnist_training/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.48232\n",
      "INFO:tensorflow:loss = 0.0820278, step = 301 (11.789 sec)\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-28-10:35:29\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_training/model.ckpt-301\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-28-10:35:31\n",
      "INFO:tensorflow:Saving dict for global step 301: Accuracy = 0.9827, global_step = 301, loss = 0.056647\n",
      "INFO:tensorflow:Validation (step 400): Accuracy = 0.9827, loss = 0.056647, global_step = 301\n",
      "INFO:tensorflow:Saving checkpoints for 401 into ./mnist_training/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.44123\n",
      "INFO:tensorflow:loss = 0.138461, step = 401 (11.847 sec)\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-28-10:35:40\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_training/model.ckpt-401\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-28-10:35:43\n",
      "INFO:tensorflow:Saving dict for global step 401: Accuracy = 0.9865, global_step = 401, loss = 0.0448599\n",
      "INFO:tensorflow:Validation (step 500): Accuracy = 0.9865, loss = 0.0448599, global_step = 401\n",
      "INFO:tensorflow:Saving checkpoints for 501 into ./mnist_training/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.29987\n",
      "INFO:tensorflow:loss = 0.134478, step = 501 (12.048 sec)\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-28-10:35:52\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_training/model.ckpt-501\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-28-10:35:55\n",
      "INFO:tensorflow:Saving dict for global step 501: Accuracy = 0.9875, global_step = 501, loss = 0.0395608\n",
      "INFO:tensorflow:Validation (step 600): Accuracy = 0.9875, loss = 0.0395608, global_step = 501\n",
      "INFO:tensorflow:Saving checkpoints for 601 into ./mnist_training/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.33388\n",
      "INFO:tensorflow:loss = 0.0993781, step = 601 (11.999 sec)\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-28-10:36:06\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_training/model.ckpt-601\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-28-10:36:09\n",
      "INFO:tensorflow:Saving dict for global step 601: Accuracy = 0.989, global_step = 601, loss = 0.0363472\n",
      "INFO:tensorflow:Validation (step 700): Accuracy = 0.989, loss = 0.0363472, global_step = 601\n",
      "INFO:tensorflow:Saving checkpoints for 701 into ./mnist_training/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.06348\n",
      "INFO:tensorflow:loss = 0.082968, step = 701 (14.157 sec)\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-28-10:36:19\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_training/model.ckpt-701\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-28-10:36:21\n",
      "INFO:tensorflow:Saving dict for global step 701: Accuracy = 0.99, global_step = 701, loss = 0.0361299\n",
      "INFO:tensorflow:Validation (step 800): Accuracy = 0.99, loss = 0.0361299, global_step = 701\n",
      "INFO:tensorflow:Saving checkpoints for 801 into ./mnist_training/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.08455\n",
      "INFO:tensorflow:loss = 0.0831533, step = 801 (12.369 sec)\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-28-10:36:31\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_training/model.ckpt-801\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-28-10:36:34\n",
      "INFO:tensorflow:Saving dict for global step 801: Accuracy = 0.9898, global_step = 801, loss = 0.0364494\n",
      "INFO:tensorflow:Validation (step 900): Accuracy = 0.9898, loss = 0.0364494, global_step = 801\n",
      "INFO:tensorflow:Saving checkpoints for 901 into ./mnist_training/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.14783\n",
      "INFO:tensorflow:loss = 0.0771529, step = 901 (12.273 sec)\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-28-10:36:44\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_training/model.ckpt-901\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-28-10:36:46\n",
      "INFO:tensorflow:Saving dict for global step 901: Accuracy = 0.9893, global_step = 901, loss = 0.033642\n",
      "INFO:tensorflow:Validation (step 1000): Accuracy = 0.9893, loss = 0.033642, global_step = 901\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into ./mnist_training/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.90078\n",
      "INFO:tensorflow:loss = 0.124932, step = 1001 (12.657 sec)\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-28-10:36:56\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_training/model.ckpt-1001\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-28-10:36:58\n",
      "INFO:tensorflow:Saving dict for global step 1001: Accuracy = 0.9872, global_step = 1001, loss = 0.0396867\n",
      "INFO:tensorflow:Validation (step 1100): Accuracy = 0.9872, loss = 0.0396867, global_step = 1001\n",
      "INFO:tensorflow:Saving checkpoints for 1101 into ./mnist_training/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.44673\n",
      "INFO:tensorflow:loss = 0.0338702, step = 1101 (11.839 sec)\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-28-10:37:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mnist_training/model.ckpt-1101\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-28-10:37:10\n",
      "INFO:tensorflow:Saving dict for global step 1101: Accuracy = 0.9899, global_step = 1101, loss = 0.030554\n",
      "INFO:tensorflow:Validation (step 1200): Accuracy = 0.9899, loss = 0.030554, global_step = 1101\n",
      "INFO:tensorflow:Saving checkpoints for 1201 into ./mnist_training/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.52658\n",
      "INFO:tensorflow:loss = 0.00947447, step = 1201 (11.729 sec)\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-28-10:37:19\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_training/model.ckpt-1201\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-28-10:37:22\n",
      "INFO:tensorflow:Saving dict for global step 1201: Accuracy = 0.9907, global_step = 1201, loss = 0.0312055\n",
      "INFO:tensorflow:Validation (step 1300): Accuracy = 0.9907, loss = 0.0312055, global_step = 1201\n",
      "INFO:tensorflow:Saving checkpoints for 1301 into ./mnist_training/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.60836\n",
      "INFO:tensorflow:loss = 0.0204064, step = 1301 (11.616 sec)\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-28-10:37:31\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_training/model.ckpt-1301\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-28-10:37:34\n",
      "INFO:tensorflow:Saving dict for global step 1301: Accuracy = 0.9927, global_step = 1301, loss = 0.025143\n",
      "INFO:tensorflow:Validation (step 1400): Accuracy = 0.9927, loss = 0.025143, global_step = 1301\n",
      "INFO:tensorflow:Saving checkpoints for 1401 into ./mnist_training/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.34515\n",
      "INFO:tensorflow:loss = 0.0207639, step = 1401 (11.983 sec)\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-28-10:37:43\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_training/model.ckpt-1401\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-28-10:37:46\n",
      "INFO:tensorflow:Saving dict for global step 1401: Accuracy = 0.9918, global_step = 1401, loss = 0.0271806\n",
      "INFO:tensorflow:Validation (step 1500): Accuracy = 0.9918, loss = 0.0271806, global_step = 1401\n",
      "INFO:tensorflow:Saving checkpoints for 1501 into ./mnist_training/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.015\n",
      "INFO:tensorflow:loss = 0.0335354, step = 1501 (12.477 sec)\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-28-10:37:56\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_training/model.ckpt-1501\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-219b718bdf2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run script ##############################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-864152b85b5c>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mrun_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# RunConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mschedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_and_evaluate\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# What to run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mhparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m  \u001b[0;31m# HParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(experiment_fn, output_dir, schedule, run_config, hparams)\u001b[0m\n\u001b[1;32m    207\u001b[0m   \u001b[0mschedule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_get_default_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_execute_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\u001b[0m in \u001b[0;36m_execute_schedule\u001b[0;34m(experiment, schedule)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Allowed values for this experiment are: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Schedule references non-callable member %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dir_suffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         )]\n\u001b[0;32m--> 502\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     eval_result = self._call_evaluate(input_fn=self._eval_input_fn,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, delay_secs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     return self._call_train(input_fn=self._train_input_fn,\n\u001b[1;32m    279\u001b[0m                             \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                             hooks=self._train_monitors + extra_hooks)\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\u001b[0m in \u001b[0;36m_call_train\u001b[0;34m(self, _sentinel, input_fn, steps, hooks, max_steps)\u001b[0m\n\u001b[1;32m    670\u001b[0m                                    \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                                    \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                                    hooks=hooks)\n\u001b[0m\u001b[1;32m    673\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m       return self._estimator.fit(input_fn=input_fn,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps)\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    516\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    860\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    978\u001b[0m               \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m               run_metadata=run_metadata))\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stop\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrun_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36mafter_run\u001b[0;34m(self, run_context, run_values)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \"monitors\"] if \"monitors\" in run_values.results else {}\n\u001b[1;32m   1197\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_monitors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m       \u001b[0minduce_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minduce_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0mrun_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36mstep_end\u001b[0;34m(self, step, output)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEveryN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_every_n_step_begin_called\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevery_n_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36mevery_n_step_end\u001b[0;34m(self, step, outputs)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Run evaluation and log it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     \u001b[0mvalidation_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36m_evaluate_estimator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    665\u001b[0m       return self._estimator.evaluate(\n\u001b[1;32m    666\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m           name=self.name)\n\u001b[0m\u001b[1;32m    668\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m       return self._estimator.evaluate(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   def predict(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_evaluate_model\u001b[0;34m(self, input_fn, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    737\u001b[0m           \u001b[0mfinal_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m           config=self._session_config)\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m       _write_dict_to_summary(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/training/evaluation.py\u001b[0m in \u001b[0;36m_evaluate_once\u001b[0;34m(checkpoint_path, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, hooks, config)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meval_ops\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   logging.info('Finished evaluation at ' + time.strftime('%Y-%m-%d-%H:%M:%S',\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    516\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    860\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    970\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run script ##############################################\n",
    "tf.app.run(main=run_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc26de89c50>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './mnist_training'}\n",
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_training/model.ckpt-1501\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import skimage.io\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set default flags for the output directories\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_string(\n",
    "    flag_name='saved_model_dir', default_value='./mnist_training',\n",
    "    docstring='Output directory for model and training stats.')\n",
    "\n",
    "\n",
    "# MNIST sample images\n",
    "IMAGE_URLS = [\n",
    "    'https://i.imgur.com/SdYYBDt.png',  # 0\n",
    "    'https://i.imgur.com/Wy7mad6.png',  # 1\n",
    "    'https://i.imgur.com/nhBZndj.png',  # 2\n",
    "    'https://i.imgur.com/V6XeoWZ.png',  # 3\n",
    "    'https://i.imgur.com/EdxBM1B.png',  # 4\n",
    "    'https://i.imgur.com/zWSDIuV.png',  # 5\n",
    "    'https://i.imgur.com/Y28rZho.png',  # 6\n",
    "    'https://i.imgur.com/6qsCz2W.png',  # 7\n",
    "    'https://i.imgur.com/BVorzCP.png',  # 8\n",
    "    'https://i.imgur.com/vt5Edjb.png',  # 9\n",
    "]\n",
    "\n",
    "def load_images():\n",
    "    \"\"\"Load MNIST sample images from the web and return them in an array.\n",
    "    Returns:\n",
    "        Numpy array of size (10, 28, 28, 1) with MNIST sample images.\n",
    "    \"\"\"\n",
    "    images = np.zeros((10, 28, 28, 1))\n",
    "    for idx, url in enumerate(IMAGE_URLS):\n",
    "        images[idx, :, :, 0] = skimage.io.imread(url)\n",
    "    return images\n",
    "\n",
    "def test_inputs():\n",
    "    \"\"\"Returns training set as Operations.\n",
    "    Returns:\n",
    "        (features, ) Operations that iterate over the test set.\n",
    "    \"\"\"\n",
    "    with tf.name_scope('Test_data'):\n",
    "        images = tf.constant(load_images(), dtype=np.float32)\n",
    "        dataset = tf.contrib.data.Dataset.from_tensor_slices((images,))\n",
    "        # Return as iteration in batches of 1\n",
    "        return dataset.batch(1).make_one_shot_iterator().get_next()\n",
    "\n",
    "\n",
    "def infer(argv=None):\n",
    "    \"\"\"Run the inference and print the results to stdout.\"\"\"\n",
    "    params = tf.contrib.training.HParams()  # Empty hyperparameters\n",
    "    # Set the run_config where to load the model from\n",
    "    run_config = tf.contrib.learn.RunConfig()\n",
    "    run_config = run_config.replace(model_dir=FLAGS.saved_model_dir)\n",
    "    # Initialize the estimator and run the prediction\n",
    "    estimator = get_estimator(run_config, params)\n",
    "    result = estimator.predict(input_fn=test_inputs)\n",
    "    for r in result:\n",
    "        print(r)\n",
    "\n",
    "tf.app.run(main=infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sess.run(test_inputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- https://medium.com/onfido-tech/higher-level-apis-in-tensorflow-67bfb602e6c0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
